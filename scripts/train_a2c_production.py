#!/usr/bin/env python3
"""
================================================================================
üöÄ A2C PRODUCTION TRAINING - ENTRENAMIENTO ROBUSTO LISTO PARA PRODUCCI√ìN
================================================================================
Script de entrenamiento A2C optimizado para RTX 4060 con:
- 500,000 timesteps (escalable a 1M+)
- n_steps=2048 (captura variaci√≥n anual: 8,760 √∑ 4 = 2,190 ‚âà 2,048 pasos)
- Entropy decay (0.01 ‚Üí 0.001) - SINCRONIZADO CON SAC/PPO
- Multiobjetivo sincronizado (rewards.py)
- GPU auto-detection
- Checkpoints cada 1,000 steps
- Resume-capable

CARACTER√çSTICAS A2C (Advantage Actor-Critic):
- Actualizaciones s√≠ncronas (m√°s estable que A3C as√≠ncrono)
- GAE (Generalized Advantage Estimation) para reducci√≥n de varianza
- On-policy (m√°s data-efficient que SAC offline)
- M√°s r√°pido que PPO (wall-clock) en entrenamiento

USO:
    python scripts/train_a2c_production.py
    python scripts/train_a2c_production.py --resume
    python scripts/train_a2c_production.py --timesteps 1000000 --priority co2_focus

MONITOREO:
    tail -f logs/a2c_training.log
    tensorboard --logdir outputs/a2c_logs

HIPERPAR√ÅMETROS:
- n_steps: 2048 (see year variation)
- learning_rate: 1e-4 (linear decay)
- gae_lambda: 0.95 (GAE for variance reduction)
- ent_coef_schedule: linear (0.01 ‚Üí 0.001)
- reward_scale: 0.1 (prevent Q-explosion)
- use_huber_loss: True (robust VF)

@author: pvbesscar-system
@date: 2026-02-04
@version: 2.0.0 (SYNCHRONIZED WITH SAC/PPO)
================================================================================
"""
from __future__ import annotations

import argparse
import json
import logging
import sys
from pathlib import Path
from datetime import datetime

# Set up logging
Path("logs").mkdir(exist_ok=True)
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
    handlers=[
        logging.FileHandler("logs/a2c_training.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)
import sys
import time
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Dict


# ==============================================================================
# LOGGING SETUP
# ==============================================================================
class ColorFormatter(logging.Formatter):
    """Formatter con colores para terminal."""

    COLORS = {
        logging.DEBUG: "\033[36m",     # Cyan
        logging.INFO: "\033[32m",      # Green
        logging.WARNING: "\033[33m",   # Yellow
        logging.ERROR: "\033[31m",     # Red
        logging.CRITICAL: "\033[35m",  # Magenta
    }
    RESET = "\033[0m"

    def format(self, record):
        color = self.COLORS.get(record.levelno, "")
        record.levelname = f"{color}{record.levelname}{self.RESET}"
        return super().format(record)


# Setup logging
handler = logging.StreamHandler()
handler.setFormatter(ColorFormatter("%(levelname)s | %(message)s"))
logging.basicConfig(level=logging.INFO, handlers=[handler])
logger = logging.getLogger(__name__)


# ==============================================================================
# VISUAL BANNERS
# ==============================================================================
def print_banner():
    """Imprime banner de inicio A2C."""
    banner = """
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                                                                              ‚ïë
‚ïë   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ïó‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ïó   ‚ïë
‚ïë  ‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ïö‚ïê‚ïê‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù    ‚ïö‚ïê‚ïê‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ïë
‚ïë  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïë ‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïë            ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ñà‚ñà‚ïó ‚ïë
‚ïë  ‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïù ‚ñà‚ñà‚ïë            ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ïó‚ïë
‚ïë  ‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó       ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë ‚ïö‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë ‚ïö‚ñà‚ñà‚ïë
‚ïë  ‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù       ‚ïö‚ïê‚ïù   ‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïë
‚ïë                                                                              ‚ïë
‚ïë  üîã Advantage Actor-Critic - Iquitos EV/Solar/BESS Optimization üå¥          ‚ïë
‚ïë                                                                              ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
"""
    print(banner)
    print(f"  üìÖ Fecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"  üêç Python: {sys.version.split()[0]}")
    print()


def print_config_summary(
    timesteps: int,
    device: str,
    gpu_info: Dict[str, Any],
    schema_path: Path,
    checkpoint_dir: Path,
):
    """Imprime resumen de configuraci√≥n A2C."""
    print()
    print("=" * 80)
    print("  ‚öôÔ∏è  CONFIGURACI√ìN A2C")
    print("=" * 80)
    print()
    print("  üìä ENTRENAMIENTO:")
    print(f"     ‚Ä¢ Timesteps totales: {timesteps:,}")
    print(f"     ‚Ä¢ N-Steps (rollout): 2,048")
    print(f"     ‚Ä¢ Learning Rate: 1e-4 (linear decay)")
    print(f"     ‚Ä¢ Gamma (discount): 0.99")
    print(f"     ‚Ä¢ GAE Lambda: 0.95")
    print(f"     ‚Ä¢ Entropy Coef: 0.01 ‚Üí 0.001 (decaying)")
    print(f"     ‚Ä¢ Value Coef: 0.5")
    print(f"     ‚Ä¢ Max Grad Norm: 0.5")
    print()
    print("  üñ•Ô∏è  HARDWARE:")
    print(f"     ‚Ä¢ Device: {device}")
    if gpu_info.get('cuda_available'):
        print(f"     ‚Ä¢ GPU: {gpu_info.get('name', 'N/A')}")
        print(f"     ‚Ä¢ VRAM: {gpu_info.get('vram_gb', 0):.2f} GB")
    print()
    print("  üìÅ RUTAS:")
    print(f"     ‚Ä¢ Schema: {schema_path}")
    print(f"     ‚Ä¢ Checkpoints: {checkpoint_dir}")
    print()
    print("  üéØ MULTI-OBJETIVO (CO‚ÇÇ Focus):")
    print(f"     ‚Ä¢ CO‚ÇÇ Weight: 0.50 (primary)")
    print(f"     ‚Ä¢ Solar Weight: 0.20")
    print(f"     ‚Ä¢ Cost Weight: 0.15")
    print(f"     ‚Ä¢ EV Weight: 0.10")
    print(f"     ‚Ä¢ Grid Weight: 0.05")
    print()


# ==============================================================================
# GPU DETECTION
# ==============================================================================
def detect_gpu() -> Dict[str, Any]:
    """Detecta GPU disponible y retorna info."""
    result = {
        'device': 'cpu',
        'cuda_available': False,
        'mps_available': False,
        'name': 'CPU',
        'vram_gb': 0.0,
    }

    try:
        import torch

        if torch.cuda.is_available():
            result['cuda_available'] = True
            result['device'] = 'cuda'
            result['name'] = torch.cuda.get_device_name(0)
            result['vram_gb'] = torch.cuda.get_device_properties(0).total_memory / (1024**3)
            logger.info(f"üéÆ GPU detectada: {result['name']} ({result['vram_gb']:.2f} GB)")
        elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            result['mps_available'] = True
            result['device'] = 'mps'
            result['name'] = 'Apple MPS'
            logger.info("üçé Apple MPS detectado")
        else:
            logger.warning("‚ö†Ô∏è  No se detect√≥ GPU, usando CPU")

    except ImportError:
        logger.warning("‚ö†Ô∏è  PyTorch no instalado, usando CPU")

    return result


# ==============================================================================
# DATASET VALIDATION
# ==============================================================================
def validate_dataset(schema_path: Path) -> bool:
    """Valida que el dataset tenga los 128 chargers requeridos."""
    if not schema_path.exists():
        logger.error(f"‚ùå Schema no encontrado: {schema_path}")
        return False

    try:
        import json
        schema = json.loads(schema_path.read_text(encoding="utf-8"))

        # Verificar chargers
        buildings = schema.get("buildings", {})
        total_chargers = 0

        for _, bdata in buildings.items():
            chargers = bdata.get("chargers", {})
            if isinstance(chargers, dict):
                total_chargers += len(chargers)

        if total_chargers != 128:
            logger.error(f"‚ùå Dataset tiene {total_chargers} chargers, se requieren 128")
            return False

        logger.info(f"‚úÖ Dataset validado: {total_chargers} chargers detectados")
        return True

    except Exception as e:
        logger.error(f"‚ùå Error validando dataset: {e}")
        return False


# ==============================================================================
# MAIN TRAINING FUNCTION
# ==============================================================================
def run_training(
    config_path: Path,
    timesteps: int,
    resume: bool = False,
    eval_only: bool = False,
) -> Dict[str, Any]:
    """Ejecuta entrenamiento A2C de producci√≥n.

    Args:
        config_path: Ruta al archivo de configuraci√≥n YAML
        timesteps: Total de timesteps para entrenar
        resume: Si True, continua desde √∫ltimo checkpoint
        eval_only: Si True, solo eval√∫a sin entrenar

    Returns:
        Dict con resumen de entrenamiento y m√©tricas
    """
    # Importar aqu√≠ para evitar imports innecesarios si hay errores de args
    from scripts._common import load_all
    from iquitos_citylearn.oe3.simulate import simulate

    # Cargar configuraci√≥n
    cfg, paths = load_all(str(config_path))

    # Detectar GPU
    gpu_info = detect_gpu()

    # Rutas
    schema_path = paths.processed_dir / "citylearn" / "iquitos_ev_mall" / "schema.json"
    out_dir = paths.oe3_simulations_dir / "a2c"
    out_dir.mkdir(parents=True, exist_ok=True)

    checkpoint_dir = paths.checkpoints_dir / "a2c"
    checkpoint_dir.mkdir(parents=True, exist_ok=True)

    # Validar dataset
    if not validate_dataset(schema_path):
        raise ValueError(f"Dataset inv√°lido: {schema_path}")

    # Mostrar configuraci√≥n
    print_config_summary(
        timesteps=timesteps,
        device=gpu_info['device'],
        gpu_info=gpu_info,
        schema_path=schema_path,
        checkpoint_dir=checkpoint_dir,
    )

    # Modo de ejecuci√≥n
    if eval_only:
        print("üéØ MODO: Solo evaluaci√≥n (sin entrenamiento)")
        timesteps = 8760  # 1 episodio para eval
    else:
        print(f"üéØ MODO: Entrenamiento ({timesteps:,} timesteps)")
        if resume:
            checkpoint_files = list(checkpoint_dir.glob("a2c_*.zip"))
            if checkpoint_files:
                latest = max(checkpoint_files, key=lambda p: p.stat().st_mtime)
                print(f"   üì• Resumiendo desde: {latest}")
            else:
                print("   ‚ö†Ô∏è  No hay checkpoints, iniciando desde cero")

    print()
    print("=" * 80)
    print("  INICIANDO ENTRENAMIENTO A2C...")
    print("=" * 80)
    print()

    start_time = time.time()

    # Ejecutar simulaci√≥n con A2C
    result = simulate(
        schema_path=schema_path,
        agent_name="a2c",
        out_dir=out_dir,
        training_dir=paths.checkpoints_dir,
        carbon_intensity_kg_per_kwh=float(cfg['oe3']['grid']['carbon_intensity_kg_per_kwh']),
        seconds_per_time_step=int(cfg['project']['seconds_per_time_step']),
        # A2C config - sincronizado con a2c_sb3.py defaults
        a2c_timesteps=timesteps,
        a2c_n_steps=2048,
        a2c_learning_rate=1e-4,
        a2c_entropy_coef=0.01,
        a2c_gamma=0.99,
        a2c_gae_lambda=0.95,
        a2c_vf_coef=0.5,
        a2c_log_interval=500,
        a2c_checkpoint_freq_steps=1000,
        a2c_resume_checkpoints=resume,
        a2c_device=gpu_info['device'],
        # General
        deterministic_eval=True,
        use_multi_objective=True,
        multi_objective_priority=cfg["oe3"]["multi_objective"]["multi_objective_priority"],
        seed=42,
    )

    elapsed = time.time() - start_time

    # Resumen final
    print()
    print("=" * 80)
    print("  ‚úÖ ENTRENAMIENTO A2C COMPLETADO")
    print("=" * 80)
    print()
    print(f"‚è±Ô∏è  Tiempo total: {timedelta(seconds=int(elapsed))}")
    print(f"üìä Steps ejecutados: {result.steps:,}")
    print()
    print("üìà M√âTRICAS DE ENERG√çA:")
    print(f"   Grid Import: {result.grid_import_kwh:,.0f} kWh")
    print(f"   Grid Export: {result.grid_export_kwh:,.0f} kWh")
    print(f"   PV Generation: {result.pv_generation_kwh:,.0f} kWh")
    print(f"   EV Charging: {result.ev_charging_kwh:,.0f} kWh")
    print(f"   Building Load: {result.building_load_kwh:,.0f} kWh")
    print()
    print("üåç M√âTRICAS CO‚ÇÇ (3-Component):")
    print(f"   CO‚ÇÇ Emitido (Grid): {result.co2_emitido_grid_kg:,.0f} kg")
    print(f"   CO‚ÇÇ Reducci√≥n Indirecta: {result.co2_reduccion_indirecta_kg:,.0f} kg")
    print(f"   CO‚ÇÇ Reducci√≥n Directa: {result.co2_reduccion_directa_kg:,.0f} kg")
    print(f"   CO‚ÇÇ NETO: {result.co2_neto_kg:,.0f} kg")

    if result.co2_neto_kg < 0:
        print()
        print("   üéâ ¬°CARBONO-NEGATIVO! El sistema reduce m√°s CO‚ÇÇ del que emite")

    print()
    print("üìÅ ARCHIVOS GENERADOS:")
    print(f"   Results: {result.results_path}")
    print(f"   Timeseries: {result.timeseries_path}")
    print(f"   Checkpoints: {checkpoint_dir}")
    print()

    # Guardar resumen
    summary = {
        "agent": "A2C",
        "timestamp": datetime.now().isoformat(),
        "elapsed_seconds": elapsed,
        "timesteps": timesteps,
        "steps_executed": result.steps,
        "device": gpu_info['device'],
        "gpu_name": gpu_info.get('name', 'N/A'),
        "hyperparameters": {
            "n_steps": 2048,
            "learning_rate": 1e-4,
            "gamma": 0.99,
            "gae_lambda": 0.95,
            "ent_coef": 0.01,
            "vf_coef": 0.5,
            "max_grad_norm": 0.5,
        },
        "energy_metrics": {
            "grid_import_kwh": result.grid_import_kwh,
            "grid_export_kwh": result.grid_export_kwh,
            "pv_generation_kwh": result.pv_generation_kwh,
            "ev_charging_kwh": result.ev_charging_kwh,
            "building_load_kwh": result.building_load_kwh,
        },
        "co2_metrics": {
            "co2_emitido_grid_kg": result.co2_emitido_grid_kg,
            "co2_reduccion_indirecta_kg": result.co2_reduccion_indirecta_kg,
            "co2_reduccion_directa_kg": result.co2_reduccion_directa_kg,
            "co2_neto_kg": result.co2_neto_kg,
            "carbon_negative": result.co2_neto_kg < 0,
        },
        "multi_objective": {
            "priority": result.multi_objective_priority,
            "reward_co2_mean": result.reward_co2_mean,
            "reward_solar_mean": result.reward_solar_mean,
            "reward_total_mean": result.reward_total_mean,
        },
        "files": {
            "results": result.results_path,
            "timeseries": result.timeseries_path,
            "checkpoints": str(checkpoint_dir),
        }
    }

    summary_path = out_dir / "a2c_summary.json"
    summary_path.write_text(json.dumps(summary, indent=2), encoding="utf-8")
    logger.info(f"üìÑ Resumen guardado: {summary_path}")

    return summary


# ==============================================================================
# CLI MAIN
# ==============================================================================
def main():
    """Entry point principal."""
    parser = argparse.ArgumentParser(
        description="üöÄ A2C Training Pipeline - Producci√≥n",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Ejemplos:
  # Entrenamiento est√°ndar (500k timesteps)
  python -m scripts.train_a2c_production

  # Entrenamiento r√°pido para testing
  python -m scripts.train_a2c_production --timesteps 50000

  # Entrenamiento extendido (1M timesteps)
  python -m scripts.train_a2c_production --timesteps 1000000

  # Continuar desde checkpoint
  python -m scripts.train_a2c_production --resume

  # Solo evaluaci√≥n
  python -m scripts.train_a2c_production --eval-only

Comparativa de Agentes:
  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
  ‚îÇ Agente  ‚îÇ Sample Effic.  ‚îÇ Wall-Clock    ‚îÇ Estabilidad   ‚îÇ
  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
  ‚îÇ A2C     ‚îÇ ‚òÖ‚òÖ‚òÜ‚òÜ‚òÜ (bajo)   ‚îÇ ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ (r√°pido)‚îÇ ‚òÖ‚òÖ‚òÖ‚òÜ‚òÜ (medio) ‚îÇ
  ‚îÇ PPO     ‚îÇ ‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ (alto)   ‚îÇ ‚òÖ‚òÖ‚òÖ‚òÜ‚òÜ (medio) ‚îÇ ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ (alto)  ‚îÇ
  ‚îÇ SAC     ‚îÇ ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ (mejor)  ‚îÇ ‚òÖ‚òÖ‚òÜ‚òÜ‚òÜ (lento) ‚îÇ ‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ (alto)  ‚îÇ
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

  A2C es ideal para:
  - Pruebas r√°pidas de concepto
  - Cuando el tiempo de entrenamiento es cr√≠tico
  - Problemas con observaciones simples
        """
    )

    parser.add_argument(
        "--config",
        type=str,
        default="configs/default.yaml",
        help="Ruta al archivo de configuraci√≥n (default: configs/default.yaml)"
    )
    parser.add_argument(
        "--timesteps",
        type=int,
        default=500000,
        help="Total de timesteps para entrenar (default: 500000)"
    )
    parser.add_argument(
        "--resume",
        action="store_true",
        help="Continuar desde √∫ltimo checkpoint"
    )
    parser.add_argument(
        "--eval-only",
        action="store_true",
        help="Solo evaluar sin entrenar"
    )

    args = parser.parse_args()

    print_banner()

    try:
        result = run_training(
            config_path=Path(args.config),
            timesteps=args.timesteps,
            resume=args.resume,
            eval_only=args.eval_only,
        )

        # Exit code basado en CO‚ÇÇ neto
        if result["co2_metrics"]["carbon_negative"]:
            print("üèÜ ¬°Objetivo logrado: Sistema Carbono-Negativo!")
            sys.exit(0)
        else:
            print("üìä Entrenamiento completado (carbono positivo)")
            sys.exit(0)

    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Entrenamiento interrumpido por usuario")
        print("   Los checkpoints guardados pueden usarse con --resume")
        sys.exit(130)
    except Exception as e:
        logger.error(f"‚ùå Error durante entrenamiento: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
