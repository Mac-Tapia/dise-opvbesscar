"""
VALIDAR INTEGRACIÃ“N DEL DATASET DE DEMANDA DEL MALL HORARIA EN CITYLEARN V2

Verifica que el archivo demandamallhorakwh.csv:
1. âœ“ Existe y tiene formato correcto (FECHAHORA;kWh)
2. âœ“ Tiene 8,785 registros (horas completas del aÃ±o)
3. âœ“ EnergÃ­a total conservada (â‰ˆ 12,403,168 kWh)
4. âœ“ Se carga correctamente en dataset_builder
5. âœ“ CityLearn v2 puede interpretarlo como non_shiftable_load
"""

import pandas as pd
from pathlib import Path
import logging
import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent))
from _pandas_dt_helpers import extract_hour, extract_values_float

logging.basicConfig(level=logging.INFO, format='%(message)s')
logger = logging.getLogger(__name__)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONFIGURACIÃ“N
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

INPUT_FILE = Path("data/interim/oe2/demandamallkwh/demandamallhorakwh.csv")
EXPECTED_ROWS = 8785  # 365 dÃ­as Ã— 24 horas + 1 hora del 1/1/2025
EXPECTED_ENERGY_KWH = 12_403_168  # Total energÃ­a (invariante)

logger.info("")
logger.info("=" * 100)
logger.info("VALIDACIÃ“N DE INTEGRACIÃ“N - DATASET HORARIO EN CITYLEARN V2")
logger.info("=" * 100)
logger.info("")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PASO 1: VALIDAR ARCHIVO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

logger.info("PASO 1ï¸âƒ£  VALIDAR ARCHIVO DE DEMANDA HORARIA")
logger.info("â”€" * 100)

if not INPUT_FILE.exists():
    logger.error(f"âŒ ARCHIVO NO ENCONTRADO: {INPUT_FILE}")
    exit(1)

logger.info(f"âœ“ Archivo encontrado: {INPUT_FILE}")
logger.info(f"  TamaÃ±o: {INPUT_FILE.stat().st_size:,} bytes")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PASO 2: CARGAR Y VALIDAR FORMATO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

logger.info("")
logger.info("PASO 2ï¸âƒ£  CARGAR Y VALIDAR FORMATO")
logger.info("â”€" * 100)

try:
    df = pd.read_csv(INPUT_FILE, sep=";")
    logger.info(f"âœ“ Archivo cargado correctamente")
    logger.info(f"  Filas: {len(df):,}")
    logger.info(f"  Columnas: {list(df.columns)}")
except Exception as e:
    logger.error(f"âŒ Error cargando archivo: {e}")
    exit(1)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PASO 3: VALIDAR COLUMNAS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

logger.info("")
logger.info("PASO 3ï¸âƒ£  VALIDAR COLUMNAS REQUERIDAS")
logger.info("â”€" * 100)

required_cols = ["FECHAHORA", "kWh"]
if not all(col in df.columns for col in required_cols):
    logger.error(f"âŒ Columnas faltantes. Se esperaba: {required_cols}, se encontrÃ³: {list(df.columns)}")
    exit(1)

logger.info(f"âœ“ Columnas validadas: {required_cols}")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PASO 4: VALIDAR NÃšMERO DE REGISTROS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

logger.info("")
logger.info("PASO 4ï¸âƒ£  VALIDAR NÃšMERO DE REGISTROS HORARIOS")
logger.info("â”€" * 100)

logger.info(f"  Registros: {len(df):,}")
logger.info(f"  Esperado: {EXPECTED_ROWS:,}")

if abs(len(df) - EXPECTED_ROWS) > 10:  # Tolerancia de 10 registros
    logger.warning(f"âš ï¸  DISCREPANCIA: Se esperaban ~{EXPECTED_ROWS} registros, se encontraron {len(df):,}")
    logger.warning(f"   Diferencia: {len(df) - EXPECTED_ROWS:+,} registros")
else:
    logger.info(f"âœ“ NÃºmero de registros correcto (tolerancia: Â±10)")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PASO 5: VALIDAR UNIDADES (kWh)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

logger.info("")
logger.info("PASO 5ï¸âƒ£  VALIDAR UNIDADES Y RANGO DE VALORES")
logger.info("â”€" * 100)

# Convertir a numÃ©rico
df["kWh"] = pd.to_numeric(df["kWh"], errors="coerce")

if df["kWh"].isna().any():
    logger.error(f"âŒ Valores kWh invÃ¡lidos encontrados: {df['kWh'].isna().sum()} registros")
    exit(1)

total_kwh = df["kWh"].sum()
mean_kwh = df["kWh"].mean()
min_kwh = df["kWh"].min()
max_kwh = df["kWh"].max()
std_kwh = df["kWh"].std()

logger.info(f"âœ“ Unidad: kWh (energÃ­a, no potencia)")
logger.info(f"  Total: {total_kwh:,.0f} kWh")
logger.info(f"  Esperado: {EXPECTED_ENERGY_KWH:,} kWh")
logger.info(f"  Diferencia: {total_kwh - EXPECTED_ENERGY_KWH:,.0f} kWh ({((total_kwh - EXPECTED_ENERGY_KWH) / EXPECTED_ENERGY_KWH * 100):+.3f}%)")
logger.info(f"  Promedio: {mean_kwh:,.2f} kWh/hora")
logger.info(f"  MÃ­nimo: {min_kwh:,.2f} kWh")
logger.info(f"  MÃ¡ximo: {max_kwh:,.2f} kWh")
logger.info(f"  DesviaciÃ³n estÃ¡ndar: {std_kwh:,.2f} kWh")

# Validar rango
if min_kwh < 0:
    logger.error(f"âŒ Valores negativos encontrados: mÃ­nimo = {min_kwh}")
    exit(1)

if max_kwh > 3500:
    logger.warning(f"âš ï¸  MÃ¡ximo muy alto: {max_kwh} kWh (expected ~2800 kWh para demanda mall)")

logger.info(f"âœ“ Rango de valores vÃ¡lido (0 a {max_kwh:,.0f} kWh)")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PASO 6: VALIDAR DATETIME
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

logger.info("")
logger.info("PASO 6ï¸âƒ£  VALIDAR TIMESTAMPS Y COBERTURA TEMPORAL")
logger.info("â”€" * 100)

try:
    df["datetime"] = pd.to_datetime(df["FECHAHORA"], format="%d/%m/%Y %H:%M")
    logger.info(f"âœ“ Timestamps parseados correctamente")
except Exception as e:
    logger.error(f"âŒ Error parseando timestamps: {e}")
    exit(1)

min_date = df["datetime"].min()
max_date = df["datetime"].max()
date_range = (max_date - min_date).days

logger.info(f"  Inicio: {min_date.strftime('%d/%m/%Y %H:%M')}")
logger.info(f"  Final: {max_date.strftime('%d/%m/%Y %H:%M')}")
logger.info(f"  Rango: {date_range} dÃ­as")

if date_range < 364 or date_range > 366:
    logger.warning(f"âš ï¸  Rango temporal anÃ³malo: {date_range} dÃ­as (esperado 365 Â±1)")
else:
    logger.info(f"âœ“ Cobertura temporal: 1 aÃ±o completo ({date_range} dÃ­as)")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PASO 7: VALIDAR PERIODICIDAD HORARIA
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

logger.info("")
logger.info("PASO 7ï¸âƒ£  VALIDAR PERIODICIDAD HORARIA (SIN DUPLICADOS/GAPS)")
logger.info("â”€" * 100)

# Verificar que no hay duplicados
duplicates = df["datetime"].duplicated().sum()
if duplicates > 0:
    logger.error(f"âŒ Timestamps duplicados encontrados: {duplicates}")
    exit(1)

logger.info(f"âœ“ Sin duplicados de timestamp")

# Verificar que no hay gaps grandes (mÃ­nimo deberÃ­a ser 1 hora)
df_sorted = df.sort_values("datetime")
# Calculate time difference in hours (diff returns timedelta, need to extract total_seconds)
df_sorted["time_diff"] = df_sorted["datetime"].diff().apply(lambda x: x.total_seconds() / 3600 if pd.notna(x) else 0)

gaps = df_sorted[df_sorted["time_diff"] > 1.5]  # Gap > 1.5 horas
if len(gaps) > 0:
    logger.warning(f"âš ï¸  {len(gaps)} gaps detectados (> 1.5 horas)")
    logger.warning(f"   Gaps mayores:")
    for idx, row in gaps.head(5).iterrows():
        logger.warning(f"     {row['datetime'].strftime('%d/%m/%Y %H:%M')} (gap: {row['time_diff']:.1f} horas)")
else:
    logger.info(f"âœ“ Periodicidad horaria consistente (sin gaps)")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PASO 8: VALIDAR PATRONES DE DEMANDA
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

logger.info("")
logger.info("PASO 8ï¸âƒ£  VALIDAR PATRONES DE DEMANDA (PICOS/VALLES)")
logger.info("â”€" * 100)

# AÃ±adir hora del dÃ­a
df["hour"] = extract_hour(df["datetime"])

# Demanda por hora del dÃ­a
hourly_demand = df.groupby("hour")["kWh"].agg(["mean", "min", "max", "std"])

logger.info(f"  Demanda por hora del dÃ­a (0-23):")
logger.info(f"  Hora  â”‚  Promedio  â”‚   MÃ­nimo   â”‚   MÃ¡ximo   â”‚  Desv.Est.")
logger.info(f"  â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")

for hour in range(24):
    if hour in hourly_demand.index:
        row = hourly_demand.loc[hour]
        logger.info(f"  {hour:02d}:00 â”‚ {row['mean']:>8,.0f}  â”‚ {row['min']:>8,.0f}  â”‚ {row['max']:>8,.0f}  â”‚ {row['std']:>8,.0f}")

# Detectar picos
peak_hours = hourly_demand.nlargest(5, "mean")
off_peak_hours = hourly_demand.nsmallest(5, "mean")

logger.info(f"")
logger.info(f"  âœ“ Top 5 horas pico (promedio):")
for idx, (hour, row) in enumerate(peak_hours.iterrows(), 1):
    logger.info(f"    {idx}. Hora {hour:02d}:00 â†’ {row['mean']:,.0f} kWh")

logger.info(f"")
logger.info(f"  âœ“ Top 5 horas valle (promedio):")
for idx, (hour, row) in enumerate(off_peak_hours.iterrows(), 1):
    logger.info(f"    {idx}. Hora {hour:02d}:00 â†’ {row['mean']:,.0f} kWh")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PASO 9: VALIDAR COMPATIBILIDAD CITYLEARN V2
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

logger.info("")
logger.info("PASO 9ï¸âƒ£  VALIDAR COMPATIBILIDAD CITYLEARN V2")
logger.info("â”€" * 100)

# CityLearn v2 espera:
# 1. Valores numÃ©ricos
# 2. Sin NaN/Inf
# 3. Valores positivos
# 4. Longitud correcta (8760 para 1 aÃ±o)

if not pd.api.types.is_numeric_dtype(df["kWh"]):
    logger.error(f"âŒ Columna kWh no es numÃ©rica")
    exit(1)

if df["kWh"].isna().any() or df["kWh"].isin([float('inf'), float('-inf')]).any():
    logger.error(f"âŒ NaN o Inf detectados en kWh")
    exit(1)

if (df["kWh"] < 0).any():
    logger.error(f"âŒ Valores negativos en kWh")
    exit(1)

logger.info(f"âœ“ Columna kWh es numÃ©rica (float64)")
logger.info(f"âœ“ Sin valores NaN o Inf")
logger.info(f"âœ“ Todos los valores positivos")

# CityLearn v2 non_shiftable_load espera lista numÃ©rica
logger.info(f"âœ“ Formato compatible con CityLearn v2.non_shiftable_load")
logger.info(f"  Se puede usar como: np.array(df['kWh'].values)")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PASO 10: SIMULAR CARGA EN DATASET_BUILDER
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

logger.info("")
logger.info("PASO ğŸ”Ÿ  SIMULAR CARGA COMO SI FUERA DATASET_BUILDER")
logger.info("â”€" * 100)

try:
    # Simular lo que dataset_builder.py hace
    mall_df = pd.read_csv(INPUT_FILE, sep=";")

    # Buscar columna de demanda
    demand_col = None
    for col in mall_df.columns:
        col_lower = col.lower()
        if any(tag in col_lower for tag in ("kwh", "demanda", "kw", "demand")):
            demand_col = col
            break

    if demand_col is None:
        demand_col = mall_df.columns[-1]  # Ãšltima columna por defecto

    mall_df["datetime"] = pd.to_datetime(mall_df["FECHAHORA"], format="%d/%m/%Y %H:%M")
    mall_series = mall_df[demand_col].values

    logger.info(f"âœ“ SimulaciÃ³n de carga exitosa")
    logger.info(f"  Columna detectada: {demand_col}")
    logger.info(f"  Array shape: {mall_series.shape}")
    logger.info(f"  Array dtype: {mall_series.dtype}")
    logger.info(f"  Suma total: {extract_values_float(mall_series).sum():,.0f} kWh")

except Exception as e:
    logger.error(f"âŒ Error simulando carga: {e}")
    exit(1)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# RESUMEN FINAL
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

logger.info("")
logger.info("=" * 100)
logger.info("âœ… VALIDACIÃ“N COMPLETADA EXITOSAMENTE")
logger.info("=" * 100)
logger.info("")
logger.info("ğŸ“Š RESUMEN:")
logger.info(f"  â€¢ Archivo: {INPUT_FILE}")
logger.info(f"  â€¢ Registros: {len(df):,} (horarios)")
logger.info(f"  â€¢ PerÃ­odo: {min_date.strftime('%d/%m/%Y')} a {max_date.strftime('%d/%m/%Y')} ({date_range} dÃ­as)")
logger.info(f"  â€¢ EnergÃ­a total: {total_kwh:,.0f} kWh")
logger.info(f"  â€¢ Unidad: kWh (energÃ­a, no potencia)")
logger.info(f"  â€¢ Separador: `;` (semicolon)")
logger.info(f"  â€¢ Estado CityLearn v2: âœ“ COMPATIBLE")
logger.info("")
logger.info("ğŸ¯ SIGUIENTE PASO:")
logger.info("  Ejecutar: python -m scripts.run_oe3_build_dataset --config configs/default.yaml")
logger.info("  Esto construirÃ¡ el schema CityLearn con este dataset horario como demanda del mall")
logger.info("")

