"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ AUDITORÃA COMPLETA BESS 6-FASES - AÃ‘O 2024 (8,760 HORAS)                   â•‘
â•‘ ValidaciÃ³n exhaustiva de carga/descarga y cumplimiento de fases              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

OBJETIVO:
- Validar que cada hora cumpla EXACTAMENTE una de las 6 fases
- Verificar columnas de carga/descarga/SOC son correctas
- Generar estadÃ­sticas detalladas por fase y perÃ­odo temporal
- Identificar anomalÃ­as o inconsistencias
- Garantizar integridad del dataset antes de entrenar RL

FASES ESPERADAS:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ FASE 1 (6h-9h):        BESS CARGANDO PRIMERO (PV â†’ BESS â†’ MALL â†’ RED)      â”‚
â”‚ FASE 2 (9h-dinÃ¡mico):  EV MÃXIMA + BESS carga en paralelo                   â”‚
â”‚ FASE 3 (SOCâ‰¥99%):      HOLDING - BESS mantiene 100% SOC (sin acciÃ³n)       â”‚
â”‚ FASE 4 (punto crÃ­tico): BESS descarga por peak shaving MALL > 1900 kW       â”‚
â”‚ FASE 5 (EV deficit):   BESS descarga para EV prioridad + MALL peak shaving â”‚
â”‚ FASE 6 (22h-6h):       REPOSO - BESS idle, SOC = 20%                       â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
"""
from __future__ import annotations
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime
from collections import defaultdict

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONFIGURACIÃ“N
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
BESS_CAPACITY_KWH = 2000.0
BESS_POWER_KW = 400.0
BESS_EFFICIENCY = 0.95
SOC_MIN = 0.20
SOC_MAX = 1.00
PEAK_SHAVING_THRESHOLD_KW = 1900.0
CLOSING_HOUR = 22

# Rutas
ROOT = Path(__file__).parent.parent.parent
DATA_DIR = ROOT / 'data' / 'oe2' / 'bess'
CSV_FILE = DATA_DIR / 'bess_ano_2024.csv'
OUTPUT_DIR = ROOT / 'outputs' / 'auditorias'
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CARGAR DATOS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
print("ğŸ“Š CARGAR DATOS...")
df = pd.read_csv(CSV_FILE)
df['datetime'] = pd.to_datetime(df['datetime'])
df['hour'] = df['datetime'].dt.hour
df['day'] = df['datetime'].dt.day
df['month'] = df['datetime'].dt.month
df['day_of_year'] = df['datetime'].dt.dayofyear

n_rows = len(df)
print(f"âœ“ Dataset cargado: {n_rows} filas Ã— {len(df.columns)} columnas")
print(f"âœ“ Rango temporal: {df['datetime'].min()} â†’ {df['datetime'].max()}")
assert n_rows == 8760, f"âŒ ERROR: Esperaba 8,760 filas, obtuve {n_rows}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FUNCIÃ“N: CLASIFICAR FASE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def classify_phase(row: pd.Series) -> str:
    """Clasificar quÃ© fase deberÃ­a estar en esta hora segÃºn la lÃ³gica BESS."""
    h = row['hour']
    soc = row['soc_percent'] / 100.0  # Convertir a decimal (0.20 - 1.00)
    pv = row['pv_kwh']
    ev = row['ev_kwh']
    mall = row['mall_kwh']
    
    # FASE 6: Reposo (22h-6h)
    if h >= CLOSING_HOUR or h < 6:
        return 'FASE6_REPOSO'
    
    # FASE 1: Carga primero (6h-9h)
    if h < 9:
        return 'FASE1_CARGA'
    
    # FASE 3: Holding (SOC >= 99%)
    if soc >= 0.99:
        return 'FASE3_HOLDING'
    
    # FASE 4: Peak shaving MALL (punto crÃ­tico)
    if pv < mall and mall > PEAK_SHAVING_THRESHOLD_KW and soc > SOC_MIN:
        return 'FASE4_PEAK_SHAVING'
    
    # FASE 5: Descarga para EV (deficit EV)
    # Calcular deficit: ev no cubierto por PV directo
    pv_to_ev = min(pv, ev)
    ev_deficit = ev - pv_to_ev
    if ev_deficit > 0 and soc > SOC_MIN:
        return 'FASE5_EV_DESCARGA'
    
    # FASE 2: EV prioridad + BESS carga paralela (9h - mientras SOC < 99%)
    return 'FASE2_EV_BESS'

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FUNCIÃ“N: VALIDAR FILA
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def validate_row(row: pd.Series, idx: int) -> dict:
    """Validar una fila especÃ­fica del dataset."""
    errors = []
    warnings = []
    
    # 1. VALIDAR ENERGÃAS NO NEGATIVAS
    energy_cols = ['pv_kwh', 'ev_kwh', 'mall_kwh', 'bess_energy_stored_hourly_kwh', 
                   'bess_energy_delivered_hourly_kwh', 'grid_import_kwh', 'grid_export_kwh']
    for col in energy_cols:
        if col in df.columns and row[col] < -0.01:  # Permitir pequeÃ±o margen flotante
            errors.append(f"âŒ {col}={row[col]:.2f} kWh (NEGATIVO)")
    
    # 2. VALIDAR SOC EN RANGO
    soc = row['soc_percent']
    if soc < 20 - 0.1 or soc > 100 + 0.1:
        errors.append(f"âŒ SOC={soc:.2f}% fuera de rango [20%, 100%]")
    
    # 3. VALIDAR COLUMNA bess_mode
    valid_modes = ['idle', 'charging', 'discharging']
    if row['bess_mode'] not in valid_modes:
        warnings.append(f"âš ï¸  bess_mode='{row['bess_mode']}' invÃ¡lido (esperaba: {valid_modes})")
    
    # 4. VALIDAR CON-SISTENCIA ENERGÃAS
    bess_stored = row['bess_energy_stored_hourly_kwh']
    bess_delivered = row['bess_energy_delivered_hourly_kwh']
    
    # Carga y descarga no deben ocurrir simultÃ¡neamente
    if bess_stored > 0 and bess_delivered > 0:
        errors.append(f"âŒ Carga y descarga simultÃ¡neas: stored={bess_stored:.2f}, delivered={bess_delivered:.2f}")
    
    # 5. VALIDAR BALANCE FIN
    h = row['hour']
    if h >= CLOSING_HOUR or h < 6:  # FASE 6
        if bess_stored > 0 or bess_delivered > 0:
            errors.append(f"âŒ FASE 6 (reposo): BESS no deberÃ­a operar (stored={bess_stored:.2f}, delivered={bess_delivered:.2f})")
    
    return {
        'row_index': idx,
        'datetime': row['datetime'],
        'errors': errors,
        'warnings': warnings,
        'has_error': len(errors) > 0
    }

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ANALIZAR TODAS LAS FILAS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
print("\nğŸ” VALIDAR 8,760 FILAS...")
df['phase_expected'] = df.apply(classify_phase, axis=1)
validation_results = [validate_row(row, idx) for idx, (_, row) in enumerate(df.iterrows())]
errors_found = [v for v in validation_results if v['has_error']]

print(f"âœ“ ValidaciÃ³n completada")
print(f"  - Errores encontrados: {len(errors_found)}")
if len(errors_found) > 0:
    print(f"\nâš ï¸  PRIMEROS 10 ERRORES:")
    for i, err in enumerate(errors_found[:10]):
        print(f"\n  Fila {err['row_index']}: {err['datetime']}")
        for e in err['errors']:
            print(f"    {e}")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ESTADÃSTICAS POR FASE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
print("\nğŸ“ˆ ESTADÃSTICAS POR FASE (8,760 HORAS):")
print("â”€" * 100)

phase_stats = defaultdict(lambda: {
    'count': 0,
    'hours': [],
    'avg_pv': 0, 'avg_ev': 0, 'avg_mall': 0,
    'avg_bess_stored': 0, 'avg_bess_delivered': 0,
    'avg_soc': 0, 'avg_grid_import': 0,
    'total_bess_stored': 0, 'total_bess_delivered': 0,
    'total_grid_import': 0, 'total_pv': 0
})

for _, row in df.iterrows():
    phase = row['phase_expected']
    phase_stats[phase]['count'] += 1
    phase_stats[phase]['hours'].append(row['hour'])
    phase_stats[phase]['avg_pv'] += row['pv_kwh']
    phase_stats[phase]['avg_ev'] += row['ev_kwh']
    phase_stats[phase]['avg_mall'] += row['mall_kwh']
    phase_stats[phase]['avg_bess_stored'] += row['bess_energy_stored_hourly_kwh']
    phase_stats[phase]['avg_bess_delivered'] += row['bess_energy_delivered_hourly_kwh']
    phase_stats[phase]['avg_soc'] += row['soc_percent']
    phase_stats[phase]['avg_grid_import'] += row['grid_import_kwh']
    phase_stats[phase]['total_bess_stored'] += row['bess_energy_stored_hourly_kwh']
    phase_stats[phase]['total_bess_delivered'] += row['bess_energy_delivered_hourly_kwh']
    phase_stats[phase]['total_grid_import'] += row['grid_import_kwh']
    phase_stats[phase]['total_pv'] += row['pv_kwh']

# Normalizar promedios
for phase in phase_stats:
    count = max(phase_stats[phase]['count'], 1)
    phase_stats[phase]['avg_pv'] /= count
    phase_stats[phase]['avg_ev'] /= count
    phase_stats[phase]['avg_mall'] /= count
    phase_stats[phase]['avg_bess_stored'] /= count
    phase_stats[phase]['avg_bess_delivered'] /= count
    phase_stats[phase]['avg_soc'] /= count
    phase_stats[phase]['avg_grid_import'] /= count

# Imprimir tabla
for phase in sorted(phase_stats.keys()):
    stats = phase_stats[phase]
    print(f"\n{phase}:")
    print(f"  Horas:              {stats['count']} ({stats['count']/8760*100:.1f}%)")
    print(f"  Promedio SOC:       {stats['avg_soc']:.1f}%")
    print(f"  PV promedio:        {stats['avg_pv']:.1f} kWh/h (total: {stats['total_pv']:,.0f} kWh)")
    print(f"  EV promedio:        {stats['avg_ev']:.1f} kWh/h")
    print(f"  MALL promedio:      {stats['avg_mall']:.1f} kWh/h")
    print(f"  âš¡ BESS carga:      {stats['avg_bess_stored']:.2f} kWh/h (total: {stats['total_bess_stored']:,.0f} kWh)")
    print(f"  ğŸ”— BESS descarga:   {stats['avg_bess_delivered']:.2f} kWh/h (total: {stats['total_bess_delivered']:,.0f} kWh)")
    print(f"  Grid import:        {stats['avg_grid_import']:.1f} kWh/h (total: {stats['total_grid_import']:,.0f} kWh)")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# VALIDAR BALANCE HORARIO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
print("\nğŸ¦ VALIDAR BALANCE ENERGÃ‰TICO HORARIO:")
print("â”€" * 100)

df['energy_balance'] = (
    df['pv_kwh'] +
    df['bess_energy_delivered_hourly_kwh'] +
    df['grid_import_kwh'] -
    df['ev_kwh'] -
    df['mall_kwh'] -
    df['bess_energy_stored_hourly_kwh'] -
    df['grid_export_kwh']
)

balance_errors = df[df['energy_balance'].abs() > 0.1]
print(f"Filas con desbalance > 0.1 kWh: {len(balance_errors)} / 8760")
if len(balance_errors) > 0:
    print(f"\nâš ï¸  Primeros 5 desbalances:")
    for idx, row in balance_errors.head(5).iterrows():
        print(f"  {row['datetime']}: {row['energy_balance']:.4f} kWh")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# VALIDAR SOC EVOLUCIÃ“N
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
print("\nğŸ“Š VALIDAR EVOLUCIÃ“N SOC (Estimado vs Real):")
print("â”€" * 100)

# Calcular SOC estimado a partir de cambios de energÃ­a
soc_estimated = np.zeros(len(df))
soc_estimated[0] = 80.0  # SOC inicial (80%)

for i in range(1, len(df)):
    prev_soc = soc_estimated[i-1] / 100.0
    stored = df.iloc[i]['bess_energy_stored_hourly_kwh']
    delivered = df.iloc[i]['bess_energy_delivered_hourly_kwh']
    
    # Cambio en SOC: +carga-descarga (normalizado por capacidad)
    delta_soc = (stored - delivered) / BESS_CAPACITY_KWH * 100
    soc_estimated[i] = np.clip(prev_soc * 100 + delta_soc, 20, 100)

df['soc_estimated'] = soc_estimated
df['soc_error'] = df['soc_percent'] - df['soc_estimated']

max_soc_error = df['soc_error'].abs().max()
mean_soc_error = df['soc_error'].abs().mean()
print(f"Error mÃ¡ximo SOC:   {max_soc_error:.2f}%")
print(f"Error promedio SOC: {mean_soc_error:.4f}%")

soc_error_large = df[df['soc_error'].abs() > 1.0]
if len(soc_error_large) > 0:
    print(f"\nâš ï¸  {len(soc_error_large)} horas con error > 1%:")
    for idx, row in soc_error_large.head(5).iterrows():
        print(f"  {row['datetime']}: Real={row['soc_percent']:.1f}%, Estimado={row['soc_estimated']:.1f}%, Error={row['soc_error']:.2f}%")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# VALIDAR PATRONES DIARIOS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
print("\nğŸ“… VALIDAR PATRONES DIARIOS (muestreo de 5 dÃ­as):")
print("â”€" * 100)

sample_days = [1, 100, 200, 300, 350]  # Muestreo: inicio, distintas Ã©pocas
for day_of_year in sample_days:
    day_data = df[df['day_of_year'] == day_of_year]
    if len(day_data) == 24:  # Validar que haya 24 horas
        soc_min = day_data['soc_percent'].min()
        soc_max = day_data['soc_percent'].max()
        soc_final = day_data.iloc[-1]['soc_percent']
        bess_stored_total = day_data['bess_energy_stored_hourly_kwh'].sum()
        bess_delivered_total = day_data['bess_energy_delivered_hourly_kwh'].sum()
        pv_total = day_data['pv_kwh'].sum()
        
        print(f"\nDÃ­a {day_of_year} ({day_data.iloc[0]['datetime'].date()}):")
        print(f"  SOC min/max/final: {soc_min:.1f}% / {soc_max:.1f}% / {soc_final:.1f}%")
        print(f"  BESS cargado:      {bess_stored_total:.1f} kWh")
        print(f"  BESS descargado:   {bess_delivered_total:.1f} kWh")
        print(f"  PV generado:       {pv_total:.1f} kWh")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# VALIDAR COLUMNAS CRÃTICAS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
print("\nâœ… VALIDAR COLUMNAS CRÃTICAS:")
print("â”€" * 100)

critical_cols = [
    'datetime', 'pv_kwh', 'ev_kwh', 'mall_kwh',
    'bess_energy_stored_hourly_kwh', 'bess_energy_delivered_hourly_kwh',
    'soc_percent', 'grid_import_kwh', 'bess_mode'
]

for col in critical_cols:
    if col not in df.columns:
        print(f"âŒ Columna FALTANTE: {col}")
    else:
        null_count = df[col].isna().sum()
        if null_count > 0:
            print(f"âŒ {col}: {null_count} valores NULL")
        else:
            if col == 'datetime' or col == 'bess_mode':
                print(f"âœ“ {col}: presente ({df[col].dtype})")
            else:
                min_val = df[col].min()
                max_val = df[col].max()
                print(f"âœ“ {col}: [{min_val:.2f}, {max_val:.2f}]")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# GENERAR REPORTE FINAL
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
print("\n" + "="*100)
print("ğŸ“‹ REPORTE FINAL DE AUDITORÃA")
print("="*100)

certification = {
    'timestamp': datetime.now().isoformat(),
    'dataset_file': str(CSV_FILE),
    'total_rows': len(df),
    'date_range': f"{df['datetime'].min()} â†’ {df['datetime'].max()}",
    'validation_status': 'ERROR' if len(errors_found) > 0 else 'OK',
    'errors_total': len(errors_found),
    'warnings_total': sum(len(v['warnings']) for v in validation_results),
    'soc_error_max': float(max_soc_error),
    'soc_error_mean': float(mean_soc_error),
    'balance_errors': len(balance_errors),
    'phases_found': list(phase_stats.keys()),
    'phase_counts': {k: v['count'] for k, v in phase_stats.items()},
    'bess_carga_anual': float(df['bess_energy_stored_hourly_kwh'].sum()),
    'bess_descarga_anual': float(df['bess_energy_delivered_hourly_kwh'].sum()),
    'pv_generado_anual': float(df['pv_kwh'].sum()),
    'grid_import_anual': float(df['grid_import_kwh'].sum()),
}

# Guardar certificaciÃ³n
cert_file = OUTPUT_DIR / f"audit_bess_6fases_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
import json
with open(cert_file, 'w') as f:
    json.dump(certification, f, indent=2)

print(f"\nâœ“ Estado de validaciÃ³n:     {certification['validation_status']}")
print(f"âœ“ Errores encontrados:     {certification['errors_total']}")
print(f"âœ“ Filas procesadas:        {certification['total_rows']:,}")
print(f"âœ“ Error mÃ¡ximo SOC:        {certification['soc_error_max']:.4f}%")
print(f"âœ“ Error promedio SOC:      {certification['soc_error_mean']:.6f}%")
print(f"âœ“ Desbalances energÃ©ticos: {certification['balance_errors']}")

print(f"\nğŸ“Š RESUMEN ANUAL:")
print(f"  PV generado:           {certification['pv_generado_anual']:>12,.0f} kWh")
print(f"  BESS cargado:          {certification['bess_carga_anual']:>12,.0f} kWh")
print(f"  BESS descargado:       {certification['bess_descarga_anual']:>12,.0f} kWh")
print(f"  Grid importado:        {certification['grid_import_anual']:>12,.0f} kWh")

print(f"\nğŸ“ Reporte guardado: {cert_file}")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CERTIFICACIÃ“N FINAL
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
if certification['validation_status'] == 'OK':
    print("\n" + "="*100)
    print("âœ… CERTIFICACIÃ“N: Dataset BESS 2024 VALIDADO CORRECTAMENTE")
    print("="*100)
    print("\nâœ“ Todas las 6 fases se generan correctamente")
    print("âœ“ Balance energÃ©tico consistente (< 0.1 kWh desviaciÃ³n)")
    print("âœ“ SOC evoluciona correctamente")
    print("âœ“ Columnas completas sin valores NULL")
    print("âœ“ Listo para entrenamiento de agentes RL")
else:
    print("\n" + "="*100)
    print("âš ï¸  ADVERTENCIA: Problemas detectados en dataset")
    print("="*100)
    print(f"\nâŒ Errores crÃ­ticos encontrados: {certification['errors_total']}")
    print("   Revisar dataset antes de usar para entrenamiento RL")
