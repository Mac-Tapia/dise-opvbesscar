# üìö Gu√≠a R√°pida: Gesti√≥n de Datos y Entrenamientos Incrementales

## üìÅ Archivos Generados

- **`training_results_archive.json`** - Archivo consolidado con datos de todos los agentes
- **`scripts/query_training_archive.py`** - Utilidad de consultas y gesti√≥n
- **`TABLA_COMPARATIVA_FINAL_CORREGIDA.md`** - Tabla markdown con comparativa completa

---

## üîç Comandos de Consulta

Todos los comandos se ejecutan as√≠:
```bash
python scripts/query_training_archive.py <comando>
```

### Ver Resumen Completo
```bash
python scripts/query_training_archive.py summary
```
Output: Reporte con todos los agentes, m√©tricas finales, ranking, duraciones

### Ver M√©tricas de Energ√≠a
```bash
python scripts/query_training_archive.py energy
```
Output: Grid import anual, CO‚ÇÇ anual, Solar utilizado (por agente)

### Ver M√©tricas de Aprendizaje
```bash
python scripts/query_training_archive.py performance
```
Output: Reward Final, Actor Loss, Critic Loss (por agente)

### Ver Duraci√≥n de Entrenamientos
```bash
python scripts/query_training_archive.py duration
```
Output: Minutos entrenados, duraci√≥n HMS, velocidad promedio (por agente)

### Ver Reducciones vs Baseline
```bash
python scripts/query_training_archive.py reductions
```
Output: Porcentaje de reducci√≥n en grid y CO‚ÇÇ (por agente)

### Ver Ranking de Agentes
```bash
python scripts/query_training_archive.py ranking
```
Output:
```
üèÜ RANKING DE AGENTES:
  1. A2C: Best energy efficiency (3,494 kWh/a√±o)
  2. PPO: Fastest training speed (3,984 kWh/a√±o)
  3. SAC: Excellent off-policy robustness (4,000 kWh/a√±o)
```

### Buscar Mejor Agente por Criterio
```bash
python scripts/query_training_archive.py best <criterion>
```

Criterios disponibles: `energy`, `speed`, `reward`, `stability`, `overall`

Ejemplos:
```bash
python scripts/query_training_archive.py best energy      # A2C (menor consumo grid)
python scripts/query_training_archive.py best speed       # PPO (m√°s r√°pido)
python scripts/query_training_archive.py best reward      # SAC (rewards m√°s altos)
python scripts/query_training_archive.py best overall     # PPO (balance general)
```

### Ver Estado de Agentes
```bash
python scripts/query_training_archive.py status
```
Output: SAC: COMPLETED, PPO: COMPLETED, A2C: COMPLETED

---

## üöÄ Entrenamientos Incrementales

### Preparar Agente para Entrenamientos Adicionales

```bash
python scripts/query_training_archive.py prepare <AGENT> <NEW_TOTAL_TIMESTEPS>
```

**Ejemplo:** Duplicar entrenamiento de PPO (26,280 ‚Üí 52,560 pasos)
```bash
python scripts/query_training_archive.py prepare PPO 52560
```

Output:
```
üìã PREPARACI√ìN PARA ENTRENAMIENTO INCREMENTAL: PPO
  Pasos actuales: 26,280
  Pasos deseados: 52,560
  Pasos a entrenar: 26,280
  Checkpoint: ppo_final.zip
  Directorio: D:\dise√±opvbesscar\analyses\oe3\training\checkpoints\ppo
```

Y proporciona el **c√≥digo template** listo para usar:

```python
from stable_baselines3 import PPO
import os

# Load agent from checkpoint
agent = PPO.load(
    os.path.join('D:\dise√±opvbesscar\analyses\oe3\training\checkpoints\ppo', 'ppo_final.zip'),
    env=env
)

# Resume training (accumulates timesteps)
agent.learn(
    total_timesteps=26280,           # Pasos adicionales a entrenar
    reset_num_timesteps=False        # CRITICAL: No resetear contador
)

# Save new checkpoint
agent.save('checkpoint_step_52560')
```

### ‚ö†Ô∏è IMPORTANTE: `reset_num_timesteps=False`

**SIEMPRE** usa `reset_num_timesteps=False` para entrenamientos incrementales:
- Si `True`: Reset el contador a 0 (pierde progreso)
- Si `False`: Acumula pasos al total existente ‚úÖ

---

## üìä Datos Almacenados en JSON

El archivo `training_results_archive.json` contiene:

### Por cada agente:
```json
{
  "algorithm_name": "Soft Actor-Critic",
  "status": "COMPLETED",
  "training_dates": {
    "start_utc": "2026-01-28T19:01:00Z",
    "end_utc": "2026-01-28T21:47:00Z",
    "duration_minutes": 166
  },
  "final_metrics": {
    "reward_final": 521.89,
    "actor_loss_final": -5.62,
    "critic_loss_final": 0.0,
    "grid_import_kwh_annual": 4000,
    "co2_kg_annual": 1808
  },
  "checkpoint_management": {
    "checkpoints_saved": 53,
    "checkpoint_directory": "D:\\...\\checkpoints\\sac",
    "final_checkpoint": "sac_final.zip",
    "can_resume_training": true
  }
}
```

---

## üîÑ Flujo de Trabajo: Nuevos Entrenamientos

### 1Ô∏è‚É£ Consult√° estado actual
```bash
python scripts/query_training_archive.py summary
```

### 2Ô∏è‚É£ Decide qu√© agente entrenar m√°s
```bash
python scripts/query_training_archive.py best energy   # Si buscas eficiencia
python scripts/query_training_archive.py best speed    # Si buscas rapidez
```

### 3Ô∏è‚É£ Prepar√° template para nuevos pasos
```bash
python scripts/query_training_archive.py prepare <AGENT> <PASOS_TOTALES>
```

### 4Ô∏è‚É£ Ejecut√° entrenamiento incremental
Copia el c√≥digo template y ajusta `env` seg√∫n tu setup

### 5Ô∏è‚É£ Actualiza datos despu√©s de entrenar
```python
from scripts.query_training_archive import TrainingArchiveManager

manager = TrainingArchiveManager()
new_metrics = {
    "reward_final": 530.5,
    "grid_import_kwh_annual": 3800,
    # ... m√°s m√©tricas ...
}
manager.update_after_incremental_training("PPO", new_metrics)
```

---

## üìà Resumen R√°pido de Agentes

| Agente | Mejor Para | Grid Anual | Duraci√≥n |
|--------|-----------|-----------|----------|
| **A2C** ü•á | Eficiencia m√°xima | 3,494 kWh | 2h 36m |
| **PPO** ü•à | Balance general | 3,984 kWh | 2h 26m |
| **SAC** ü•â | Exploraci√≥n robusta | 4,000 kWh | 2h 46m |

---

## üõ†Ô∏è Troubleshooting

### Erro: "Archive not found"
- Verifica que `training_results_archive.json` exista en ra√≠z del proyecto

### Comando no reconocido
- Uso: `python scripts/query_training_archive.py <comando>`
- No: `python query_training_archive.py ...`

### Entrenamientos incrementales fallan
- Verifica `reset_num_timesteps=False` en el c√≥digo
- Aseg√∫rate de que `env` sea la misma que la original
- Backup checkpoints antes de resumir

---

## üìé Referencias

- üìä [Tabla Comparativa Final](./TABLA_COMPARATIVA_FINAL_CORREGIDA.md)
- üìÑ [SAC Report](./REPORTE_ENTRENAMIENTO_SAC_FINAL.md)
- üìÑ [PPO Report](./REPORTE_ENTRENAMIENTO_PPO_FINAL.md)
- üìÑ [A2C Report](./REPORTE_ENTRENAMIENTO_A2C_DETALLADO.md)
- üóÑÔ∏è [Training Archive (JSON)](./training_results_archive.json)

