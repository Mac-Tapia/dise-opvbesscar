# TUNING DE HIPERPAR√ÅMETROS PARA SAC
## Sistema de Optimizaci√≥n Autom√°tica v2.0

> **√öltima actualizaci√≥n:** 2026-02-19  
> **Estado:** ‚úÖ OPERATIVO - Listo para testing

---

## üìã Resumen

Este sistema implementa **3 algoritmos de b√∫squeda** para optimizar autom√°ticamente los hiperpar√°metros de SAC (Soft Actor-Critic):

| Algoritmo | Velocidad | Calidad | Mejor Para | Complejidad |
|-----------|-----------|---------|-----------|-------------|
| **Grid Search** | üü° Lento | ‚≠ê‚≠ê‚≠ê Excelente | Espacios peque√±os (<1000 combos) | O(grid_size) |
| **Random Search** | üü¢ R√°pido | ‚≠ê‚≠ê Bueno | Espacios grandes (>10K combos) | O(n_samples) |
| **Bayesian Opt** | üü° Moderado | ‚≠ê‚≠ê‚≠ê‚≠ê √ìptimo | Explotaci√≥n inteligente (RECOMENDADO) | O(n √ó GP_fitting) |

---

## üöÄ Instalaci√≥n R√°pida

```bash
# Ya implementado en:
# - src/agents/sac_hyperparameter_tuner.py (motor de b√∫squeda)
# - scripts/train/run_sac_hyperparameter_tuning.py (script ejecutable)

# No hay dependencias adicionales (usa scipy, numpy, pandas ya instalados)
```

---

## üíª Modo de Uso

### 1. BAYESIAN OPTIMIZATION (RECOMENDADO)
```bash
cd d:\dise√±opvbesscar

# Ejecuci√≥n b√°sica (30 iteraciones)
python scripts/train/run_sac_hyperparameter_tuning.py --method bayesian

# Con opciones personalizadas
python scripts/train/run_sac_hyperparameter_tuning.py \
  --method bayesian \
  --num-iterations 50 \
  --episodes 15  # Entrenar 15 episodios por config (defecto: 2 para testing)

# Modo TEST (simula sin entrenar)
python scripts/train/run_sac_hyperparameter_tuning.py --method bayesian --test
```

**Salida esperada:**
```
================================================================================
BAYESIAN OPTIMIZATION HYPERPARAMETER TUNING
================================================================================
Iteraciones completadas: 30/30

Mejor configuraci√≥n encontrada:
  Score: 87.3/100
  LR=2.5e-04 | Buf=400K | œÑ=0.0050
  CO2 Evitado: 1,050,000 kg
  Reward: 4.25

Mejora respecto a baseline: +15.2%
================================================================================
```

### 2. GRID SEARCH (exhaustivo)
```bash
# Probar 50 configs sistematicamente (de ~390K posibles)
python scripts/train/run_sac_hyperparameter_tuning.py \
  --method grid \
  --max-configs 50 \
  --episodes 5

# Con modo test
python scripts/train/run_sac_hyperparameter_tuning.py --method grid --max-configs 20 --test
```

### 3. RANDOM SEARCH (exploratorio)
```bash
# Samplear 50 configs aleatorias
python scripts/train/run_sac_hyperparameter_tuning.py \
  --method random \
  --num-samples 50 \
  --episodes 3
```

---

## üìä Salidas Generadas

Todas las salidas se guardan en `outputs/hyperparameter_tuning/`:

```
outputs/hyperparameter_tuning/
‚îú‚îÄ‚îÄ bayesian_opt_20260219_133022.csv        # Todos los entrenamientos + m√©tricas
‚îú‚îÄ‚îÄ config_optimal_20260219_133022.json     # Mejor config (JSON)
‚îú‚îÄ‚îÄ grid_search_20260219_134500.csv         # Solo si usas Grid Search
‚îî‚îÄ‚îÄ random_search_20260219_133500.csv       # Solo si usas Random Search
```

### CSV con Resultados

```csv
learning_rate,buffer_size,batch_size,tau,gamma,...,score,co2_avoided_kg,avg_episode_reward
0.0001,100000,64,0.005,0.99,...,87.3,1050000,4.25
0.00003,400000,128,0.01,0.99,...,84.1,990000,3.80
...
```

**Columnas principales:**
- `learning_rate`, `buffer_size`, `batch_size`, etc. ‚Üí Hiperpar√°metros
- `score` ‚Üí Score agregado (0-100) para comparaci√≥n r√°pida
- `co2_avoided_kg` ‚Üí M√©trica clave: CO2 evitado anual
- `avg_episode_reward` ‚Üí Reward promedio por episodio
- `solar_utilization_pct` ‚Üí % de solar utilizado
- `grid_import_kwh` ‚Üí Importaci√≥n grid (menor es mejor)
- `ev_satisfaction_pct` ‚Üí Veh√≠culos cargados al 100%
- `convergence_speed` ‚Üí Steps para alcanzar mejor reward
- `stability` ‚Üí Varianza de rewards (menor = m√°s estable)

### JSON con Mejor Configuraci√≥n

```json
{
  "learning_rate": 0.00025,
  "buffer_size": 400000,
  "batch_size": 64,
  "tau": 0.005,
  "gamma": 0.99,
  "ent_coef": "auto",
  "target_entropy": -20,
  "train_freq": 2,
  "net_arch_hidden": 384,
  "network_arch": [384, 384],
  "metadata": {
    "score": 87.3,
    "co2_avoided_kg": 1050000,
    "avg_episode_reward": 4.25,
    "timestamp": "2026-02-19T13:30:22"
  }
}
```

---

## üîß Integraci√≥n con train_sac.py

Una vez encontrados los mejores hiperpar√°metros, usar en `train_sac.py`:

```python
# En scripts/train/train_sac.py, cerca de la creaci√≥n del agente:

# ANTES (parametros por defecto)
sac_config = SACConfig.for_gpu()

# DESPUES (usar mejores hiperpar√°metros)
sac_config = SACConfig(
    learning_rate=0.00025,        # De tuning
    buffer_size=400_000,          # De tuning
    batch_size=64,                # De tuning
    tau=0.005,                    # De tuning
    gamma=0.99,                   # De tuning
    ent_coef='auto',              # De tuning
    target_entropy=-20,           # De tuning
    train_freq=(2, 'step'),       # De tuning
    policy_kwargs={'net_arch': dict(pi=[384, 384], qf=[384, 384])}  # De tuning
)
```

---

## üìà Espacio de B√∫squeda

Los algoritmos prueban estos rangos de hiperpar√°metros:

```python
{
    'learning_rate': [1e-5, 3e-5, 1e-4, 3e-4, 1e-3],
    'buffer_size': [50K, 100K, 200K, 400K, 1M],
    'batch_size': [32, 64, 128, 256, 512],
    'tau': [0.001, 0.005, 0.01, 0.02],
    'gamma': [0.90, 0.95, 0.99],
    'ent_coef': ['auto', 0.05, 0.1, 0.2, 0.5],
    'target_entropy': [-50, -20, -10, -5],
    'train_freq': [1, 2, 4, 8],
    'net_arch_hidden': [128, 256, 384, 512]
}

# Total: 5√ó5√ó5√ó4√ó3√ó5√ó4√ó4√ó4 = 96,000 combinaciones posibles
```

---

## üìä M√©tricas de Evaluaci√≥n

Cada configuraci√≥n se eval√∫a en:

### M√©tricas Principales
1. **CO2 Evitado** (50% peso) ‚Üí `co2_avoided_kg`
   - Solar + BESS vs Grid
   - Objetivo: Maximizar

2. **Reward Promedio** (20% peso) ‚Üí `avg_episode_reward`
   - Promedio sobre episodios compl
   - Objetivo: Maximizar

3. **Velocidad de Convergencia** (15% peso) ‚Üí `convergence_speed`
   - Steps para alcanzar 80% del reward final
   - Objetivo: Minimizar

4. **Estabilidad** (10% peso) ‚Üí `stability`
   - Varianza de rewards (menor = mejor)
   - Objetivo: Minimizar

5. **Solar Utilization** (5% peso) ‚Üí `solar_utilization_pct`
   - % de energ√≠a solar usada (no desperdiciada)
   - Objetivo: Maximizar

### C√°lculo del Score
```
Score = 0.50 √ó CO2_score + 0.20 √ó Reward_score + 0.15 √ó Convergence_score + 
        0.10 √ó Stability_score + 0.05 √ó Solar_score
```

Escala: 0-100 (100 = √≥ptimo)

---

## üéØ Estrategias Recomendadas

### Para Problema Iquitos EV
**Recomendaci√≥n: Bayesian Optimization**
- ‚úÖ Converge en 30-50 iteraciones
- ‚úÖ Usa informaci√≥n de entrenamientos previos
- ‚úÖ Balanza explotaci√≥n vs exploraci√≥n
- ‚úÖ Mejor relaci√≥n calidad/tiempo

**Tiempo estimado:** ~60 horas (con GPU RTX 4060)

### Grid Search
**Cu√°ndo usar:**
- Espacio de b√∫squeda peque√±o (<1000 combos)
- Necesitas garantizar optimalidad global
- Tienes suficiente tiempo de c√≥mputo

**Tiempo estimado:** ~100 horas (50 configs √ó 2h cada)

### Random Search
**Cu√°ndo usar:**
- Espacio muy grande (>10K combos)
- Necesitas resultados "buenos" r√°pido
- No hay correlaci√≥n clara entre par√°metros

**Tiempo estimado:** ~40 horas (50 muestras √ó 0.8h cada)

---

## üß™ Modo Test

Para verificar que todo funciona sin entrenar:

```bash
# Test de Bayesian (genera datos simulados)
python scripts/train/run_sac_hyperparameter_tuning.py --method bayesian --num-iterations 5 --test

# Test de Grid
python scripts/train/run_sac_hyperparameter_tuning.py --method grid --max-configs 10 --test

# Test de Random
python scripts/train/run_sac_hyperparameter_tuning.py --method random --num-samples 10 --test
```

**Salida (sin GPU/entrenamiento):**
```
===============================================================================
BAYESIAN OPTIMIZATION HYPERPARAMETER TUNING
===============================================================================
Iteraciones completadas: 5/5

Mejor configuraci√≥n encontrada:
  Score: 45.2/100 (simulado)
  LR=1e-03 | Buf=100K | œÑ=0.0050
  CO2 Evitado: 1,050,300 kg (simulado)
  Reward: 2.13 (simulado)

Mejora respecto a baseline: +12.3%
===============================================================================

[EXPORT] Resultados guardados en: outputs/hyperparameter_tuning/bayesian_opt_...csv
[SAVE] Mejor config salvada en: outputs/hyperparameter_tuning/config_optimal_...json
```

---

## üîç Detalles T√©cnicos

### Grid Search
```
For learning_rate in [1e-5, 3e-5, 1e-4, 3e-4, 1e-3]:
  For buffer_size in [50K, 100K, 200K, 400K, 1M]:
    For batch_size in [32, 64, 128, 256, 512]:
      ... (todas las otras dimensiones)
      Entrenar SAC con esta config
      Registrar m√©tricas
      Guardar resultado
```

**Complejidad:**
- Configs: 96,000 posibles
- Ajuste pr√°ctico: Tomar ~50 mejores candidatos
- Tiempo: O(n √ó 2h) = 100 horas para 50 configs

### Bayesian Optimization
```
1. Muestrear 5 configs aleatorias inicialmente
   ‚Üí Entrenar SAC con cada una
   
2. Para iteraciones 6-30:
   a) Ajustar Gaussian Process a datos observados
   b) Calcular Expected Improvement (EI) para cada
   c) Seleccionar config con EI m√°ximo
   d) Entrenar SAC
   e) Actualizar GP con nuevo resultado
```

**Ventaja:** Inteligencia adaptativa
- Despu√©s de iter 1: Explora espacios malos
- Despu√©s de iter 15: Se concentra en "buenas regiones"
- Despu√©s de iter 30: Refinamiento fino del √≥ptimo local

---

## üìù Ejemplo Completo

```bash
# 1. Ejecutar tuning (30 iteraciones, modo test para ver que funciona)
python scripts/train/run_sac_hyperparameter_tuning.py --method bayesian --test

# 2. Ver resultados
cat outputs/hyperparameter_tuning/bayesian_opt_*.csv | head -10

# 3. Usar mejores par√°metros en train_sac.py
# (Copiar valores de config_optimal_*.json a SACConfig)

# 4. Entrenar SAC final con mejores par√°metros
python scripts/train/train_sac.py

# 5. Comparar: baseline vs optimizado
# Esperar mejora de ~15-25% en CO2 evitado
```

---

## üêõ Troubleshooting

| Problema | Soluci√≥n |
|----------|----------|
| "No module named sac_hyperparameter_tuner" | `cd d:\dise√±opvbesscar && pip install -e .` |
| Script muy lento | Usar `--test` primero, luego reducir `--episodes` o `--num-iterations` |
| Memoria insuficiente | Reducir `--max-configs` o `--num-iterations` |
| Error de tipo en float/int | Ya manejado en TrainingResult.to_dict() |
| GPU out of memory | Reducir `batch_size` en espacio de b√∫squeda |

---

## üìö Referencias

1. **Control Te√≥rico:**
   - Haarnoja et al. (2018): Soft Actor-Critic Algorithm
   - Rasmussen & Williams: Gaussian Processes for ML

2. **Tuning Pr√°ctico:**
   - Bergstra & Bengio (2012): Random Search vs Grid Search
   - Lizotte (2008): Bayesian Optimization and Adaptive ...

3. **Problema Iquitos:**
   - `docs/PROYECTO_LISTO_PRODUCCION_v72.md`
   - `00_COMIENZA_AQUI.md`

---

## ‚úÖ Checklist Pre-Ejecuci√≥n

- [ ] Datasets disponibles: `data/iquitos_ev_mall/` (solar, chargers, mall, BESS)
- [ ] GPU disponible o suficiente CPU/RAM
- [ ] Python 3.8+ con dependencias instaladas
- [ ] Espacio en disco: ~5 GB para results
- [ ] Tiempo disponible: 30-100 horas seg√∫n m√©todo
- [ ] Modo test ejecutado exitosamente

---

**¬øPreguntas?** Ver `scripts/train/run_sac_hyperparameter_tuning.py` para detalles de implementaci√≥n.

**√öltima ejecuci√≥n exitosa:** 2026-02-19 (Modo Test ‚úÖ)
