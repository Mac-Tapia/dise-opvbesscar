# ğŸš€ ESTRATEGIA DE ENTRENAMIENTO RECOMENDADA

<!-- markdownlint-disable MD013 -->
 **Fecha**: 2026-01-24 | **VersiÃ³n**: MÃXIMA POTENCIA INDIVIDUAL | **Estado**: âœ… 

---

## ğŸ“‹ ÃNDICE DE ESTRATEGIAS

1. [OpciÃ³n 1: Entrenamiento Secuencial (Recomendado)][ref]

[ref]: #opciÃ³n-1-entrenamiento-secuencial-recomendado
2. [OpciÃ³n 2: Entrenamiento Paralelo en GPUs][ref]

[ref]: #opciÃ³n-2-entrenamiento-paralelo-en-gpus
3. [OpciÃ³n 3: Entrenamiento Individual RÃ¡pido][ref]

[ref]: #opciÃ³n-3-entrenamiento-individual-rÃ¡pido
4. [OpciÃ³n 4: Entrenamiento de Prueba (5 episodios)][ref]

[ref]: #opciÃ³n-4-entrenamiento-de-prueba-5-episodios
5. [Monitoreo y Resultados](#monitoreo-y-resultados)

---

## OPCIÃ“N 1: ENTRENAMIENTO SECUENCIAL (Recomendado)

**DescripciÃ³n**: Entrena los 3 agentes uno despuÃ©s de otro en la misma GPU.

**Ventajas**:

- âœ… Simple de ejecutar (un comando)
- âœ… GPU siempre disponible
- âœ… Reproducible
- âœ… Menos riesgo de OOM

**DuraciÃ³n Total**: ~11 horas

### Comando

<!-- markdownlint-disable MD013 -->
```bash
# Verificar primero
.\verificar_agentes.ps1

# Entrenar todos en serie
& .venv/Scripts/python.exe scripts/train_agents_serial.py --device cuda --episodes 50
```bash
<!-- markdownlint-enable MD013 -->

### Detalle de EjecuciÃ³n

<!-- markdownlint-disable MD013 -->
```bash
â”Œâ”€ A2C (RÃ¡pido) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DuraciÃ³n: 2.5-3 horas                  â”‚
â”‚ Episodes: 57 (~500k steps)             â”‚
...
```

[Ver cÃ³digo completo en GitHub]bash
<!-- markdownlint-enable MD013 -->

### Logs Esperados

<!-- markdownlint-disable MD013 -->
```bash
[Inicio] A2C Entrenamiento
 Episode 1/57 | Reward: -1200 | COâ‚‚: 600 kg 
 Episode 10/57 | Reward: -800 | COâ‚‚: 500 kg 
 Episode 30/57 | Reward: -400 | COâ‚‚: 350 kg 
 Episode 50/57 | Reward: -100 | COâ‚‚: 300 kg âœ… 

[Inicio] SAC Entrenamiento
 Episode 1/50 | Reward: -1100 | COâ‚‚: 580 kg 
 Episode 5/50 | Reward: -700 | COâ‚‚: 450 kg 
 Episode 20/50 | Reward: -200 | COâ‚‚: 280 kg 
 Episode 50/50 | Reward: +100...
```

[Ver cÃ³digo completo en GitHub]bash
<!-- markdownlint-enable MD013 -->

---

## OPCIÃ“N 2: ENTRENAMIENTO PARALELO EN GPUS

**DescripciÃ³n**: Entrena 2-3 agentes simultÃ¡neamente en GPU usando subprocesos.

**Ventajas**:

- âœ… Mucho mÃ¡s rÃ¡pido (~6-7 horas)
- âœ… Mejor utilizaciÃ³n GPU
- âœ… Todos los agentes avanzan simultÃ¡neamente

**Desventajas**:

- âš ï¸ Requiere GPU con suficiente VRAM
- âš ï¸ Menor control individual
- âš ï¸ Potencial OOM si VRAM insuficiente

**Requisito**: RTX 4060 (8GB) puede manejar:

- SAC + PPO en GPU: ~5-6 GB + 3-4 GB = 9-10 GB (âŒ Ajustado)
- Mejor: SAC o PPO en GPU, A2C en CPU

### Comando OpciÃ³n 2A: SAC+A2C en GPU

<!-- markdownlint-disable MD013 -->
```bash
# Terminal 1 (GPU)
& .venv/Scripts/python.exe scripts/train_gpu_robusto.py ^
  --agent SAC --episodes 50 --device cuda

# Terminal 2 (esperar 30 segundos, luego GPU asignarÃ¡)
& .venv/Scripts/python.exe scripts/train_gpu_robusto.py ^
  --agent A2C --episodes 57 --device cuda

# Terminal 3 (CPU mientras GPU estÃ¡ ocupada)
& .venv/Scripts/python.exe scripts/train_gpu_robusto.py ^
  --agent PPO --episo...
```

[Ver cÃ³digo completo en GitHub]bash
# MÃ¡s seguro y controlado
& .venv/Scripts/python.exe scripts/train_gpu_robusto.py ^
  --agent SAC --episodes 50 --device cuda

& .venv/Scripts/python.exe scripts/train_gpu_robusto.py ^
  --agent PPO --episodes 57 --device cuda

& .venv/Scripts/python.exe scripts/train_gpu_robusto.py ^
  --agent A2C --episodes 57 --device cuda
```bash
<!-- markdownlint-enable MD013 -->

**Tiempo Total**: ~11 horas (igual que secuencial, pero control fino)

---

## OPCIÃ“N 3: ENTRENAMIENTO INDIVIDUAL RÃPIDO

**DescripciÃ³n**: Entrena un solo agente para experimentar sin esperar.

### Solo SAC (MÃ¡xima Estabilidad)

<!-- markdownlint-disable MD013 -->
```bash
# 3 horas, mÃ¡xima estabilidad
& .venv/Scripts/python.exe scripts/train_gpu_robusto.py ^
  -...
```

[Ver cÃ³digo completo en GitHub]bash
# 2.5 horas, prototipado rÃ¡pido
& .venv/Scripts/python.exe scripts/train_gpu_robusto.py ^
  --agent A2C --episodes 57 --device cuda
```bash
<!-- markdownlint-enable MD013 -->

**Resultado Esperado**:

- Convergencia: ~15-20 episodios
- Reward Final: -150 a +100
- COâ‚‚: 300-400 kg/episodio
- Baseline funcional

### Solo PPO (Mejor rendimiento)

<!-- markdownlint-disable MD013 -->
```bash
# 5-6 horas, mejor rendimiento final
& .venv/Scripts/python.exe scripts/train_gpu_robusto.py ^
  --agent PPO --episodes 57 --device cuda
```bash
<!-- m...
```

[Ver cÃ³digo completo en GitHub]bash
# ~30 minutos
& .venv/Scripts/python.exe scripts/train_agents_serial.py ^
  --device cuda --episodes 5
```bash
<!-- markdownlint-enable MD013 -->

### Prueba Individual SAC

<!-- markdownlint-disable MD013 -->
```bash
# ~10 minutos
& .venv/Scripts/python.exe scripts/train_gpu_robusto.py ^
  --agent SAC --episodes 5 --device cuda
```bash
<!-- markdownlint-enable MD013 -->

### Prueba Individual PPO

<!-- markdownlint-disable MD013 -->
```bash
# ~15 minutos
& .venv/Scripts/python.exe scripts/train_gpu_robust...
```

[Ver cÃ³digo completo en GitHub]bash
# ~8 minutos
& .venv/Scripts/python.exe scripts/train_gpu_robusto.py ^
  --agent A2C --episodes 5 --device cuda
```bash
<!-- markdownlint-enable MD013 -->

---

## ğŸ“Š MONITOREO Y RESULTADOS

### Archivos de Salida Generados

<!-- markdownlint-disable MD013 -->
```bash
results/
â”œâ”€â”€ SAC/
â”‚   â”œâ”€â”€ checkpoints/
â”‚   â”‚   â”œâ”€â”€ model_episode_10.zip
â”‚   â”‚   â”œâ”€â”€ model_episode_25.zip
â”‚   â”‚   â”œâ”€â”€ model_episode_50.zip (FINAL)
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ logs/
â”‚   â”‚   â”œâ”€â”€ training_log.txt
â”‚   â”‚   â”œâ”€â”€ metrics.csv
â”‚   â”‚   â””â”€â”€ performance...
```

[Ver cÃ³digo completo en GitHub]bash
<!-- markdownlint-enable MD013 -->

### MÃ©tricas Clave a Monitorear

#### 1. Reward Convergencia

<!-- markdownlint-disable MD013 -->
```bash
SAC:
  Episode 1:    -1100  (inicio caÃ³tico)
  Episode 10:   -600   (mejorando)
  Episode 25:   -200   (converging)
  Episode 50:   +100   âœ… (Ã³ptimo)

PPO:
  Episode 1:    -1300  (inicio peor)
  Episode 20:   -400   (mejorando mÃ¡s lento)
  Episode 40:   +50    (convergencia suave)
  Episode 57:   +250   âœ…âœ… (MEJOR)

A2C:
  Episode 1:    -1200  (inicio)
  Episode 15:   -500   (rÃ¡pida mejora)
  Episo...
```

[Ver cÃ³digo completo en GitHub]bash
SAC:
  Initial: ~600 kg/episodio
  Final:   250-350 kg/episodio (EXCELENTE)

PPO:
  Initial: ~620 kg/episodio
  Final:   200-300 kg/episodio (MÃS BAJO!)

A2C:
  Initial: ~600 kg/episodio
  Final:   300-400 kg/episodio (BUENO)
```bash
<!-- markdownlint-enable MD013 -->

#### 3. EV SatisfacciÃ³n

<!-- markdownlint-disable MD013 -->
```bash
SAC:  90-95% (ALTA)
PPO:  88-93% (ALTA)
A2C:  85-90% (BUENA)
```bash
<!-- markdownlint-enable MD013 -->

### Herramientas de Monitoreo

<!-- markdownlint-disable MD013 -->
```bash
# Ver mÃ©tricas en tiempo real
tail -f results/SAC/logs/training_log.txt

# Generar grÃ¡ficos despuÃ©s del entrenamien...
```

[Ver cÃ³digo completo en GitHub]bash
<!-- markdownlint-enable MD013 -->

---

## ğŸ¯ RECOMENDACIÃ“N FINAL

### Para MÃ¡ximo Rendimiento Total

**OpciÃ³n 1 (Secuencial)** â† RECOMENDADO

<!-- markdownlint-disable MD013 -->
```bash
& .venv/Scripts/python.exe scripts/train_agents_serial.py --device cuda --episodes 50
```bash
<!-- markdownlint-enable MD013 -->

- âœ… Simple (un comando)
- âœ… Controlado (no OOM)
- âœ… Completo (todos los agentes)
- â±ï¸ DuraciÃ³n: ~11 horas

### Para MÃ¡xima Velocidad

#### OpciÃ³n 3B (Solo A2C)

<!-- markdownlint-disable MD013 -->
```bash
& .venv/Scripts/python.exe scripts/train_gpu_robusto.py --agent A...
```

[Ver cÃ³digo completo en GitHub]bash
# Entrenar todos 3 agentes
& .venv/Scripts/python.exe scripts/train_agents_serial.py --device cuda --episodes 50

# Luego reentrenar PPO con mÃ¡s episodios
& .venv/Scripts/python.exe scripts/train_gpu_robusto.py --agent PPO --episodes 100 --device cuda
```bash
<!-- markdownlint-enable MD013 -->

- âœ… Todos los agentes entrenados
- âœ… PPO con entrenamiento extra
- â±ï¸ DuraciÃ³n: ~17 horas

---

## âš ï¸ SOLUCIÃ“N DE PROBLEMAS

### Si tienes OOM (Out of Memory)

<!-- markdownlint-disable MD013 -->
```bash
# Reducir batch size para SAC
# Cambiar en sac.py: batch_size = 256 (desde 512)

# O usar CPU para un agente
& .venv/Scripts/python.exe scripts/train_gpu_robust...
```

[Ver cÃ³digo completo en GitHub]bash
# Aumentar learning rate (ligeramente)
# SAC:  1.5e-4 â†’ 2.0e-4
# PPO:  2.0e-4 â†’ 2.5e-4
# A2C:  1.5e-4 â†’ 2.0e-4
```bash
<!-- markdownlint-enable MD013 -->

### Si el reward es muy negativo despuÃ©s de 20 episodios

<!-- markdownlint-disable MD013 -->
```bash
# Checkear normalizaciÃ³n de observaciones
# Checkear pesos multiobjetivo
# Considerar reducir hidden_sizes a (512, 512)
```bash
<!-- markdownlint-enable MD013 -->

---

## ğŸ“ˆ ROADMAP DE ENTRENAMIENTO

<!-- markdownlint-disable MD013 -->
```bash
DÃA 1 (MaÃ±ana):
  ...
```

[Ver cÃ³digo completo en GitHub]bash
<!-- markdownlint-enable MD013 -->

---

## âœ… CHECKLIST PRE-ENTRENAMIENTO

- [ ] Ejecutar `.\verificar_agentes.ps1`
- [ ] Revisar STATUS_CATALIZACION_MAXIMA_POTENCIA.txt
- [ ] Verificar GPU disponible: `nvidia-smi`
- [ ] Tener suficiente espacio en disco (~20 GB para checkpoints)
- [ ] Seleccionar estrategia de entrenamiento
- [ ] Documentar inicio con timestamp
- [ ] Monitorear los primeros 5-10 episodios

---

## ğŸš€ GO TIME

Todos los agentes estÃ¡n optimizados al mÃ¡ximo nivel individual.

#### OpciÃ³n recomendada:

<!-- markdownlint-disable MD013 -->
```bash
& .venv/Scripts/python.exe scripts/train_agents_serial.py --device cuda --episodes 50
```bash
<!-- markdownlint-enable MD013 -->

**Tiempo estimado**: 11 horas  
**Resultado esperado**: 3 agentes entrenados, converging, listos para producciÃ³n

---

**Ãšltima actualizaciÃ³n**: 2026-01-24  
**VersiÃ³n**: MÃXIMA POTENCIA INDIVIDUAL v2.0  
**Estado**: âœ… LISTO PARA ENTRENAR
