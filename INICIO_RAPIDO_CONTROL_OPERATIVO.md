# ğŸš€ INICIO RÃPIDO - Control Operativo Avanzado

**Objetivo**: Mejorar operaciÃ³n del sistema EV (sin cambiar BESS: 2000 kWh)  
**DuraciÃ³n Total**: 10-14 horas  
**Ãšltima ActualizaciÃ³n**: 2026-01-18

---

## âš¡ Comandos Clave

### 1. Capturar Baseline (Sin Control)

```bash
python -m scripts.run_uncontrolled_baseline --config configs/default.yaml
# â±ï¸ ~30 min | Salida: uncontrolled_diagnostics.csv + summary.json
```

### 2. Reentrenar SAC (Con Control Operativo)

```bash
python -m scripts.run_oe3_simulate \
  --config configs/default.yaml \
  --agent sac \
  --experiment retrain_operational \
  --episodes 5 \
  --device cuda
# â±ï¸ ~4-6 horas | Salida: Checkpoint + logs
```

### 3. Comparar Resultados

```bash
python -m scripts.compare_baseline_vs_retrain --config configs/default.yaml
# â±ï¸ ~30 min | Salida: Tabla comparativa + grÃ¡ficos
```

---

## ğŸ“Š MÃ©tricas Esperadas de Mejora

| KPI | Baseline | Esperado | Mejora |
|-----|----------|----------|--------|
| Potencia pico (kW) | 175 | 140 | â†“20% |
| ImportaciÃ³n pico (MWh/aÃ±o) | 1.28 | 0.95 | â†“26% |
| ImportaciÃ³n total (MWh/aÃ±o) | 2.45 | 2.10 | â†“14% |
| SOC mÃ­nimo BESS (%) | 22 | 45 | â†‘103% |
| COâ‚‚ anual (t) | 1,110 | 950 | â†“14% |
| Fairness (ratio) | 1.80 | 1.20 | â†“33% |

---

## ğŸ“ Archivos Generados

### Inputs

```
configs/
â””â”€â”€ default.yaml                          [ACTUALIZADO: +45 lÃ­neas]
    â””â”€â”€ oe2.operational_control (NEW)

src/iquitos_citylearn/oe3/
â”œâ”€â”€ enriched_observables.py                [NUEVO: 310 lÃ­neas]
â””â”€â”€ rewards.py                             [ACTUALIZADO: +180 lÃ­neas]

scripts/
â”œâ”€â”€ run_uncontrolled_baseline.py           [NUEVO: 180 lÃ­neas]
â””â”€â”€ compare_baseline_vs_retrain.py         [NUEVO: 450 lÃ­neas]
```

### Outputs (Generados durante ejecuciÃ³n)

```
outputs/oe3/
â”œâ”€â”€ diagnostics/
â”‚   â”œâ”€â”€ uncontrolled_diagnostics.csv       (8760 rows Ã— 15 cols)
â”‚   â”œâ”€â”€ uncontrolled_summary.json
â”‚   â”œâ”€â”€ sac_retrain_diagnostics.csv
â”‚   â””â”€â”€ sac_retrain_summary.json
â”œâ”€â”€ simulations/
â”‚   â””â”€â”€ sac_retrain_evaluation/
â”‚       â””â”€â”€ sac_simulation_results.json
â””â”€â”€ analysis/
    â”œâ”€â”€ comparison_metrics.csv
    â”œâ”€â”€ comparison_summary.json
    â””â”€â”€ plots/
        â”œâ”€â”€ power_profile.png
        â”œâ”€â”€ soc_evolution.png
        â””â”€â”€ grid_import.png
```

---

## ğŸ”§ ConfiguraciÃ³n de Control Operativo

Definida en `configs/default.yaml`:

```yaml
oe2:
  operational_control:
    peak_hours: [18, 19, 20, 21]          # Horas crÃ­ticas
    valley_hours: [9, 10, 11, 12]         # Horas de bajo consumo
    power_limits_kw:
      playa_motos: 120.0                  # Throttling operativo
      playa_mototaxis: 48.0
      total_aggregate: 150.0
    bess_soc_target:
      normal_hours: 0.60                  # 1200 kWh
      pre_peak_hours: 0.85                # 1700 kWh (cargar antes de pico)
      during_peak_hours: 0.40             # 800 kWh (permitir descarga)
    peak_cost_multiplier: 1.5
    import_penalty_weight: 0.30
    fairness_penalty_weight: 0.15
    soc_reserve_penalty: 0.20
```

---

## ğŸ“š DocumentaciÃ³n Principal

| Documento | PropÃ³sito | PÃ¡ginas |
|-----------|-----------|---------|
| **PLAN_CONTROL_OPERATIVO.md** | Plan completo de 8 fases | 15 |
| **GUIA_IMPLEMENTACION_CONTROL_OPERATIVO.md** | Pasos detallados con validaciones | 40 |
| **RESUMEN_MAESTRO_CAMBIOS.md** | Changelog completo | 25 |
| **INICIO_RAPIDO.md** | Este documento | 5 |

**Lectura recomendada**:

1. ğŸ“– Este documento (5 min)
2. ğŸ“– PLAN_CONTROL_OPERATIVO.md (10 min) - Entender estrategia
3. ğŸš€ GUIA_IMPLEMENTACION_CONTROL_OPERATIVO.md (durante ejecuciÃ³n)
4. ğŸ“Š RESUMEN_MAESTRO_CAMBIOS.md (referencia tÃ©cnica)

---

## ğŸ¯ Proceso de 3 Pasos

### Paso 1: Baseline (40 min)

```bash
# Ejecutar agente sin control
python -m scripts.run_uncontrolled_baseline --config configs/default.yaml

# Validar
python -c "
import pandas as pd
df = pd.read_csv('outputs/oe3/diagnostics/uncontrolled_diagnostics.csv')
print(f'âœ“ {len(df)} timesteps')
print(f'Potencia pico: {df[\"ev_power_total_kw\"].max():.1f} kW')
"
```

### Paso 2: Reentreno (5 horas)

```bash
# Entrenar SAC con penalizaciones operacionales
python -m scripts.run_oe3_simulate \
  --config configs/default.yaml \
  --agent sac \
  --experiment retrain_operational \
  --episodes 5 \
  --device cuda

# Monitorear (en otra terminal)
python monitor_checkpoints.py
```

### Paso 3: AnÃ¡lisis (45 min)

```bash
# Comparar y generar grÃ¡ficos
python -m scripts.compare_baseline_vs_retrain --config configs/default.yaml

# Ver resultados
python -c "
import pandas as pd
df = pd.read_csv('outputs/oe3/analysis/comparison_metrics.csv')
print(df.to_string(index=False))
"
```

---

## ğŸ” Validaciones RÃ¡pidas

### DespuÃ©s de Paso 1 (Baseline)

```bash
âœ… outputs/oe3/diagnostics/uncontrolled_diagnostics.csv existe (8760 rows)
âœ… Potencia pico entre 170-180 kW
âœ… ImportaciÃ³n entre 2.4-2.5 M kWh
âœ… SOC mÃ­nimo entre 20-25%
```

### DespuÃ©s de Paso 2 (Reentreno)

```bash
âœ… outputs/oe3/checkpoints/sac_retrain_operational_final.zip existe
âœ… Logs muestran convergencia de rewards
âœ… Entrenamiento completÃ³ N episodes sin excepciones
```

### DespuÃ©s de Paso 3 (AnÃ¡lisis)

```bash
âœ… comparison_metrics.csv tiene 8+ mÃ©tricas
âœ… GrÃ¡ficos generados (power_profile.png, soc_evolution.png, grid_import.png)
âœ… SAC mejora â‰¥80% de mÃ©tricas vs baseline
```

---

## ğŸ“ˆ MÃ©todos de Mejora Implementados

### 1ï¸âƒ£ Throttling de Potencia

Limitar carga activa por playa:

- **Motos**: 120 kW (de 224 kW mÃ¡x) = -46%
- **Mototaxis**: 48 kW (sin cambio)
- **Agregado**: 150 kW (de 272 kW mÃ¡x) = -45%

### 2ï¸âƒ£ Reserva DinÃ¡mica de SOC

Mantener energÃ­a BESS para pico:

- **Normal (0-15h, 22h)**: SOC â‰¥ 60%
- **Pre-pico (16-17h)**: SOC â‰¥ 85% â† Cargar BESS
- **Pico (18-21h)**: SOC â‰¥ 40% â† Usar BESS

### 3ï¸âƒ£ Penalizaciones en Rewards

Entrenar agente para cumplir restricciones:

```python
penalizar: -max(0, soc_target - soc_actual)       # SOC bajo
penalizar: -max(0, p_total - 150_kW)              # Pico alto
penalizar: -(ratio_fairness - 1.0) / 2            # Desequilibrio
penalizar: -max(0, importaciÃ³n - 50) / 100        # ImportaciÃ³n pico
```

---

## âš ï¸ Restricciones de Seguridad

âœ… **NO se modifica**:

- BESS capacidad: 2,000 kWh (fijo)
- BESS potencia: 1,200 kW (fijo)
- Solar potencia: 4,162 kWp (fijo)
- Chargers instalados: 272 kW (fijo)

âœ… **Controlable**:

- LÃ­mites de carga activa (throttling)
- Reserva de energÃ­a (scheduling)
- Pesos de recompensa (RL)

---

## ğŸ› Troubleshooting RÃ¡pido

### Error: "ModuleNotFoundError: enriched_observables"

```bash
export PYTHONPATH="${PYTHONPATH}:$(pwd)/src"
```

### Error: "CUDA out of memory"

```bash
# Usar CPU
python -m scripts.run_oe3_simulate ... --device cpu
```

### Reentreno lento

```bash
# Reducir episodes en default.yaml
oe3:
  evaluation:
    sac:
      episodes: 2  # De 5 a 2
```

### Resultados no mejoran

```bash
# Aumentar penalizaciÃ³n operacional
oe2:
  operational_control:
    import_penalty_weight: 0.50  # De 0.30 a 0.50
    soc_reserve_penalty: 0.30    # De 0.20 a 0.30
```

---

## ğŸ“ Soporte

**Preguntas sobre**:

- ğŸ“– Estrategia general â†’ PLAN_CONTROL_OPERATIVO.md
- ğŸ”§ ImplementaciÃ³n paso a paso â†’ GUIA_IMPLEMENTACION_CONTROL_OPERATIVO.md
- ğŸ“ Cambios tÃ©cnicos â†’ RESUMEN_MAESTRO_CAMBIOS.md
- ğŸ’» CÃ³digo â†’ Ver docstrings en mÃ³dulos

**Validar instalaciÃ³n**:

```bash
python -c "
from iquitos_citylearn.oe3.enriched_observables import OperationalConstraints
from iquitos_citylearn.oe3.rewards import create_iquitos_reward_weights
from scripts._common import load_all
cfg, _ = load_all('configs/default.yaml')
print('âœ… Todo OK - Listo para ejecutar')
"
```

---

## ğŸ“Š Dashboard de Progreso

```
FASE 1: Capturar Baseline                        âœ… COMPLETADA
FASE 2: Enriquecer Observables                   âœ… COMPLETADA
FASE 3: Actualizar Recompensas                   âœ… COMPLETADA
FASE 4: Implementar Constraints                  âœ… COMPLETADA
FASE 5: Reentrenar SAC                           â³ LISTA (5-6h)
FASE 6: Evaluar SAC                              â³ LISTA (30min)
FASE 7: Comparar Resultados                      â³ LISTA (45min)
FASE 8: DocumentaciÃ³n Final                      â³ LISTA (30min)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total Tiempo EjecuciÃ³n Computacional             â‰ˆ 6-8 horas
Total Tiempo Humano (setup + validaciÃ³n)         â‰ˆ 2-3 horas
```

---

## ğŸ“ Conceptos Clave

- **Throttling**: Limitar potencia sin cambiar capacidad
- **Reserva dinÃ¡mica**: Mantener energÃ­a BESS para horas crÃ­ticas
- **Fairness**: Equilibrio de carga entre diferentes tipos de vehÃ­culos
- **PenalizaciÃ³n**: ReducciÃ³n de recompensa por incumplimiento de restricciones
- **SAC**: Soft Actor-Critic (algoritmo RL usado para reentreno)

---

## ğŸ”— Links RÃ¡pidos

| Recurso | UbicaciÃ³n |
|---------|-----------|
| Config de sistema | `configs/default.yaml` |
| Control operativo | `oe2.operational_control` |
| Observables enriquecidos | `src/iquitos_citylearn/oe3/enriched_observables.py` |
| Recompensas mejoradas | `src/iquitos_citylearn/oe3/rewards.py` |
| Agentes | `src/iquitos_citylearn/oe3/agents/` |
| Salidas | `outputs/oe3/` |

---

**Â¿Listo para comenzar?**

ğŸ‘‰ **PrÃ³ximo paso**: Ejecutar Paso 1

```bash
python -m scripts.run_uncontrolled_baseline --config configs/default.yaml
```

âœ… **Tiempo estimado**: 30 minutos  
ğŸ“Š **Resultado**: baseline_diagnostics.csv + summary.json

---

**Documento**: INICIO_RAPIDO.md v1.0  
**Fecha**: 2026-01-18  
**Estado**: ğŸŸ¢ LISTO PARA EJECUTAR
