#!/usr/bin/env python3
"""
LIMPIEZA DE DUPLICADOS: Chargers Dataset v5.2
==============================================

Script para eliminar filas completamente duplicadas del dataset.
Mantiene el dataset Ã­ntegro (8,760 horas = 365 dÃ­as Ã— 24 horas)
"""

import pandas as pd
from pathlib import Path
from datetime import datetime
import shutil

# Rutas
ORIGINAL_PATH = Path("data/oe2/chargers/chargers_ev_ano_2024_v3.csv")
BACKUP_PATH = Path("data/oe2/chargers/chargers_ev_ano_2024_v3.BACKUP_ANTES_LIMPIEZA.csv")
CLEANED_PATH = Path("data/oe2/chargers/chargers_ev_ano_2024_v3.csv")  # Sobrescribir

print("\n" + "="*90)
print("ğŸ§¹ LIMPIEZA DE DUPLICADOS: Chargers Dataset v5.2")
print("="*90)

# Cargar dataset original
print(f"\nğŸ“‚ Cargando dataset: {ORIGINAL_PATH}")
df = pd.read_csv(ORIGINAL_PATH, index_col=0, parse_dates=[0])
print(f"âœ“ Dimensiones originales: {df.shape[0]:,} filas Ã— {df.shape[1]:,} columnas")

# Hacer backup DEL ORIGINAL (con filas duplicadas)
print(f"\nğŸ’¾ Creando backup del dataset original...")
shutil.copy(ORIGINAL_PATH, BACKUP_PATH)
print(f"âœ“ Backup: {BACKUP_PATH}")

# Detectar duplicados
print(f"\nğŸ” Analizando duplicados...")
dup_mask = df.duplicated(keep=False)  # Marca TODAS las duplicadas (no solo las segundas)
dup_count_total = dup_mask.sum()
dup_unique = df.duplicated().sum()  # Solo las segundas y posteriores

print(f"âœ“ Total filas que son duplicadas: {dup_count_total}")
print(f"âœ“ Total filas a eliminar: {dup_unique}")

if dup_count_total > 0:
    # Mostrar ejemplo
    dup_df = df[dup_mask].head(3)
    print(f"\nğŸ“‹ Ejemplo de filas duplicadas:")
    print(dup_df.iloc[:, :5].to_string())

# Eliminar duplicados (mantiene la primera ocurrencia)
print(f"\nğŸ§¹ Eliminando duplicados...")
df_cleaned = df.drop_duplicates(keep='first')
print(f"âœ“ Dimensiones despuÃ©s de limpieza: {df_cleaned.shape[0]:,} filas Ã— {df_cleaned.shape[1]:,} columnas")

# Verificar integridad despuÃ©s de limpieza
print(f"\nâœ… VerificaciÃ³n post-limpieza:")
print(f"   Filas: {df_cleaned.shape[0]:,}")
print(f"   Columnas: {df_cleaned.shape[1]:,}")
print(f"   PerÃ­odo: {df_cleaned.index.min()} â†’ {df_cleaned.index.max()}")
print(f"   AÃ±o: {df_cleaned.index.year.unique()}")
print(f"   Duplicados restantes: {df_cleaned.duplicated().sum()}")

# Validar que no falta energÃ­a
energy_original = df["ev_energia_total_kwh"].sum()
energy_cleaned = df_cleaned["ev_energia_total_kwh"].sum()
print(f"\n   EnergÃ­a original:  {energy_original:>12,.0f} kWh")
print(f"   EnergÃ­a limpia:    {energy_cleaned:>12,.0f} kWh")
print(f"   PÃ©rdida: {((energy_original - energy_cleaned) / energy_original * 100):.4f}%")

# Guardar dataset limpio (sobrescribir el original)
print(f"\nğŸ’¾ Guardando dataset limpio...")
df_cleaned.to_csv(CLEANED_PATH)
print(f"âœ“ Guardado: {CLEANED_PATH}")

# Resumen
print(f"\n" + "="*90)
print("âœ… LIMPIEZA COMPLETADA")
print("="*90)
print(f"\nResumen:")
print(f"   âŒ Duplicados eliminados: {dup_unique:,} filas")
print(f"   âœ… Dataset limpio: {df_cleaned.shape[0]:,} filas")
print(f"   âœ… Columnas intactas: {df_cleaned.shape[1]:,}")
print(f"   âœ… Backup guardado: {BACKUP_PATH}")
print(f"   âœ… Dataset limpio actualizado: {CLEANED_PATH}")

print(f"\nğŸ’¡ Si necesitas revertir, copia de {BACKUP_PATH} de vuelta al original")
print("="*90 + "\n")
