# SAC Divergencia: ExplicaciÃ³n Visual para Entender QUÃ‰ PasÃ³

## El Escenario: Observaciones de EnergÃ­a

Imagina que SAC estÃ¡ viendo "pantallazos" de energÃ­a en Iquitos:

```
REALIDAD:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TIMESTEP 1: DÃ­a nublado (solar bajo)       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Grid Import:     6,000,000 kWh/dÃ­a   â”‚
â”‚ PV GeneraciÃ³n:   2,000,000 kWh/dÃ­a   â”‚
â”‚ Building Load:   4,500,000 kWh/dÃ­a   â”‚
â”‚ EV Demand:       50 kWh constante    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

LO QUE DEBERÃA VER LA RED NEURONAL (Normal normalization):
[6000, 2000, 4500, 50] 
  â†“ normalize (mean=0, std=1)
[-1.2, -0.8, -0.5, 0.0]  â† RICAS EN INFORMACIÃ“N, DISTINTAS

LO QUE VE CON clip_obs=5.0 (Â¡NUESTRO PROBLEMA!):
[6000, 2000, 4500, 50]
  â†“ prescale 0.001
[6, 2, 4.5, 0.05]
  â†“ normalize (stats malas en Episode 1)
[???, ???, ???, ???]  â† NORMALIZACIÃ“N DEFECTUOSA
  â†“ clip to [-5.0, +5.0]
[5.0, 5.0, 5.0, -5.0]  â† âš ï¸ INFORMACIÃ“N DESTRUIDA


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TIMESTEP 2: DÃ­a soleado (solar alto)       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Grid Import:     3,000,000 kWh/dÃ­a   â”‚
â”‚ PV GeneraciÃ³n:   7,500,000 kWh/dÃ­a   â”‚
â”‚ Building Load:   4,500,000 kWh/dÃ­a   â”‚
â”‚ EV Demand:       50 kWh constante    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

LO QUE DEBERÃA VER (Normal):
[3000, 7500, 4500, 50]
  â†“ normalize
[-2.5, +1.2, -0.5, 0.0]  â† CLARAMENTE DIFERENTE DE TIMESTEP 1

LO QUE VE CON clip_obs=5.0:
[3000, 7500, 4500, 50]
  â†“ prescale 0.001
[3, 7.5, 4.5, 0.05]
  â†“ normalize (stats aÃºn malas)
[???, ???, ???, ???]
  â†“ clip to [-5.0, +5.0]
[5.0, 5.0, 5.0, -5.0]  â† âš ï¸ IDÃ‰NTICA A TIMESTEP 1!!!
```

## La Tragedia: Red Neuronal Incapaz de Aprender

```python
ENTRADA TIMESTEP 1 (nublado):   [5.0, 5.0, 5.0, -5.0]  â†’ AcciÃ³n: random
ENTRADA TIMESTEP 2 (soleado):   [5.0, 5.0, 5.0, -5.0]  â† IDÃ‰NTICA!
                                  â†“
              Â¿CÃ³mo puede la red aprender acciones diferentes?

Backprop:
  âˆ‚Loss/âˆ‚Î¸ = 0 (gradientes casi cero porque entradas idÃ©nticas)
  Î¸_nuevo = Î¸ - Î± * 0 = Î¸ (network parameters NO CAMBIAN)
  
RESULTADO: Red neuronal CONGELADA, no puede aprender nada
```

## La Secundaria: EntropÃ­a Bloqueada

Mientras la red intentaba aprender (sin lograrlo), pasÃ³ esto:

```
Episode 1:
â”œâ”€ Policy aleatoria
â”œâ”€ Algunos timesteps: agente accidentalmente usa solar
â”‚  â””â”€ Reward: -50,000 (aÃºn negativo, pero menos que "ignora solar")
â”œâ”€ Otros timesteps: agente ignora solar
â”‚  â””â”€ Reward: -100,000 (muy negativo)
â””â”€ Network notarÃ¡: "ignora solar" parece mejor (menos negativo)

Episode 2:
â”œâ”€ EntropÃ­a = 0.1 (explora solo 10%)
â”œâ”€ Network favorece "ignora solar" (porque reward fue menos malo)
â”œâ”€ 90% del tiempo: policy = "ignora solar"
â”œâ”€ 10% del tiempo: policy = exploraciÃ³n aleatoria
â””â”€ Pero clip_obs=5.0 hace que NO PUEDA ver diferencias para aprender mejor

Episode 3:
â”œâ”€ Policy completamente convergida a "SIEMPRE MAXIMIZA GRID"
â”œâ”€ EntropÃ­a decay muy lento (1e-5) â†’ Still 0.08
â”œâ”€ ExploraciÃ³n insuficiente â†’ No hay escape de este mÃ­nimo local
â””â”€ RED DIVIDIDA: Grid Import 13.2M kWh (vs optimal 7M)
```

## Las 4 Causas Trabajando Juntas (Efecto Multiplicador)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CLIP_OBS = 5.0                                              â”‚
â”‚ â””â”€ Efecto: Observaciones â†’ [5, 5, 5, ...] (todas idÃ©nticas) â”‚
â”‚    Consecuencia: Red neuronal NO PUEDE VER DIFERENCIAS     â”‚
â”‚                                                              â”‚
â”‚    PERO AÃšN PODRÃA APRENDER SI:                            â”‚
â”‚    â”œâ”€ EntropÃ­a alta (explora acciones diferentes)           â”‚
â”‚    â””â”€ Gradientes grandes (network updates significativas)   â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ENT_COEF_INIT = 0.1                                         â”‚
â”‚ â””â”€ Efecto: Explora solo 10% del tiempo                      â”‚
â”‚    Consecuencia: Si encuentra "algo bueno" (ignora solar),  â”‚
â”‚                  converge rÃ¡pido sin explorar alternativas  â”‚
â”‚                                                              â”‚
â”‚    PERO AÃšN PODRÃA APRENDER SI:                            â”‚
â”‚    â”œâ”€ EntropÃ­a decae lentamente (tiempo para explorar)      â”‚
â”‚    â””â”€ Gradientes grandes permiten cambios de policy rÃ¡pido  â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ENT_COEF_LR = 1e-5                                          â”‚
â”‚ â””â”€ Efecto: EntropÃ­a se adapta cada 100+ episodios           â”‚
â”‚    Consecuencia: No cambia entropÃ­a en 3 episodios de test  â”‚
â”‚    (cambio: 0.1 â†’ 0.1 + 3*0.087 â‰ˆ 0.26, barely noticeable)â”‚
â”‚                                                              â”‚
â”‚    PERO AÃšN PODRÃA APRENDER SI:                            â”‚
â”‚    â””â”€ Gradientes grandes hacen updates eficientes            â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MAX_GRAD_NORM = 0.5                                         â”‚
â”‚ â””â”€ Efecto: Gradientes clipeados + lr bajo = micro-updates   â”‚
â”‚    Consecuencia: Network parameters cambian ~1e-6 por paso  â”‚
â”‚    (cambio imperceptible, network stuck en initialization)  â”‚
â”‚                                                              â”‚
â”‚    RESULTADO FINAL: âŒ DIVERGENCIA GARANTIZADA               â”‚
â”‚    â””â”€ Network no aprende (clip_obs)                         â”‚
â”‚    â””â”€ Network no explora (ent bajo)                         â”‚
â”‚    â””â”€ Network no adapta (ent_lr bajo)                       â”‚
â”‚    â””â”€ Network no actualiza (grad norm bajo)                 â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## AnalogÃ­a: Ceguera Combinada

Imagina que intentas aprender a navegar un auto:

```
PERSONA NORMAL:
â”œâ”€ Ves carreteras claramente (clip_obs OK)
â”œâ”€ Exploras diferentes rutas (entropÃ­a OK)
â”œâ”€ Aprendes rÃ¡pido (gradientes OK)
â””â”€ RESULTADO: Eventualmente encuentras ruta Ã³ptima

PERSONA CON TODOS LOS PROBLEMAS DE SAC:
â”œâ”€ Todo ve "gris" - no distingue carreteras (clip_obs=5.0)
â”œâ”€ Solo prueba 10% de las rutas (entropÃ­a=0.1)
â”œâ”€ Aprende MUY lentamente (ent_lr=1e-5, grad norm=0.5)
â”œâ”€ DespuÃ©s 3 intentos: converge a "siempre girar izquierda"
â””â”€ RESULTADO: Divergencia garantizada
```

---

## âœ… CÃ³mo Los Fixes Lo Resuelven

### FIX 1: clip_obs = 100.0
```
Ahora ve:
TIMESTEP NUBLADO:   [-1.2, -0.8, -0.5, 0.0]
TIMESTEP SOLEADO:   [-2.5, +1.2, -0.5, 0.0]  â† DIFERENTES!

Red neuronal puede aprender:
"Cuando PV alta (pos values) â†’ acciÃ³n X"
"Cuando PV baja (neg values) â†’ acciÃ³n Y"
```

### FIX 2: ent_coef_init = 0.5
```
Antes: Explora solo 10% â†’ Converge rÃ¡pido a "ignora solar"
Ahora: Explora 50% â†’ Tiene muchos timesteps para probar solar control

Resultado: Network descubre "usar solar = mejor reward"
```

### FIX 3: ent_coef_lr = 1e-3
```
Antes: EntropÃ­a NO CAMBIA (0.1 â†’ 0.26 despuÃ©s de 3 episodios)
Ahora: EntropÃ­a adapta por-episodio (0.5 â†’ 0.4 â†’ 0.35 ... segÃºn task)

Resultado: SAC se auto-ajusta: "Â¿Necesito mÃ¡s exploraciÃ³n? â†‘ Aumenta"
```

### FIX 4: max_grad_norm = 10.0
```
Antes: Updates ~1e-6 (network frozen)
Ahora: Updates ~1e-4 (network actually learns)

Combined with fixes 1-3:
Network PUEDE VER DIFERENCIAS (fix 1)
QUIERE explorar (fix 2)
SE ADAPTA rÃ¡pido (fix 3)
APRENDE rÃ¡pido (fix 4)
```

---

## ğŸ¯ Impacto Esperado DespuÃ©s de Fixes

**Episodio 1 (antes)**: Random policy â†’ Grid 13.2M  
**Episodio 1 (ahora)**: Random policy â†’ Grid 13.2M (aÃºn no sabe)  

**Episodio 2 (antes)**: Stuck en "ignora solar" â†’ Grid 13.2M  
**Episodio 2 (ahora)**: Explora solar â†’ Grid 10-11M (mejora!)  

**Episodio 3 (antes)**: Converged en "ignora solar" â†’ Grid 13.2M  
**Episodio 3 (ahora)**: Aprendiendo solar â†’ Grid 8-9M (mucho mejor)  

**Episodio 5 (antes)**: Stuck â†’ Grid 13.2M  
**Episodio 5 (ahora)**: Converging en optimal â†’ Grid 7-7.5M (casi PPO)  

**Episodio 50 (expected)**: SAC should match PPO â†’ Grid 7.2M, COâ‚‚ -23%

---

## ğŸ“‹ Archivos de Referencia

1. **DIAGNOSTICO_SAC_DIVERGENCIA_2026_02_02.md** - AnÃ¡lisis tÃ©cnico profundo
2. **RESUMEN_CAUSAS_SAC_Y_FIXES.md** - Detalle por cada causa + soluciÃ³n
3. **QUICK_REFERENCE_SAC_DIVERGENCIA.txt** - Quick summary ejecutivo

**Todos en**: `d:\diseÃ±opvbesscar\`

El cÃ³digo corregido estÃ¡ en: `src/iquitos_citylearn/oe3/agents/sac.py` (lÃ­neas 153, 154, 161, 479)
