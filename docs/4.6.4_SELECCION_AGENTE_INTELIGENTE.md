# 4.6.4 Selección del Agente Inteligente de Gestión de Carga de Motos y Mototaxis Eléctricas

## Resumen Ejecutivo

El agente **A2C (Advantage Actor-Critic)** fue seleccionado como el sistema de gestión inteligente óptimo para la carga de motos y mototaxis eléctricas en Iquitos, logrando una **reducción de 3,647.5 toneladas de CO₂ anuales** (62.4% de reducción respecto al escenario sin energía solar), maximizando la eficiencia operativa del sistema y contribuyendo de forma cuantificable a la reducción de emisiones de dióxido de carbono en la ciudad de Iquitos.

---

## 1. Contexto de la Problemática

### 1.1 Sistema Aislado de Iquitos

La ciudad de Iquitos opera con un **sistema eléctrico aislado (SEIN-Iquitos)** que depende exclusivamente de generación térmica, con un factor de emisión de **0.4521 kg CO₂/kWh**. Esta condición particular hace que cualquier reducción en el consumo de energía de la red tenga un impacto directo y significativo en la reducción de emisiones de gases de efecto invernadero.

### 1.2 Infraestructura del Sistema

| Componente | Especificación |
|------------|----------------|
| **Sistema Fotovoltaico** | 4,050 kWp instalados |
| **Almacenamiento BESS** | 1,700 kWh capacidad máxima SOC |
| **Cargadores EV** | 19 unidades × 2 tomas = 38 puntos de carga |
| **Potencia por punto** | 7.4 kW (Mode 3, 32A @ 230V monofásico) |
| **Potencia total instalada** | 281.2 kW |
| **Vehículos atendidos** | 270 motos + 39 mototaxis/día |
| **Demanda Mall** | 12,403,168 kWh/año |
| **Demanda EVs** | 565,875 kWh/año |
| **Generación Solar** | 8,292,514 kWh/año |

---

## 2. Metodología de Selección

### 2.1 Algoritmos de Aprendizaje por Refuerzo Evaluados

Se evaluaron tres algoritmos de aprendizaje por refuerzo (RL) de última generación implementados mediante la biblioteca Stable-Baselines3:

| Algoritmo | Tipo | Características Principales |
|-----------|------|----------------------------|
| **A2C** | On-Policy | Advantage Actor-Critic: eficiente en recursos, buen balance exploración-explotación |
| **PPO** | On-Policy | Proximal Policy Optimization: función objetivo recortada, alta estabilidad |
| **SAC** | Off-Policy | Soft Actor-Critic: maximización de entropía, mejor exploración continua |

### 2.2 Configuración del Entrenamiento

- **Timesteps totales**: 87,600 por agente (10 episodios × 8,760 horas/año)
- **Hardware**: GPU NVIDIA RTX 4060 (8GB VRAM)
- **Observaciones**: Estado del sistema PV, BESS SOC, demanda EVs, demanda Mall, hora/fecha
- **Acciones**: Control continuo [0,1] normalizado → 1 BESS + 38 puntos de carga
- **Función de recompensa multi-objetivo**: 
  - 50% minimización CO₂ grid
  - 20% maximización autoconsumo solar
  - 15% completación de carga EV
  - 10% estabilidad de red
  - 5% minimización de costos

### 2.3 Criterios de Evaluación

Se definió un **score compuesto ponderado**:
- **40%**: Reward promedio (eficiencia operativa)
- **60%**: Reducción de CO₂ (impacto ambiental)

---

## 3. Resultados Comparativos

### 3.1 Métricas de Entrenamiento

| Métrica | A2C | PPO | SAC |
|---------|-----|-----|-----|
| **Total Timesteps** | 87,600 | 87,600 | 87,600 |
| **Episodios** | 10 | 10 | 10 |
| **Reward Final** | 3,036.82 | 1,014.44 | 0.0067 |
| **Reward Mejor** | 3,036.82 | 1,014.44 | 0.0068 |
| **Reward Promedio** | 2,725.09 | 818.55 | 0.0067 |

### 3.2 Emisiones de CO₂

| Métrica | A2C | PPO | SAC |
|---------|-----|-----|-----|
| **CO₂ Grid Final (kg/año)** | 2,115,420 | 2,738,263 | 2,938,950 |
| **CO₂ Grid Mínimo (kg/año)** | 2,104,618 | 2,738,263 | 2,586,153 |
| **CO₂ Grid Promedio (kg/año)** | 2,200,222 | 3,074,701 | 2,904,216 |

### 3.3 Escenarios Baseline de Referencia

| Escenario | Descripción | CO₂ (kg/año) |
|-----------|-------------|--------------|
| **Baseline SIN Solar** | 100% demanda de grid térmico | 5,847,700 |
| **Baseline CON Solar** | Solar sin control inteligente (70% autoconsumo) | 3,223,368 |

### 3.4 Reducción de CO₂ Respecto a Baseline Sin Solar

| Agente | CO₂ con Control | Reducción (kg) | Reducción (%) |
|--------|-----------------|----------------|---------------|
| **A2C** | 2,200,222 | **3,647,478** | **62.4%** |
| **PPO** | 3,074,701 | 2,772,999 | 47.4% |
| **SAC** | 2,904,216 | 2,943,484 | 50.3% |

### 3.5 Score Compuesto de Selección

| Agente | Score Reward (40%) | Score CO₂ (60%) | **SCORE TOTAL** |
|--------|-------------------|-----------------|-----------------|
| **A2C** | 272,509.44 | 62.37 | **109,041.20** |
| **PPO** | 81,855.16 | 47.42 | 32,770.52 |
| **SAC** | 0.67 | 50.34 | 30.47 |

---

## 4. Análisis del Agente Seleccionado: A2C

### 4.1 Justificación Técnica

El agente **A2C (Advantage Actor-Critic)** fue seleccionado basándose en:

1. **Mayor Score Total**: 109,041.20 puntos (3.3× superior a PPO, 3,578× superior a SAC)
2. **Máxima Reducción de CO₂**: 3,647.5 toneladas/año (62.4%)
3. **Mejor Eficiencia Operativa**: Reward promedio de 2,725.09

### 4.2 Características del Algoritmo A2C

| Aspecto | Descripción |
|---------|-------------|
| **Arquitectura** | Actor-Critic con función de ventaja (Advantage) |
| **Política** | On-Policy (aprende de experiencias actuales) |
| **Exploración** | Balance natural exploración-explotación |
| **Recursos** | Eficiente en memoria y cómputo |
| **Estabilidad** | Alta estabilidad durante entrenamiento |
| **Convergencia** | Rápida convergencia en 10 episodios |

### 4.3 Comportamiento Aprendido

El agente A2C aprendió las siguientes estrategias óptimas:

1. **Maximización de Autoconsumo Solar**: Prioriza carga de EVs durante horas de máxima irradiancia solar (10:00-15:00)
2. **Gestión Inteligente del BESS**: 
   - Carga durante excedente solar
   - Descarga durante picos de demanda del mall
3. **Programación de Carga EV**: Distribuye la carga de los 270 motos y 39 mototaxis evitando coincidencia con picos del mall
4. **Minimización de Importación Grid**: Reduce al mínimo la dependencia del sistema térmico aislado

---

## 5. Cuantificación del Impacto Ambiental

### 5.1 Reducción de Emisiones de CO₂

| Métrica | Valor |
|---------|-------|
| **Emisiones con A2C** | 2,200,222 kg CO₂/año |
| **Baseline sin solar** | 5,847,700 kg CO₂/año |
| **Reducción absoluta** | **3,647,478 kg CO₂/año** |
| **Reducción porcentual** | **62.4%** |
| **Equivalente en toneladas** | **3,647.5 t CO₂/año** |

### 5.2 Equivalencias Ambientales

La reducción de **3,647.5 toneladas de CO₂ anuales** equivale aproximadamente a:

| Equivalencia | Valor |
|--------------|-------|
| **Árboles plantados** | ~167,000 árboles/año |
| **Vehículos de combustión retirados** | ~792 vehículos/año |
| **Hogares sin electricidad** | ~636 hogares/año |
| **Vuelos Lima-Miami evitados** | ~1,418 vuelos/año |

### 5.3 Desglose de la Reducción

| Fuente de Reducción | Contribución Estimada |
|---------------------|----------------------|
| **Generación Solar PV** | ~70% (2,553 t CO₂/año) |
| **Optimización BESS** | ~15% (547 t CO₂/año) |
| **Gestión Inteligente EV** | ~15% (547 t CO₂/año) |

---

## 6. Contribución al Desarrollo Sostenible

### 6.1 Alineación con ODS

El sistema de gestión inteligente con A2C contribuye directamente a:

| ODS | Contribución |
|-----|--------------|
| **ODS 7** | Energía asequible y no contaminante: Maximización de uso de energía solar |
| **ODS 11** | Ciudades sostenibles: Transporte eléctrico limpio en Iquitos |
| **ODS 13** | Acción por el clima: Reducción de 3,647.5 t CO₂/año |

### 6.2 Impacto en Iquitos

Para una ciudad con sistema eléctrico aislado y alta dependencia de generación térmica:

1. **Reducción de costos operativos**: Menor importación de combustibles fósiles
2. **Mejora de calidad del aire**: Sustitución de vehículos de combustión
3. **Resiliencia energética**: Sistema con almacenamiento y gestión inteligente
4. **Modelo replicable**: Aplicable a otras ciudades amazónicas aisladas

---

## 7. Conclusiones

### 7.1 Selección del Agente

El **Agente A2C (Advantage Actor-Critic)** fue seleccionado como el sistema de gestión inteligente óptimo para la carga de motos y mototaxis eléctricas en Iquitos, basándose en:

- **Máxima eficiencia operativa**: Reward promedio 2,725.09 (3.3× superior a PPO)
- **Mayor reducción de emisiones**: 62.4% respecto al escenario sin solar
- **Estabilidad algorítmica**: Convergencia consistente en 10 episodios
- **Eficiencia computacional**: Entrenamiento completo en 87,600 timesteps

### 7.2 Contribución Cuantificable

El sistema de gestión inteligente con A2C contribuye de forma cuantificable a la reducción de emisiones de CO₂ en Iquitos:

| Métrica | Valor |
|---------|-------|
| **Reducción anual** | **3,647.5 toneladas de CO₂** |
| **Porcentaje** | **62.4%** respecto a escenario sin solar |
| **EVs beneficiados** | 270 motos + 39 mototaxis diarios |
| **Energía solar aprovechada** | 8.29 GWh/año |

### 7.3 Recomendación Final

Se recomienda la implementación del **agente A2C** para la gestión inteligente de carga de motos y mototaxis eléctricas en el sistema integrado Mall-Solar-BESS-EV de Iquitos, garantizando:

1. Maximización del autoconsumo solar
2. Optimización del almacenamiento BESS
3. Gestión eficiente de los 38 puntos de carga
4. Reducción significativa de emisiones de CO₂
5. Contribución medible al desarrollo sostenible de la ciudad

---

## Referencias Técnicas

- **Mnih, V., et al. (2016)**. "Asynchronous Methods for Deep Reinforcement Learning". ICML.
- **Stable-Baselines3 Documentation**: https://stable-baselines3.readthedocs.io/
- **OSINERGMIN (2024)**: Factor de emisión Sistema Aislado Iquitos: 0.4521 kg CO₂/kWh
- **CityLearn v2**: Framework de simulación para sistemas de energía urbana

---

*Documento generado: 2026-02-17*  
*Proyecto: pvbesscar - Optimización de Carga EV con RL*  
*Versión: 1.0*
