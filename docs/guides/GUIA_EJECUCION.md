# üöÄ Gu√≠a de Ejecuci√≥n - PVBESSCAR

## Descripci√≥n General

Este documento explica c√≥mo ejecutar el sistema de optimizaci√≥n de carga EV con Solar PV + BESS mediante Reinforcement Learning utilizando el nuevo punto de entrada unificado `ejecutar.py`.

## Requisitos del Sistema

### Hardware Recomendado
- **CPU**: 8+ cores (Intel i7/i9 o AMD Ryzen 7/9)
- **RAM**: 16 GB m√≠nimo, 32 GB recomendado
- **GPU**: NVIDIA RTX 4060 o superior (opcional pero recomendado)
  - 15-30 min training con GPU
  - 2-10 horas training con CPU
- **Almacenamiento**: 50 GB libres

### Software
- **Python**: 3.11 (recomendado) o 3.12
- **Sistema Operativo**: Windows 10/11, Linux (Ubuntu 20.04+), macOS 12+
- **CUDA**: 11.8+ (si se usa GPU NVIDIA)

## Instalaci√≥n Paso a Paso

### 1. Clonar el Repositorio

```bash
git clone https://github.com/Mac-Tapia/dise-opvbesscar.git
cd dise-opvbesscar
```

### 2. Crear Entorno Virtual

**Windows:**
```powershell
python -m venv .venv
.venv\Scripts\activate
```

**Linux/macOS:**
```bash
python3 -m venv .venv
source .venv/bin/activate
```

### 3. Instalar Dependencias

**Solo CPU (b√°sico):**
```bash
pip install -r requirements.txt
```

**Con GPU NVIDIA (recomendado para entrenamiento):**
```bash
pip install -r requirements.txt
pip install -r requirements-training.txt
```

### 4. Verificar Instalaci√≥n

```bash
python ejecutar.py --validate
```

Salida esperada:
```
================================================================================
üöÄ PVBESSCAR - Optimizaci√≥n de Carga EV con RL
================================================================================

[1/4] Verificando versi√≥n de Python...
  ‚úì Python 3.11.x (CORRECTO)

[2/4] Verificando dependencias...
  ‚úì numpy
  ‚úì pandas
  ‚úì torch
  ‚úì gymnasium
  ‚úì stable_baselines3
  ‚úì yaml

[3/4] Verificando datasets OE2...
  ‚úì Solar: data/interim/oe2/solar/pv_generation_timeseries.csv
  ‚úì Chargers: data/interim/oe2/chargers/chargers_hourly_dataset.csv
  ‚úì BESS: data/interim/oe2/bess/bess_hourly_dataset_2024.csv
  ‚úì Mall: data/interim/oe2/mall/mall_demand_hourly.csv

[4/4] Verificando entorno de ejecuci√≥n...
  ‚úì GPU disponible: NVIDIA GeForce RTX 4060

‚úì Validaci√≥n completada
```

## Modos de Ejecuci√≥n

### Modo 1: Validaci√≥n (Sin Entrenamiento)

Verifica que el sistema est√© correctamente configurado sin ejecutar entrenamiento.

```bash
python ejecutar.py --validate
```

**Cu√°ndo usar:**
- Primera vez que instalas el sistema
- Despu√©s de actualizar dependencias
- Para verificar que los datasets est√°n disponibles
- Para confirmar disponibilidad de GPU

**Duraci√≥n:** ~5-10 segundos

---

### Modo 2: Entrenamiento A2C (‚≠ê RECOMENDADO)

Entrena el agente A2C - el mejor rendimiento seg√∫n resultados de producci√≥n.

```bash
python ejecutar.py --agent a2c
```

**Caracter√≠sticas:**
- üèÜ **64.3% reducci√≥n CO‚ÇÇ** (mejor de los 3 agentes)
- ‚ö° **Convergencia r√°pida** (~2 horas en GPU RTX 4060)
- üìà **Estable y predecible** (ideal para producci√≥n)
- üí∞ **Cost savings**: $1.73M USD/a√±o

**Salida guardada en:**
- `checkpoints/A2C/latest.zip` - Modelo entrenado
- `outputs/a2c_training/` - M√©tricas y logs

**Duraci√≥n:**
- GPU RTX 4060: ~2 horas
- CPU (8 cores): ~6-8 horas

---

### Modo 3: Entrenamiento PPO

Entrena el agente PPO - alternativa on-policy.

```bash
python ejecutar.py --agent ppo
```

**Caracter√≠sticas:**
- üìä **47.5% reducci√≥n CO‚ÇÇ**
- ‚è±Ô∏è **Convergencia media** (~2.5 horas)
- üîÑ **Volatilidad moderada**
- ‚ö†Ô∏è **No recomendado** (A2C es superior)

**Salida guardada en:**
- `checkpoints/PPO/latest.zip`
- `outputs/ppo_training/`

**Duraci√≥n:**
- GPU RTX 4060: ~2.5 horas
- CPU (8 cores): ~8-10 horas

---

### Modo 4: Entrenamiento SAC

Entrena el agente SAC - off-policy, convergencia lenta.

```bash
python ejecutar.py --agent sac
```

**Caracter√≠sticas:**
- üìâ **43.3% reducci√≥n CO‚ÇÇ**
- üêå **Convergencia muy lenta** (~10 horas)
- üß† **Complejo off-policy** (replay buffer grande)
- üíæ **Alto uso de memoria** (~17 GB replay buffer)

**Salida guardada en:**
- `checkpoints/SAC/sac_final.zip`
- `outputs/sac_training/`

**Duraci√≥n:**
- GPU RTX 4060: ~10 horas
- CPU (8 cores): ~30-40 horas

---

## Workflow Completo (Recomendado)

### Paso 1: Validaci√≥n Inicial
```bash
python ejecutar.py --validate
```

### Paso 2: Entrenar A2C (Producci√≥n)
```bash
python ejecutar.py --agent a2c
```

### Paso 3: Verificar Resultados
```bash
# Listar checkpoints generados
ls -lh checkpoints/A2C/

# Ver m√©tricas de entrenamiento
cat outputs/a2c_training/training_evolution.csv
```

### Paso 4: Cargar y Usar Modelo Entrenado
```python
from stable_baselines3 import A2C

# Cargar modelo entrenado
model = A2C.load("checkpoints/A2C/latest.zip")

# Usar para predicci√≥n
action, _ = model.predict(observation, deterministic=True)
```

## M√©tricas de Salida

Despu√©s del entrenamiento, encontrar√°s:

### 1. Checkpoints (Modelos Entrenados)
```
checkpoints/
‚îú‚îÄ‚îÄ A2C/
‚îÇ   ‚îú‚îÄ‚îÄ latest.zip              # Modelo final
‚îÇ   ‚îî‚îÄ‚îÄ checkpoint_*.zip        # Checkpoints intermedios
```

### 2. M√©tricas de Entrenamiento
```
outputs/a2c_training/
‚îú‚îÄ‚îÄ training_evolution.csv      # Evoluci√≥n por episodio
‚îú‚îÄ‚îÄ logs.csv                    # M√©tricas cada 1,000 steps
‚îú‚îÄ‚îÄ result_a2c.json             # Resumen final
‚îú‚îÄ‚îÄ timeseries_a2c.csv          # Series temporales completas
‚îî‚îÄ‚îÄ trace_a2c.csv               # Trace detallado por timestep
```

### 3. Logs del Sistema
```
entrenamiento_a2c.log           # Log completo de entrenamiento
```

## Interpretaci√≥n de Resultados

### M√©tricas Clave

| M√©trica | Descripci√≥n | Valor √ìptimo (A2C) |
|---------|-------------|-------------------|
| **CO‚ÇÇ Reducci√≥n** | % reducci√≥n vs baseline | 64.3% |
| **Reward Promedio** | Recompensa media | 0.4970 |
| **CO‚ÇÇ Grid Import** | Emisiones por import grid | 19.8M kg/a√±o |
| **Solar Autoconsumo** | % PV usado directamente | 51.7% |
| **Grid Import Reducci√≥n** | % menos import vs baseline | 45% |
| **Cost Savings** | Ahorro econ√≥mico anual | $1.73M USD |

### Ejemplo de Salida Exitosa

```
================================================================================
‚úì ENTRENAMIENTO A2C COMPLETADO
================================================================================

Resultados guardados en:
  ‚Ä¢ checkpoints/A2C/latest.zip
  ‚Ä¢ outputs/a2c_training/

M√©tricas Finales:
  CO‚ÇÇ Reducci√≥n:        64.3%
  Reward Promedio:      0.4970
  Solar Autoconsumo:    51.7%
  Cost Savings:         $1.73M USD/a√±o
  Timesteps:            87,600 (10 episodios)
  Duraci√≥n:             2h 15m
```

## Soluci√≥n de Problemas

### Error: Dependencias no instaladas

**S√≠ntoma:**
```
‚úó numpy (NO INSTALADO)
‚úó pandas (NO INSTALADO)
```

**Soluci√≥n:**
```bash
pip install -r requirements.txt
```

---

### Error: Datasets no encontrados

**S√≠ntoma:**
```
‚ö† Solar: data/interim/oe2/solar/pv_generation_timeseries.csv (NO ENCONTRADO)
```

**Soluci√≥n:**

Los datasets deben estar en las rutas especificadas. Verifica que:
1. El repositorio se clon√≥ completamente
2. Los archivos de datos est√°n en `data/interim/oe2/`
3. Los permisos de lectura est√°n correctos

---

### Error: GPU no disponible

**S√≠ntoma:**
```
‚ö† Solo CPU disponible (entrenamiento ser√° lento)
```

**Soluciones:**

**Opci√≥n 1 - Continuar con CPU:**
El entrenamiento funcionar√° pero ser√° m√°s lento (6-8 horas vs 2 horas).

**Opci√≥n 2 - Habilitar GPU:**
1. Instalar CUDA Toolkit 11.8+
2. Instalar PyTorch con soporte CUDA:
```bash
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
```

---

### Error: Out of Memory (OOM)

**S√≠ntoma:**
```
RuntimeError: CUDA out of memory
```

**Soluci√≥n:**

Reduce batch size en el script de entrenamiento:
```python
# En scripts/train/train_a2c_multiobjetivo.py
# L√≠nea ~250 aprox.
batch_size = 64  # Reducir de 128 a 64
```

---

## Comparaci√≥n de Agentes

| Agente | CO‚ÇÇ Reducci√≥n | Tiempo GPU | Complejidad | Producci√≥n |
|--------|---------------|------------|-------------|------------|
| **A2C** ‚≠ê | **64.3%** | **2h** | Baja | ‚úÖ RECOMENDADO |
| PPO | 47.5% | 2.5h | Media | ‚ö†Ô∏è Alternativa |
| SAC | 43.3% | 10h | Alta | ‚ö†Ô∏è Alternativa |

**Recomendaci√≥n:** Usar A2C para producci√≥n debido a su mejor rendimiento, convergencia r√°pida y estabilidad.

## Pr√≥ximos Pasos

Despu√©s de ejecutar con √©xito:

1. **Evaluar Modelo:**
   - Revisar m√©tricas en `outputs/a2c_training/`
   - Analizar convergencia en `training_evolution.csv`

2. **Validar en Entorno Real:**
   - Cargar checkpoint en sistema de producci√≥n
   - Monitorear rendimiento real vs simulado

3. **Optimizaci√≥n Continua:**
   - Ajustar reward weights si es necesario
   - Re-entrenar con nuevos datos

4. **Despliegue:**
   - Ver `DEPLOYMENT_INSTRUCTIONS_A2C.md`
   - Implementar en infraestructura Iquitos

## Referencias

- **README.md** - Descripci√≥n general del proyecto
- **DEPLOYMENT_INSTRUCTIONS_A2C.md** - Gu√≠a de despliegue
- **docs/** - Documentaci√≥n t√©cnica completa
- **scripts/train/** - Scripts de entrenamiento individuales

## Soporte

Para preguntas o problemas:
1. Revisar esta gu√≠a
2. Consultar logs en `entrenamiento_*.log`
3. Abrir issue en GitHub con logs completos

---

**√öltima actualizaci√≥n:** 2026-02-15  
**Versi√≥n:** 1.0.0
