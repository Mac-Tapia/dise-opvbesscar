# ðŸš€ ÃNDICE DE IMPLEMENTACIÃ“N: Conectar SAC â†” Config â†” Rewards â†” COâ‚‚

**Fecha:** 2026-02-01 | **Status:** ðŸ“‹ PLAN DE IMPLEMENTACIÃ“N | **Prioridad:** ðŸ”´ CRÃTICA

---

## ðŸ“Œ RESUMEN EJECUTIVO

El anÃ¡lisis completo revelÃ³ que SAC **NO estÃ¡ sincronizado** con:
- âŒ ConfiguraciÃ³n YAML (parÃ¡metros hardcoded)
- âŒ Sistema multiobjetivo de recompensas (usa rewards genÃ©ricos de CityLearn)
- âŒ CÃ¡lculos de COâ‚‚ directo e indirecto (no se aplican)

**Impacto:** Agente entrenÃ¡ndose sin optimizar COâ‚‚, sin penalizaciones, sin control de YAML.

**SoluciÃ³n:** 3 FIX interconectados + 1 test script para validar.

---

## ðŸ“š DOCUMENTOS GENERADOS

### 1. ðŸ“– AUDITORÃA COMPLETA
**Archivo:** [`AUDITORIA_CONEXION_SAC_CONFIG_REWARDS_CO2_2026_02_01.md`](./AUDITORIA_CONEXION_SAC_CONFIG_REWARDS_CO2_2026_02_01.md)

**Contenido:**
- âœ… AnÃ¡lisis detallado de desconexiones
- âœ… Puntos de fallo en cada integraciÃ³n
- âœ… Flujos actuales (ROTOS) vs esperados (CORRECTOS)
- âœ… Matriz de impacto antes/despuÃ©s
- âœ… Checklist de implementaciÃ³n
- â±ï¸ Tiempo estimado: 4 dÃ­as

---

## ðŸ”§ FIXES A IMPLEMENTAR

### FIX #1: Conectar SAC â†” Config YAML
**Archivo:** [`FIX_1_LOADER_YAML_SAC.py`](./FIX_1_LOADER_YAML_SAC.py)

**QuÃ© hace:**
```python
# âŒ ANTES: make_sac() ignora YAML
def make_sac(env, config=None):
    if config is None:
        cfg = SACConfig()  # Hardcoded defaults

# âœ… DESPUÃ‰S: make_sac() carga YAML automÃ¡ticamente
def make_sac(env, config=None):
    if config is None:
        cfg = SACConfig(**load_config_from_yaml())  # Valores del YAML
```

**ImplementaciÃ³n:**
1. Copiar funciÃ³n `_extract_sac_config_from_yaml()` a `src/iquitos_citylearn/oe3/agents/sac.py`
2. Copiar funciÃ³n `make_sac_with_yaml_config()` a `src/iquitos_citylearn/oe3/agents/sac.py`
3. Reemplazar `make_sac()` para que use nuevo loader
4. Test: `pytest tests/test_sac_yaml_loading.py`

**Tiempo:** ~30 minutos

---

### FIX #2: Integrar MultiObjectiveReward en SAC
**Archivo:** [`FIX_2_MULTIOBJETIVO_WRAPPER_SAC.py`](./FIX_2_MULTIOBJETIVO_WRAPPER_SAC.py)

**QuÃ© hace:**
```python
# âŒ ANTES: SAC entrenando con rewards genÃ©ricos
reward = env.step(action)[1]  # reward sin multiobjetivo

# âœ… DESPUÃ‰S: SAC entrenando con multiobjetivo
wrapper = MultiObjectiveRewardWrapper(env, reward_fn)
reward = wrapper.step(action)[1]  # 5 componentes (COâ‚‚, solar, cost, EV, grid)
```

**ImplementaciÃ³n:**
1. Copiar clase `MultiObjectiveRewardWrapper` a `src/iquitos_citylearn/oe3/agents/sac.py`
2. Copiar funciÃ³n `create_sac_with_multiobjectve_training()` a `src/iquitos_citylearn/oe3/agents/sac.py`
3. Modificar `_train_sb3_sac()` para usar wrapper:
   ```python
   wrapped, reward_fn = create_sac_with_multiobjectve_training(
       env=env,
       sac_config=self.config,
       use_multiobjectve=True,
   )
   ```
4. Test: `pytest tests/test_sac_multiobjectve.py`

**Tiempo:** ~45 minutos

---

### FIX #3: Agregar SecciÃ³n OE3 SAC a config.yaml
**Archivo:** [`FIX_3_CONFIG_YAML_NEW_SECTION.md`](./FIX_3_CONFIG_YAML_NEW_SECTION.md)

**QuÃ© hace:**
```yaml
# âŒ ANTES: config.yaml sin secciÃ³n oe3.sac
oe3:
  dataset: {...}
  grid: {...}

# âœ… DESPUÃ‰S: config.yaml con secciÃ³n oe3.sac y oe3.reward
oe3:
  sac:
    episodes: 50
    batch_size: 256
    learning_rate: 5e-5
    weight_co2: 0.50
    weight_solar: 0.20
    ...
  reward:
    weight_co2: 0.50
    weight_solar: 0.20
    ...
  grid:
    carbon_intensity_kg_per_kwh: 0.4521
    ...
```

**ImplementaciÃ³n:**
1. Abrir `configs/default.yaml`
2. Ubicar secciÃ³n `oe3:`
3. Agregar subsecciÃ³n `oe3.sac:` con todos los parÃ¡metros
4. Agregar subsecciÃ³n `oe3.reward:` con pesos y baselines
5. Actualizar `oe3.grid:` con nuevas opciones
6. Test: `python -c "import yaml; yaml.safe_load(open('configs/default.yaml'))"`

**Tiempo:** ~15 minutos

---

## ðŸ“‹ CHECKLIST DE IMPLEMENTACIÃ“N

### FASE 1: PreparaciÃ³n (DÃ­a 1, ~1 hora)
- [ ] Leer [`AUDITORIA_CONEXION_SAC_CONFIG_REWARDS_CO2_2026_02_01.md`](./AUDITORIA_CONEXION_SAC_CONFIG_REWARDS_CO2_2026_02_01.md) completamente
- [ ] Revisar los 3 FIX files
- [ ] Confirmar que tests pasarÃ¡n sin problemas

### FASE 2: Implementar FIX #1 (DÃ­a 2, ~30 min)
- [ ] Copiar `_extract_sac_config_from_yaml()` a sac.py
- [ ] Copiar `make_sac_with_yaml_config()` a sac.py
- [ ] Reemplazar `make_sac()` para usar loader YAML
- [ ] Agregar logs para verificar carga de YAML
- [ ] Test: `python -c "from iquitos_citylearn.oe3.agents.sac import make_sac; ..."`

### FASE 3: Implementar FIX #2 (DÃ­a 2-3, ~45 min)
- [ ] Copiar `MultiObjectiveRewardWrapper` a sac.py
- [ ] Copiar `create_sac_with_multiobjectve_training()` a sac.py
- [ ] Modificar `_train_sb3_sac()` para instanciar wrapper
- [ ] Agregar logs para componentes multiobjetivo
- [ ] Test: Ejecutar 1 episodio SAC y verificar componentes

### FASE 4: Implementar FIX #3 (DÃ­a 3, ~15 min)
- [ ] Abrir `configs/default.yaml`
- [ ] Agregar secciones `oe3.sac` y `oe3.reward`
- [ ] Actualizar `oe3.grid` con nuevas opciones
- [ ] Validar YAML: `python -c "import yaml; yaml.safe_load(...)"`
- [ ] Test: `python -c "from iquitos_citylearn.config import load_config; cfg=load_config(); print(cfg['oe3']['sac']['episodes'])"`

### FASE 5: ValidaciÃ³n Integrada (DÃ­a 4, ~1 hora)
- [ ] Crear script de test `tests/test_sac_integration.py`
- [ ] Verificar que SAC carga config desde YAML
- [ ] Verificar que multiobjetivo wrapper se aplica
- [ ] Ejecutar 5-10 episodios SAC y capturar logs
- [ ] Analizar logs: 
  - âœ… `[INFO] Loading SAC config from YAML: episodes=50, batch_size=256, ...`
  - âœ… `[STEP 100] r_co2=X.XX r_solar=X.XX r_cost=X.XX r_ev=X.XX r_grid=X.XX | TOTAL=X.XX`
  - âœ… `[STEP 200] COâ‚‚_grid=XXX.Xkg COâ‚‚_avoided=XXX.Xkg`

### FASE 6: Entrenamiento de VerificaciÃ³n (DÃ­a 4-5, ~6 horas)
- [ ] Ejecutar SAC con 10 episodios: `python -m scripts.run_oe3_simulate --config configs/default.yaml --agent sac --episodes 10 --use_multi_objective True`
- [ ] Monitorear progreso de rewards
- [ ] Verificar convergencia: reward_final > -0.5 (buena seÃ±al)
- [ ] Recolectar mÃ©tricas COâ‚‚
- [ ] Generar reporte: `python -m scripts.run_oe3_co2_table`

---

## ðŸ§ª TESTS REQUERIDOS

### Test 1: Config Loading
**Archivo:** `tests/test_sac_config_yaml_loading.py`

```python
def test_sac_loads_yaml_config():
    """Verifica que make_sac() carga config desde YAML."""
    env = make_dummy_env()  # or CityLearnEnv
    
    # âœ… Sin config explÃ­cito â†’ debe cargar YAML
    agent = make_sac(env)
    assert agent.config.episodes == 50, "Episodes debe venir de YAML"
    assert agent.config.batch_size == 256, "Batch size debe venir de YAML"
    assert agent.config.weight_co2 == 0.50, "Weight COâ‚‚ debe venir de YAML"
```

### Test 2: Multiobjetivo Wrapper
**Archivo:** `tests/test_sac_multiobjectve_wrapper.py`

```python
def test_multiobjectve_wrapper_computes_components():
    """Verifica que MultiObjectiveRewardWrapper calcula 5 componentes."""
    env = make_dummy_env()
    reward_fn = MultiObjectiveReward(...)
    wrapper = MultiObjectiveRewardWrapper(env, reward_fn)
    
    obs, info = wrapper.reset()
    action = wrapper.action_space.sample()
    
    obs, reward, terminated, truncated, info = wrapper.step(action)
    
    # âœ… Verificar que info tiene componentes
    assert "multi_objective" in info, "Info debe incluir multi_objective"
    mo = info["multi_objective"]
    assert "r_co2" in mo, "Debe calcular r_co2"
    assert "r_solar" in mo, "Debe calcular r_solar"
    assert "reward_total" in mo, "Debe calcular reward_total"
```

### Test 3: COâ‚‚ Calculations
**Archivo:** `tests/test_co2_calculations.py`

```python
def test_co2_indirect_calculation():
    """Verifica que COâ‚‚ indirecto = solar Ã— 0.4521."""
    reward_fn = MultiObjectiveReward(...)
    
    # âœ… 100 kWh solar directo â†’ 100 Ã— 0.4521 = 45.21 kg COâ‚‚ evitado
    _, components = reward_fn.compute(
        grid_import_kwh=50.0,
        solar_generation_kwh=100.0,  # 100 kWh solar
        ...
    )
    
    expected_avoided = 100.0 * 0.4521  # 45.21 kg
    assert abs(components["co2_avoided_indirect_kg"] - expected_avoided) < 1.0
```

---

## ðŸ“Š MATRIZ DE VALIDACIÃ“N

| Checkpoin | MÃ©todo de VerificaciÃ³n | Status |
|-----------|----------------------|--------|
| FIX #1 funciona | `python -c "make_sac(env); assert agent.config.episodes == 50"` | ðŸŸ¡ Pendiente |
| FIX #2 funciona | `python -c "wrapper = MultiObjectiveRewardWrapper(...); wrapper.step(action)"` | ðŸŸ¡ Pendiente |
| FIX #3 vÃ¡lido | `yaml.safe_load(open('config.yaml'))` | ðŸŸ¡ Pendiente |
| IntegraciÃ³n | SAC + Wrapper + YAML = Training correcto | ðŸŸ¡ Pendiente |
| COâ‚‚ tracking | Logs muestran `r_co2`, `co2_avoided_kg` | ðŸŸ¡ Pendiente |
| Convergencia | Training converge sin divergencia | ðŸŸ¡ Pendiente |

---

## ðŸŽ¯ NEXT STEPS

### Inmediatos (HOY):
1. âœ… Leer auditoria completa
2. âœ… Revisar los 3 FIX files
3. â³ Comenzar FIX #1 (loader YAML)

### Corto Plazo (MAÃ‘ANA):
1. â³ Terminar FIX #1
2. â³ Comenzar FIX #2 (multiobjetivo wrapper)
3. â³ Terminar FIX #3 (config YAML)

### Mediano Plazo (SEMANA):
1. â³ Ejecutar tests (tests/test_sac_*.py)
2. â³ Training de verificaciÃ³n (10 episodios)
3. â³ AnÃ¡lisis de resultados (COâ‚‚ reduction)

### Resultado Final:
- âœ… SAC completamente sincronizado con YAML
- âœ… Multiobjetivo reward integrado
- âœ… COâ‚‚ directos e indirectos tracked
- âœ… Entrenamiento optimizando 5 objetivos
- âœ… Listo para training productivo (50+ episodios)

---

## ðŸ“ž PREGUNTAS FRECUENTES

**Q: Â¿Puedo entrenar antes de implementar los FIX?**  
A: âŒ No. El agente entrenarÃ­a sin objetivos multiobjetivo, resultados inÃºtiles.

**Q: Â¿CuÃ¡nto tiempo toma implementar todo?**  
A: 4-5 dÃ­as completos (8-10 horas de trabajo).

**Q: Â¿Puedo hacer solo FIX #1 y #3 sin FIX #2?**  
A: âŒ No. Sin FIX #2 (multiobjetivo), el agente sigue sin optimizar COâ‚‚.

**Q: Â¿QuÃ© pasa si no sincronizo con config.yaml?**  
A: Valores hardcoded en SAC seguirÃ¡n siendo utilizados, YAML serÃ¡ ignorado.

---

## ðŸ“ˆ IMPACTO ESPERADO

| MÃ©trica | Antes (âŒ) | DespuÃ©s (âœ…) | Mejora |
|---------|-----------|-------------|--------|
| **Componentes reward** | 1 (genÃ©rico) | 5 (multiobjetivo) | +400% |
| **COâ‚‚ reduction** | No tracked | Tracked directo + indirecto | N/A |
| **Config flexibility** | Hardcoded | YAML-driven | 100% |
| **Penalizaciones** | No | SÃ­ (peak, fairness) | N/A |
| **Convergencia** | Lenta/errÃ¡tica | Estable | ~50% mÃ¡s rÃ¡pido |
| **Reproducibilidad** | Baja | Alta | 100% |

---

**Generado por:** GitHub Copilot  
**Fecha:** 2026-02-01  
**Status:** ðŸ“‹ PLAN LISTO PARA IMPLEMENTACIÃ“N
