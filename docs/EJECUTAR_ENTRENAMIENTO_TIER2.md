# EJECUTAR ENTRENAMIENTO - TIER 2 ACTUALIZADO

**Fecha**: 2026-01-18
**Modo**: Serial (A2C ‚Üí PPO ‚Üí SAC en series)
**Episodes c/agente**: 2 (test r√°pido)
**GPU**: CUDA

---

## üöÄ QUICK START - ENTRENAR TODO

### Opci√≥n 1: Script MASTER (TODO EN UNO)

```powershell
# En: d:\dise√±opvbesscar

# A2C - 2 episodios
python -m src.train_a2c_cuda --episodes=2 --verbose=1

# PPO - 2 episodios
python -m src.train_ppo_cuda --episodes=2 --verbose=1

# SAC - 2 episodios
python -m src.train_sac_cuda --episodes=2 --verbose=1
```text

---

## üìã CONFIG TIER 2 PARA CADA AGENTE

### A2C TIER 2 CONFIG

```python
A2CConfig(
    train_steps=500000,
    n_steps=1024,              # ‚Üë TIER 2: de 512
    learning_rate=2.5e-4,      # ‚Üì TIER 2: de 3e-4
    lr_schedule="linear",      # TIER 2: de constant
    ent_coef=0.02,             # ‚Üë TIER 2: de 0.01
    hidden_sizes=(512, 512),   # ‚Üë TIER 2: de (256, 256)
    activation="relu",         # TIER 2: de tanh

    # Multiobjetivo (igual)
    weight_co2=0.50,
    weight_cost=0.15,
    weight_solar=0.20,
    weight_ev_satisfaction=0.10,
    weight_grid_stability=0.05,
)
```text

### PPO TIER 2 CONFIG

```python
PPOConfig(
    train_steps=500000,
    n_steps=1024,
    batch_size=256,            # ‚Üë TIER 2: de 128
    n_epochs=15,               # ‚Üë TIER 2: de 10
    learning_rate=2.5e-4,      # ‚Üì TIER 2: de 3e-4
    lr_schedule="linear",      # TIER 2: de constant
    ent_coef=0.02,             # ‚Üë TIER 2: de 0.01
    hidden_sizes=(512, 512),   # ‚Üë TIER 2: de (256, 256)
    activation="relu",         # TIER 2: de tanh
    use_sde=True,              # NEW TIER 2
    sde_sample_freq=-1,        # Sample every step

    # Multiobjetivo (igual)
    weight_co2=0.50,
    weight_cost=0.15,
    weight_solar=0.20,
    weight_ev_satisfaction=0.10,
    weight_grid_stability=0.05,
)
```text

### SAC TIER 2 CONFIG

```python
SACConfig(
    episodes=2,
    batch_size=256,            # ‚Üì TIER 2: de 512
    buffer_size=150000,        # ‚Üë TIER 2: de 100k
    learning_rate=2.5e-4,      # ‚Üì TIER 2: de 3e-4
    ent_coef=0.02,             # ‚Üë TIER 2: de 0.01
    target_entropy=-40,        # ‚Üì TIER 2: de -50
    hidden_sizes=(512, 512),   # ‚Üë TIER 2: de (256, 256)
    update_per_timestep=2,     # NEW TIER 2
    use_dropout=True,          # NEW TIER 2
    dropout_rate=0.1,          # NEW TIER 2

    # Multiobjetivo + Adaptive normalization (rewards.py)
    weight_co2=0.50,
    weight_cost=0.05,          # ‚Üì TIER 2: de 0.15
    weight_solar=0.20,
    weight_ev_satisfaction=0.10,
    weight_grid_stability=0.15, # ‚Üë TIER 2: de 0.10
)
```text

---

## üîÑ PASOS EJECUCI√ìN

### 1. Verificar Setup GPU

```powershell
# En terminal PowerShell
nvidia-smi

# Deber√≠a mostrar: NVIDIA GPU con CUDA disponible
```text

### 2. Limpiar Checkpoints Anteriores (OPCIONAL)

```powershell
# Backup viejo
mkdir backups_tier1
mv checkpoints_a2c backups_tier1/
mv checkpoints_ppo backups_tier1/
mv checkpoints_sac backups_tier1/
```text

### 3. Entrenar A2C (2 episodios)

```powershell
cd "d:\dise√±opvbesscar"
python -m src.train_a2c_cuda --episodes=2 --verbose=1
```text

**Expected Output**:

```text
Episode 1/2: Reward=..., Import=..., CO2=...
Episode 2/2: Reward=..., Import=..., CO2=...
‚úÖ A2C training complete
```text

**Tiempo**: ~15-20 minutos GPU

### 4. Entrenar PPO (2 episodios)

```powershell
python -m src.train_ppo_cuda --episodes=2 --verbose=1
```text

**Expected Output**:

```text
Episode 1/2: Reward=..., Stability=...
Episode 2/2: Reward=..., Stability=...
‚úÖ PPO training complete
```text

**Tiempo**: ~15-20 minutos GPU

### 5. Entrenar SAC (2 episodios)

```powershell
python -m src.train_sac_cuda --episodes=2 --verbose=1
```text

**Expected Output**:

```text
Episode 1/2: Reward=..., Convergence=...
Episode 2/2: Reward=..., Convergence=...
‚úÖ SAC training complete
```text

**Tiempo**: ~10-15 minutos GPU (SAC m√°s r√°pido)

---

## üìä MONITOREO DURANTE ENTRENAMIENTO

### En Terminal (Real-time)

```powershell
# Monitor GPU
while($true) { nvidia-smi; Start-Sleep 5 }

# Deber√≠a ver:
# - GPU-Util: 80-100%
# - Memory: Aumentando gradualmente
# - Temp: <80¬∞C idealmente
```text

### M√©tricas a Esperar

| Agente | Ep 1 Reward | Ep 2 Reward | Trend |
| -------- | ------------- | ------------- | ------- |
| **A2C** | -0.5 a 0.0 | -0.2 a 0.1 | ‚Üë Mejorando |
| **PPO** | -0.3 a 0.1 | 0.0 a 0.3 | ‚Üë Mejorando |
| **SAC** | 0.0 a 0.3 | 0.2 a 0.5 | ‚Üë‚Üë R√°pido |

**SAC deber√≠a convergir m√°s r√°pido** (reward mejor en menos episodios)

---

## üíæ CHECKPOINTS GENERADOS

Despu√©s de entrenamientos:

```text
checkpoints_a2c/
  ‚îî‚îÄ episode_1/
  ‚îî‚îÄ episode_2/
  ‚îî‚îÄ FINAL/

checkpoints_ppo/
  ‚îî‚îÄ episode_1/
  ‚îî‚îÄ episode_2/
  ‚îî‚îÄ FINAL/

checkpoints_sac/
  ‚îî‚îÄ episode_1/
  ‚îî‚îÄ episode_2/
  ‚îî‚îÄ FINAL/
```text

---

## üìà AN√ÅLISIS POST-ENTRENAMIENTO

### Generar Reportes

```powershell
# Comparar 3 agentes
python -c "
from src.analyze_agents import compare_tier2_results
compare_tier2_results(
    checkpoints=['checkpoints_a2c/FINAL',
                 'checkpoints_ppo/FINAL',
                 'checkpoints_sac/FINAL'],
    episodes=2
)
"
```text

### Resultados Esperados

```text
A2C TIER 2:
  - Avg Reward: 0.05-0.15
  - Import Peak: 260-280 kWh/h
  - Convergence: Medium

PPO TIER 2:
  - Avg Reward: 0.10-0.20
  - Import Peak: 240-260 kWh/h
  - Convergence: Slow but Stable

SAC TIER 2:
  - Avg Reward: 0.20-0.35 ‚≠ê
  - Import Peak: <240 kWh/h ‚≠ê
  - Convergence: Fast ‚≠ê
```text

---

## üîß TROUBLESHOOTING

### Si GPU Memory Error

```powershell
# Bajar batch_size
# PPO: batch_size 256 ‚Üí 128
# A2C: n_steps 1024 ‚Üí 512
# SAC: batch_size 256 ‚Üí 128
```text

### Si Reward diverge

```powershell
# Bajar learning_rate
# 2.5e-4 ‚Üí 2.0e-4
# Subir entropy (ya est√° en 0.02)
```text

### Si Muy lento

```powershell
# Verificar GPU est√° siendo usado:
nvidia-smi
# GPU-Util debe estar >80%

# Si no:
# Bajar episode length o sample rate
```text

---

## ‚úÖ CHECKLIST PRE-ENTRENAMIENTO

```text
[ ] GPU CUDA disponible (nvidia-smi)
[ ] Configs TIER 2 aplicados (ppo_sb3.py, a2c_sb3.py, sac.py)
[ ] Repos clean (git status limpio)
[ ] ~10GB GPU memory libre
[ ] ~2 horas disponibles (2ep √ó 3 agentes)
[ ] Checkpoints dir vac√≠o o backuped
```text

---

## üìã COMANDOS R√ÅPIDO COPY-PASTE

```powershell
# Setup
cd "d:\dise√±opvbesscar"

# A2C
python -m src.train_a2c_cuda --episodes=2 --verbose=1

# PPO
python -m src.train_ppo_cuda --episodes=2 --verbose=1

# SAC
python -m src.train_sac_cuda --episodes=2 --verbose=1

# Commit after
git add -A
git commit -m "Training: 2-episode test run A2C, PPO, SAC TIER 2"
git push origin main
```text

---

## üéØ PR√ìXIMOS PASOS

1. ‚úÖ Ejecutar 2 episodios c/agente
2. ‚úÖ Recopilar m√©tricas
3. ‚úÖ Comparar A2C vs PPO vs SAC
4. ‚úÖ Decidir: ¬øproducci√≥n con SAC? ¬øcontinuaci√≥n con PPO?
5. ‚úÖ TIER 3: Model-based learning (si tiempo)

---

**Status**: ‚úÖ READY TO TRAIN
**Estimated Duration**: 40-60 minutes (2ep √ó 3 agents)
**Expected Best**: SAC (convergencia + eficiencia)