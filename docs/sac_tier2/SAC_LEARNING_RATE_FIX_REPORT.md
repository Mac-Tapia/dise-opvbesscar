# üî¥ CR√çTICO: SAC Learning Rate Cap Bug - IDENTIFICADO Y CORREGIDO

**Fecha**: 2026-01-18 19:05
**Estado**: ‚úÖ FIXED Y RELANZADO
**Impacto**: Bloqueaba completamente el aprendizaje del agente SAC

---

## Problema Detectado

El log de entrenamiento mostr√≥ que SAC **NO estaba aprendiendo**:

<!-- markdownlint-disable MD013 -->
```text
Paso 25-500:   reward_avg = 0.5600 ‚Üí 0.5550 (EMPEORANDO)
Learning Rate: lr = 3.00e-05 (¬°100x MENOR que lo configurado!)
```text
<!-- markdownlint-enable MD013 -->

**Configurado en YAML**: `learning_rate: 0.001` (0.001)
**Actual en ejecuci√≥n**: `learning_rate: 3.00e-05` (0.00003)
**Factor de degradaci√≥n**: **33.3x m√°s lento** ‚ùå

---

## Ra√≠z del Problema

En [src/iquitos_citylearn/oe3/agents/sac.p...
```

[Ver c√≥digo completo en GitHub]python
# ‚ùå ANTES (BUG)
stable_lr = min(self.config.learning_rate, 3e-5)  # Cap a 3e-5 (muy bajo)
stable_batch = min(self.config.batch_size, 512)   # Cap a 512 (muy bajo)
```text
<!-- markdownlint-enable MD013 -->

**Problema**:

- Capaba el learning rate a 3e-5 sin importar la configuraci√≥n
- Capaba batch_size a 512 (config = 32,768 para GPU)
- C√≥digo antiguo de "estabilidad conservadora" que nunca se removi√≥

---

## Soluci√≥n Aplicada

‚úÖ Removida la limitaci√≥n de learning rate
‚úÖ Removida la limitaci√≥n de batch size
‚úÖ Usando valores de configuraci√≥n directamente

**Cambio...
```

[Ver c√≥digo completo en GitHub]text
<!-- markdownlint-enable MD013 -->

---

<!-- markdownlint-disable MD013 -->
## Impacto de la Correcci√≥n | M√©trica | Antes | Despu√©s | Mejora | | --- | ------- | --- | -------- | | Learning Rate | 3.00e-05 | 1.00e-03 | **33.3x m√°s r√°pido** | | Batch Size | 512 | 32,768 | **64x m√°s grande** | | Gradient Quality | Muy bajo | √ìptimo para GPU | **Mejor convergencia** | |Esperado: Reward 500 pasos|0.5550 (plano)|0.6x+ (creciente)|**Aprendizaje real**| ---

## Entrenamiento Relanzado

**Comando ejecutado** (19:05:28):

<!-- markdownlint-disable MD013 -->
```bash
.\\.venv\\Scripts\\python.exe -m scripts.run_oe3_simulate --config configs/default.yaml
```text
<!-- markdownlint-enable MD013 -->

**Configuraci√≥n confirmada**:

- SAC: episodes=2, batch_size=32,768, gradient_steps=256,
  - **learning_rate=0.001**
- PPO: episodes=2, n_steps=32,768, batch_size=32,768, **learning_rate=0.001**
- A2C: episodes=2, n_steps=65,536, **learning_rate=0.001**
- Multiobjetiv...
```

[Ver c√≥digo completo en GitHub]diff
  target_entropy = self.config.target_entropy \
          if self.config.target_entropy is not None else "auto"

- # Learning rate M√ÅS conservador para estabilidad
- stable_lr = min(self.config.learning_rate, 3e-5)  # Max 3e-5 (muy bajo)
-
- # Gamma est√°ndar (SAC maneja bien gamma alto con entropy)
- stable_gamma = self.config.gamma  # Usar config original (0.99)
-
- # Batch size moderado
- stable_batch = min(self.config.batch_size, 512)
+ # Use configured learning rate (not capped anymore)
+ stable_lr = self.config.learning_rate
+
+ # Gamma est√°ndar (SAC maneja bien gamma alto con entropy)
+ stable_gamma = self.config.gamma  # Usar config original (0.99)
+
+ # Use configured batch size (not capped anymore - GPU can handle 32k)
+ stable_batch = self.config.batch_size
```text
<!-- markdownlint-enable MD013 -->

---

## Commit

<!-- markdownlint-disable MD013 -->
```text
Fix: Remove SAC learning rate cap (3e-5 ‚Üí use config 0.001) and batch_size cap (512 ‚Üí use config 32768)
```text
<!-- markdownlint-enable MD013 -->

---

## An√°lisis Post-Mortem

**Por qu√© no se detect√≥ antes**:

1. Los logs mostraban `lr=3.00e-05` pero no indicaban qui√©n la capaba
2. La variable `stable_lr` hac√≠a que pareciera una decisi√≥n deliberada
3. El actor_loss y critic_loss bajaban (falsamente indicaban "progreso")

**Lecciones**:

- Siempre loguear qu√© valor se estaba usando vs qu√© se configur√≥
- Revisar `min()` y `max()` caps en c√≥digo cr√≠tico de RL
- La estabilidad no viene de learning rates ultra-bajos, sino de good reward
  - design + entropy

---

**Estado**: üü¢ **ENTRENAMIENTO RELANZADO CON FIX APLICADO - ESPERAR SAC PHASE
~30 MIN**