â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    âš¡ MÃXIMA POTENCIA INDIVIDUAL âš¡                         â•‘
â•‘                   3 AGENTES OPTIMIZADOS ÃšNICAMENTE                          â•‘
â•‘                          2026-01-24 v2.0                                    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€ ğŸ”´ SAC (Soft Actor-Critic) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     OFF-POLICY MÃXIMA ESTABILIDAD                           â”‚
â”‚                                                                              â”‚
â”‚  ğŸ¯ ESPECIALIDAD: Experiencias diversas, suavidad extrema, tareas complejas â”‚
â”‚                                                                              â”‚
â”‚  âš™ï¸  CONFIGURACIÃ“N INDIVIDUAL:                                              â”‚
â”‚      Learning Rate:        1.5e-4         (â†“ bajo = suave)                  â”‚
â”‚      Batch Size:           512            (â†‘â†‘ off-policy puede)             â”‚
â”‚      Buffer Size:          1,000,000      (â†‘â†‘â†‘ 10x MEMORIA)                â”‚
â”‚      Gamma:                0.999          (â†‘ horizonte largo)               â”‚
â”‚      Tau:                  0.001          (â†“â†“ soft updates suave)           â”‚
â”‚      Hidden Sizes:         (1024, 1024)   (â†‘â†‘ 4M parÃ¡metros)               â”‚
â”‚      Entropy Coef:         0.01           (auto-adaptativo)                 â”‚
â”‚      Gradient Steps:       1              (off-policy estÃ¡ndar)             â”‚
â”‚                                                                              â”‚
â”‚  ğŸ“Š CARACTERÃSTICAS:                                                        â”‚
â”‚      â”œâ”€ 1M experiencias en replay buffer (crucial!)                        â”‚
â”‚      â”œâ”€ Batch processing de 512 muestras (estable)                         â”‚
â”‚      â”œâ”€ Soft target updates (Ï„=0.001 = extrasuave)                        â”‚
â”‚      â”œâ”€ Redes grandes (1024x1024 = mÃ¡xima capacidad)                       â”‚
â”‚      â””â”€ EntropÃ­a auto-ajustable (exploraciÃ³n dinÃ¡mica)                     â”‚
â”‚                                                                              â”‚
â”‚  ğŸ® RENDIMIENTO ESPERADO:                                                  â”‚
â”‚      â”œâ”€ Convergencia:     ~10-15 episodios                                 â”‚
â”‚      â”œâ”€ Reward Final:     -100 a +200 (MUY BUENO)                          â”‚
â”‚      â”œâ”€ COâ‚‚ MÃ­nimo:       250-350 kg/episodio                              â”‚
â”‚      â”œâ”€ EV SatisfacciÃ³n:  90-95% (ALTA)                                    â”‚
â”‚      â”œâ”€ Estabilidad:      â­â­â­â­â­ MÃXIMA                                   â”‚
â”‚      â”œâ”€ Tiempo:           ~3 horas                                          â”‚
â”‚      â””â”€ Mejor Para:       PrecisiÃ³n mÃ¡xima y robustez                      â”‚
â”‚                                                                              â”‚
â”‚  ğŸ’¾ MEMORIA GPU: ~5-6 GB (RTX 4060 = âœ… OK)                                â”‚
â”‚  â±ï¸  VELOCIDAD: Moderada (estabilidad > velocidad)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ ğŸŸ¢ PPO (Proximal Policy Optimization) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ON-POLICY MÃXIMA CONVERGENCIA                            â”‚
â”‚                                                                              â”‚
â”‚  ğŸ¯ ESPECIALIDAD: Convergencia ultra-suave, balance perfecto exp-exploit   â”‚
â”‚                                                                              â”‚
â”‚  âš™ï¸  CONFIGURACIÃ“N INDIVIDUAL:                                              â”‚
â”‚      Learning Rate:        2.0e-4         (â†“ bajo = suave)                  â”‚
â”‚      Batch Size:           128            (â†“ on-policy requiere pequeÃ±o)    â”‚
â”‚      N Steps:              2,048          (â†‘â†‘ MUCHAS experiencias)          â”‚
â”‚      N Epochs:             20             (â†‘ MUCHOS updates por batch)      â”‚
â”‚      Gamma:                0.999          (â†‘ horizonte largo)               â”‚
â”‚      GAE Lambda:           0.98           (â†‘ estimaciÃ³n advantage)          â”‚
â”‚      Clip Range:           0.1            (â†“ RESTRICTIVO = estable)         â”‚
â”‚      Hidden Sizes:         (1024, 1024)   (â†‘â†‘ 4M parÃ¡metros)               â”‚
â”‚      Entropy Coef:         0.01           (bajo ruido)                      â”‚
â”‚      VF Coef:              0.7            (value function importante)       â”‚
â”‚                                                                              â”‚
â”‚  ğŸ“Š CARACTERÃSTICAS:                                                        â”‚
â”‚      â”œâ”€ 1M pasos totales (2x estÃ¡ndar)                                     â”‚
â”‚      â”œâ”€ 2048 experiencias por update (datos frescos)                       â”‚
â”‚      â”œâ”€ 20 epochs Ã— 128 batch = 2560 actualizaciones                       â”‚
â”‚      â”œâ”€ Clipping restrictivo (clip=0.1 vs 0.2 estÃ¡ndar)                    â”‚
â”‚      â”œâ”€ SDE (Stochastic Delta Exploration) = exploraciÃ³n mejorada          â”‚
â”‚      â””â”€ Redes grandes (1024x1024 = capacidad mÃ¡xima)                       â”‚
â”‚                                                                              â”‚
â”‚  ğŸ® RENDIMIENTO ESPERADO:                                                  â”‚
â”‚      â”œâ”€ Convergencia:     ~20-30 episodios (SUAVE)                         â”‚
â”‚      â”œâ”€ Reward Final:     -50 a +300 (EXCELENTE)                           â”‚
â”‚      â”œâ”€ COâ‚‚ MÃ­nimo:       200-300 kg/episodio (MUY BAJO!)                  â”‚
â”‚      â”œâ”€ EV SatisfacciÃ³n:  88-93% (ALTA)                                    â”‚
â”‚      â”œâ”€ Estabilidad:      â­â­â­â­ MUY BUENA                                â”‚
â”‚      â”œâ”€ Convergencia:     â­â­â­â­â­ Ã“PTIMA                                   â”‚
â”‚      â”œâ”€ Tiempo:           ~5-6 horas (LENTO pero MEJOR)                     â”‚
â”‚      â””â”€ Mejor Para:       Rendimiento general Ã³ptimo                        â”‚
â”‚                                                                              â”‚
â”‚  ğŸ’¾ MEMORIA GPU: ~3-4 GB (RTX 4060 = âœ… CÃ³modo)                            â”‚
â”‚  â±ï¸  VELOCIDAD: Lenta pero convergencia perfecta                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ ğŸ”µ A2C (Advantage Actor-Critic) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     ON-POLICY MÃXIMA VELOCIDAD                              â”‚
â”‚                                                                              â”‚
â”‚  ğŸ¯ ESPECIALIDAD: Velocidad, eficiencia GPU, baseline sÃ³lido                â”‚
â”‚                                                                              â”‚
â”‚  âš™ï¸  CONFIGURACIÃ“N INDIVIDUAL:                                              â”‚
â”‚      Learning Rate:        1.5e-4         (â†“ bajo = suave)                  â”‚
â”‚      N Steps:              2,048          (â†‘â†‘ MUCHAS experiencias)          â”‚
â”‚      Gamma:                0.999          (â†‘ horizonte largo)               â”‚
â”‚      GAE Lambda:           0.95           (âœ… Ã³ptimo para A2C)              â”‚
â”‚      Hidden Sizes:         (1024, 1024)   (â†‘â†‘ 4M parÃ¡metros)               â”‚
â”‚      Entropy Coef:         0.01           (bajo ruido)                      â”‚
â”‚      VF Coef:              0.7            (value function importante)       â”‚
â”‚      Max Grad Norm:        1.0            (â†‘ menos agresivo)                â”‚
â”‚      Train Steps:          1,000,000      (â†‘ 2x estÃ¡ndar)                   â”‚
â”‚                                                                              â”‚
â”‚  ğŸ“Š CARACTERÃSTICAS:                                                        â”‚
â”‚      â”œâ”€ Recolecta 2048 pasos en paralelo (GPU eficiente)                   â”‚
â”‚      â”œâ”€ Algoritmo simple pero poderoso (menos overhead)                     â”‚
â”‚      â”œâ”€ GAE Lambda 0.95 (mejor que 1.0)                                    â”‚
â”‚      â”œâ”€ Redes grandes (1024x1024 = capacidad mÃ¡xima)                       â”‚
â”‚      â””â”€ No usa replay buffer (velocidad pura)                              â”‚
â”‚                                                                              â”‚
â”‚  ğŸ® RENDIMIENTO ESPERADO:                                                  â”‚
â”‚      â”œâ”€ Convergencia:     ~15-20 episodios (RÃPIDA)                        â”‚
â”‚      â”œâ”€ Reward Final:     -150 a +100 (BUENO)                              â”‚
â”‚      â”œâ”€ COâ‚‚ MÃ­nimo:       300-400 kg/episodio (BAJO)                       â”‚
â”‚      â”œâ”€ EV SatisfacciÃ³n:  85-90% (BUENA)                                   â”‚
â”‚      â”œâ”€ Estabilidad:      â­â­â­â­ BUENA                                     â”‚
â”‚      â”œâ”€ Velocidad:        â­â­â­â­â­ MÃXIMA                                   â”‚
â”‚      â”œâ”€ Tiempo:           ~2.5-3 horas (RÃPIDO)                             â”‚
â”‚      â””â”€ Mejor Para:       Prototipado rÃ¡pido, baseline                     â”‚
â”‚                                                                              â”‚
â”‚  ğŸ’¾ MEMORIA GPU: ~2-3 GB (RTX 4060 = âœ… MUY CÃ³modo)                       â”‚
â”‚  â±ï¸  VELOCIDAD: RÃ¡pida (velocidad > perfecciÃ³n)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                        ğŸ“Š TABLA COMPARATIVA FINAL                          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

                       SAC          PPO          A2C
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Learning Rate         1.5e-4       2.0e-4       1.5e-4
Batch Size            512          128          Auto
N Steps               1            2048         2048
N Epochs              -            20           -
Buffer Size           1M           -            -
Hidden Sizes          1024x1024    1024x1024    1024x1024
Gamma                 0.999        0.999        0.999
Tau / GAE Lambda      0.001/0.98   0.98         0.95
Clip Range            -            0.1          -
VF Coef               -            0.7          0.7
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Convergencia          10-15 ep     20-30 ep     15-20 ep
Reward Final          -100 a +200  -50 a +300   -150 a +100
COâ‚‚ MÃ­nimo            250-350      200-300      300-400
EV SatisfacciÃ³n       90-95%       88-93%       85-90%
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Estabilidad           â­â­â­â­â­    â­â­â­â­    â­â­â­â­
Convergencia          â­â­â­â­      â­â­â­â­â­    â­â­â­
Velocidad             â­â­â­        â­â­         â­â­â­â­â­
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Tiempo Entrenam.      ~3h          ~5-6h        ~2.5-3h
GPU Requerida         5-6 GB       3-4 GB       2-3 GB
Mejor Para            PrecisiÃ³n    Rendimiento  Velocidad
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                          ğŸš€ INSTRUCCIONES LANZAMIENTO                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… VERIFICACIÃ“N PRE-ENTRENAMIENTO:
   .\verificar_agentes.ps1

ğŸ”´ SAC (MÃ¡xima Estabilidad):
   & .venv/Scripts/python.exe scripts/train_gpu_robusto.py --agent SAC --episodes 50 --device cuda

ğŸŸ¢ PPO (MÃ¡xima Convergencia):
   & .venv/Scripts/python.exe scripts/train_gpu_robusto.py --agent PPO --episodes 57 --device cuda

ğŸ”µ A2C (MÃ¡xima Velocidad):
   & .venv/Scripts/python.exe scripts/train_gpu_robusto.py --agent A2C --episodes 57 --device cuda

ğŸ“… OPCIÃ“N SECUENCIAL (Recomendada):
   & .venv/Scripts/python.exe scripts/train_agents_serial.py --device cuda --episodes 50

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                         âœ… ESTADO FINAL: LISTO                            â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸŸ¢ SAC:     Learning Rate 1.5e-4   | Batch 512     | Buffer 1M
ğŸŸ¢ PPO:     Learning Rate 2.0e-4   | Batch 128     | N Steps 2048
ğŸŸ¢ A2C:     Learning Rate 1.5e-4   | N Steps 2048  | GAE 0.95

ğŸŸ¢ Red Neuronal: (1024, 1024) todos = 4M parÃ¡metros
ğŸŸ¢ Gamma: 0.999 todos = horizonte largo 8760 pasos
ğŸŸ¢ GPU: RTX 4060 8GB
ğŸŸ¢ CUDA: 12.1
ğŸŸ¢ Datos: 128 cargadores + 5 schemas

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    âš¡ MÃXIMA POTENCIA INDIVIDUAL âœ…
                 3 AGENTES ÃšNICAMENTE OPTIMIZADOS
                  Listo para ENTRENAMIENTO YA
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
