#!/usr/bin/env python3
"""
FLUJO COMPLETO - SOBRESCRIBIR ARCHIVO CON MISMO NOMBRE
1. Eliminar archivo antiguo si existe
2. Generar nuevo dataset con MISMO nombre
3. Validar
4. Listo para entrenamiento
"""

import sys
import os
from pathlib import Path
import pandas as pd

print("\n" + "="*80)
print("üöÄ FLUJO COMPLETO: GENERAR DATASET (SOBRESCRIBIR ANTIGUA)")
print("="*80 + "\n")

try:
    # ========================================================================
    # PASO 0: ELIMINAR ARCHIVO ANTIGUO
    # ========================================================================
    print("[PASO 0/4] Eliminando archivo antiguo si existe...")
    print("-" * 80)
    
    # UBICACI√ìN CORRECTA: data/oe2/chargers/
    csv_file = Path("data/oe2/chargers/chargers_real_hourly_2024.csv")
    
    if csv_file.exists():
        os.remove(csv_file)
        print(f"‚úÖ Archivo antiguo eliminado: {csv_file}\n")
    else:
        print(f"‚ÑπÔ∏è No hab√≠a archivo anterior\n")

    # ========================================================================
    # PASO 1: GENERAR DATASET SOC DIN√ÅMICO
    # ========================================================================
    print("[PASO 1/4] Generando Dataset SOC Din√°mico...")
    print("-" * 80)
    
    sys.path.insert(0, str(Path("src")))
    from dimensionamiento.oe2.disenocargadoresev.chargers import generate_soc_dynamic_dataset
    
    # USAR CARPETA CORRECTA: data/oe2/chargers/
    output_dir = Path("data/oe2/chargers")
    df = generate_soc_dynamic_dataset(output_dir=output_dir)
    
    print(f"\n‚úÖ Dataset generado: {csv_file}\n")

    # ========================================================================
    # PASO 2: VALIDAR INTEGRIDAD
    # ========================================================================
    print("[PASO 2/4] Validando integridad del dataset...")
    print("-" * 80)
    
    # Validaci√≥n 1: Leer CSV
    df_check = pd.read_csv(csv_file)
    assert len(df_check) == 8760, f"‚ùå ERROR: {len(df_check)} filas, esperaba 8760"
    print(f"‚úÖ Filas: {len(df_check)} (correcto: 8,760)")
    
    # Validaci√≥n 2: Columnas cr√≠ticas
    required_cols = [
        'timestamp', 'soc_arrival_motos_mean', 'soc_target_motos_mean',
        'fully_charged_total', 'vehicles_charging_motos'
    ]
    for col in required_cols:
        assert col in df_check.columns, f"‚ùå ERROR: columna faltante: {col}"
    print(f"‚úÖ Columnas: {len(df_check.columns)} (todas presentes)")
    
    # Validaci√≥n 3: Per√≠odo
    start_date = df_check['timestamp'].min()
    end_date = df_check['timestamp'].max()
    assert '2024-01-01' in str(start_date), f"‚ùå ERROR: fecha inicio incorrecta: {start_date}"
    assert '2024-12-31' in str(end_date), f"‚ùå ERROR: fecha fin incorrecta: {end_date}"
    print(f"‚úÖ Per√≠odo: {start_date.date()} a {end_date.date()}")
    
    # Validaci√≥n 4: Valores SOC
    soc_arrival = df_check['soc_arrival_motos_mean']
    print(f"‚úÖ SOC din√°mico: {soc_arrival.mean():.1%} ¬± {soc_arrival.std():.1%}")
    
    # Validaci√≥n 5: Veh√≠culos
    daily_vehicles = df_check['vehicles_charging_motos'].sum() / 365
    print(f"‚úÖ Veh√≠culos motos/d√≠a: {daily_vehicles:.0f}")
    
    print()

    # ========================================================================
    # PASO 3: CONFIRMAR INTEGRACI√ìN
    # ========================================================================
    print("[PASO 3/4] Confirmando integraci√≥n con dataset_builder.py...")
    print("-" * 80)
    
    # Verificar que el archivo existe y es accesible
    assert csv_file.exists(), "‚ùå ERROR: archivo no se guard√≥ correctamente"
    file_size_mb = csv_file.stat().st_size / (1024 * 1024)
    print(f"‚úÖ Archivo existe: {csv_file}")
    print(f"‚úÖ Tama√±o: {file_size_mb:.2f} MB")
    print(f"‚úÖ Compatible con dataset_builder.py: S√ç")
    
    print()

    # ========================================================================
    # PASO 4: RESUMEN FINAL
    # ========================================================================
    print("[PASO 4/4] Resumen y pr√≥ximos pasos...")
    print("-" * 80)
    
    print("\nüìä DATASET GENERADO:")
    print(f"  üìÅ Carpeta: data/oe2/chargers/")
    print(f"  üìÑ Archivo: chargers_real_hourly_2024.csv")
    print(f"  üì¶ Tama√±o: {file_size_mb:.2f} MB")
    print(f"  üìà Filas: {len(df_check)} (1 a√±o √ó 24 horas)")
    print(f"  üìã Columnas: {len(df_check.columns)}")
    print(f"  üìÖ Per√≠odo: {start_date.date()} a {end_date.date()}")
    print(f"  ‚úÖ Estado: LISTO PARA ENTRENAMIENTO")
    
    print("\nüéØ PR√ìXIMOS PASOS - ENTRENAR AGENTES:")
    print("  ")
    print("  1Ô∏è‚É£  SAC (Soft Actor-Critic):")
    print("      python train_sac_multiobjetivo.py")
    print("      ‚è±Ô∏è  Duraci√≥n: 5-7 horas")
    print("")
    print("  2Ô∏è‚É£  PPO (Proximal Policy Optimization):")
    print("      python train_ppo_multiobjetivo.py")
    print("      ‚è±Ô∏è  Duraci√≥n: 4-6 horas")
    print("")
    print("  3Ô∏è‚É£  A2C (Advantage Actor-Critic):")
    print("      python train_a2c_multiobjetivo.py")
    print("      ‚è±Ô∏è  Duraci√≥n: 3-4 horas")
    
    print("\nüìà ARQUITECTURA SINCRONIZADA:")
    print("  ‚úÖ OE2 (Dimensionamiento)")
    print("     ‚Ä¢ 32 chargers √ó 4 sockets = 128 tomas controlables")
    print("     ‚Ä¢ 4,050 kWp Solar")
    print("     ‚Ä¢ 4,520 kWh BESS")
    print("")
    print("  ‚úÖ OE3 (Entrenamiento RL)")
    print("     ‚Ä¢ Observaci√≥n: 778-dim (con SOC din√°mico)")
    print("     ‚Ä¢ Acci√≥n: 129-dim (1 BESS + 128 chargers)")
    print("     ‚Ä¢ Episodio: 8,760 timesteps horarios")
    print("")
    print("  ‚úÖ Dataset SOC Din√°mico")
    print("     ‚Ä¢ Archivo: chargers_real_hourly_2024_soc_dynamic.csv")
    print("     ‚Ä¢ Estructura: 8,760 √ó 16 (hora √ó variables)")
    print("     ‚Ä¢ Integraci√≥n: dataset_builder.py")
    
    print("\n" + "="*80)
    print("‚úÖ FLUJO COMPLETADO - DATASET LISTO PARA ENTRENAR")
    print("="*80)
    print()
    
except Exception as e:
    print(f"\n‚ùå ERROR: {e}\n")
    import traceback
    traceback.print_exc()
    sys.exit(1)
