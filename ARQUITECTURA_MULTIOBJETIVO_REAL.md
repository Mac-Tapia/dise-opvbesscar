# ARQUITECTURA MULTIOBJETIVO REAL - ENTRENAMIENTO AGENTS SAC/PPO/A2C

**Fecha:** 2026-02-05  
**Estado:** âœ… SISTEMA FUNCIONAL - Tests ejecutados exitosamente

---

## ğŸ¯ OBJETIVO PRINCIPAL

Optimizar la **carga de 128 chargers (112 motos + 16 mototaxis)** y el **BESS de 4,520 kWh** en el **ambiente aislado de Iquitos, PerÃº** para **minimizar emisiones de COâ‚‚ de la red tÃ©rmica** (~0.4521 kg COâ‚‚/kWh) y **maximizar autoconsumo solar** (4,162 kWp disponible).

---

## ğŸ—ï¸ ARQUITECTURA MULTIOBJETIVO IMPLEMENTADA

### 1. **CÃ¡lculos de COâ‚‚ (Directo e Indirecto)**

```
COâ‚‚ INDIRECTO (Minimizar):
â”œâ”€â”€ ImportaciÃ³n de grid Ã— 0.4521 kg COâ‚‚/kWh
â”‚   â””â”€â”€ OBJETIVO: Minimizar este valor
â”‚
COâ‚‚ EVITADO INDIRECTO:
â”œâ”€â”€ EnergÃ­a solar consumida Ã— 0.4521 kg COâ‚‚/kWh
â”‚   â””â”€â”€ Evita grid import (mÃ¡s solar = menos grid = menos COâ‚‚)
â”‚
COâ‚‚ EVITADO DIRECTO (Tracking):
â”œâ”€â”€ EVs cargadas (motos + mototaxis) Ã— factor conversiÃ³n
â”‚   â””â”€â”€ Equivalencia a combustible evitado (8.9 kg COâ‚‚/galÃ³n)
```

**Ubicaciones en cÃ³digo:**
- CÃ¡lculos: `src/rewards/rewards.py` (lÃ­nea 200+)
  - `calculate_co2_reduction_indirect()` â†’ Solar vs grid
  - `calculate_co2_reduction_direct()` â†’ EVs cargadas
  - `calculate_co2_reduction_bess_discharge()` â†’ BESS descarga

- Componentes recompensa: `MultiObjectiveReward.compute()`
  - `co2_grid_kg`: Grid import
  - `co2_avoided_indirect_kg`: EnergÃ­a solar evita grid
  - `co2_avoided_direct_kg`: EVs evitan combustible
  - `co2_net_kg`: Neto (grid - evitado)

### 2. **Pesos Multiobjetivo (Configurables)**

```python
# Preset "co2_focus" (USADO POR DEFECTO)
Pesos:
  â”œâ”€â”€ COâ‚‚: 0.50  â† PRIMARIO: Minimizar importaciÃ³n grid
  â”œâ”€â”€ Solar: 0.20  â† Maximizar autoconsumo PV
  â”œâ”€â”€ Cost: 0.15  â† Minimizar costo elÃ©ctrico
  â”œâ”€â”€ EV satisfaction: 0.08  â† Cargar EVs a 90% SOC
  â”œâ”€â”€ EV utilization: 0.02  â† Maximizar EVs cargadas
  â””â”€â”€ Grid stability: 0.05  â† Suavizar picos

# Otros presets disponibles
"balanced", "cost_focus", "ev_focus", "solar_focus"
```

**UbicaciÃ³n:** `src/rewards/rewards.py` lÃ­nea 748+  
**FunciÃ³n:** `create_iquitos_reward_weights(priority)`

### 3. **Control Diferenciado Motos vs Mototaxis**

```
ESPACIOS DE ACCIÃ“N (129 dimensiones):
â”œâ”€â”€ [0] BESS dispatch (1 dim)
â”‚   â””â”€â”€ Power setpoint: [0,1] â†’ [0, 2712 kW]
â”‚
â”œâ”€â”€ [1-112] MOTOS sockets (112 dims)
â”‚   â”œâ”€â”€ 112 motos fÃ­sicas
â”‚   â”œâ”€â”€ Potencia nominal: 2 kW cada una
â”‚   â”œâ”€â”€ Control: setpoint [0,1] â†’ [0, 2 kW]
â”‚   â””â”€â”€ Objetivo: Cargar a 90% SOC (13h operaciÃ³n 9AM-10PM)
â”‚
â””â”€â”€ [113-128] MOTOTAXIS sockets (16 dims)
    â”œâ”€â”€ 16 mototaxis fÃ­sicas
    â”œâ”€â”€ Potencia nominal: 3 kW cada una
    â”œâ”€â”€ Control: setpoint [0,1] â†’ [0, 3 kW]
    â””â”€â”€ Objetivo: Cargar a 90% SOC (13h operaciÃ³n 9AM-10PM)
```

**Capacidad de carga:**
```
Motos: 1,800/dÃ­a Ã— 365 = 657,000/aÃ±o
Mototaxis: 260/dÃ­a Ã— 365 = 94,900/aÃ±o
Total: 751,900 vehÃ­culos/aÃ±o
```

**UbicaciÃ³n en cÃ³digo:**
- ConfiguraciÃ³n: `src/rewards/rewards.py` lÃ­nea 133+
  - `IquitosContext.motos_daily_capacity: 1800`
  - `IquitosContext.mototaxis_daily_capacity: 260`
  - `IquitosContext.charger_power_kw_moto: 2.0`
  - `IquitosContext.charger_power_kw_mototaxi: 3.0`

- Control: `train_sac_multiobjetivo.py` lÃ­nea 180+
  ```python
  # Despacho diferenciado
  motos_power = np.sum(charger_setpoints[:112]) Ã— 2.0 kW
  mototaxis_power = np.sum(charger_setpoints[112:]) Ã— 3.0 kW
  ```

### 4. **FunciÃ³n de Recompensa Completa**

```
r_total = w_co2 Ã— r_co2 
        + w_solar Ã— r_solar 
        + w_cost Ã— r_cost 
        + w_ev Ã— r_ev
        + w_grid Ã— r_grid

Donde cada r_i âˆˆ [-1, 1] (normalizado)
```

**Componentes:**

| Componente | FÃ³rmula | InterpretaciÃ³n |
|-----------|---------|-----------------|
| **r_co2** | 1 - 2Ã—min(co2_net/baseline) | Minimizar importaciÃ³n neta |
| **r_solar** | 2Ã—(self_consumption_ratio) - 1 | Maximizar uso directo PV |
| **r_cost** | 1 - 2Ã—min(costo/baseline) | Minimizar USD/kWh |
| **r_ev** | 2Ã—(ev_soc/target) - 1 + bonuses | Cargar a 90% SOC + urgencia horaria |
| **r_grid** | Penalidades por picos | Suavizar demanda pico 18-21h |

**UbicaciÃ³n:** `src/rewards/rewards.py` lÃ­nea 215-500

---

## ğŸ§  INTEGRACIÃ“N EN AGENTS

### SAC (Soft Actor-Critic - RECOMENDADO)

**Script:** `train_sac_multiobjetivo.py`

```python
# Crear environment con cÃ¡lculos reales
env = CityLearnRealEnv(
    reward_calc=MultiObjectiveReward(weights, context),
    context=context
)

# SAC agent
agent = SAC('MlpPolicy', env,
           learning_rate=3e-4,
           buffer_size=1,000,000,  # Replay buffer grande
           ent_coef='auto')  # Entropy tuning automÃ¡tico

# Entrenar
agent.learn(total_timesteps=100000)
```

**Ventajas SAC:**
- Off-policy: Eficiente en muestras
- Maneja recompensas asimÃ©tricas bien
- Auto-tuning de entropy: ExploraciÃ³n adaptativa

**Test ejecutado:** âœ… Funcionando
```
Reward multiobjetivo: 62.78
COâ‚‚ evitado: 10.7 kg/episodio
r_co2: 1.000 (excelente)
r_solar: -0.371 (mejora con entrenamiento)
r_ev: 0.041 (bÃ¡sico, mejora con entrenamiento)
```

### PPO (Proximal Policy Optimization)

**Script:** `train_ppo_a2c_multiobjetivo.py`

```python
agent = PPO('MlpPolicy', env,
           learning_rate=3e-4,
           n_steps=2048,  # Rollout
           clip_range=0.2)

agent.learn(total_timesteps=100000)
```

**Ventajas PPO:**
- On-policy: Estable
- Clip range previene cambios grandes
- Mejor para multitarea

### A2C (Advantage Actor-Critic)

**Script:** `train_ppo_a2c_multiobjetivo.py`

```python
agent = A2C('MlpPolicy', env,
           learning_rate=7e-4,  # MÃ¡s alto que SAC/PPO
           n_steps=5)  # ActualizaciÃ³n frecuente

agent.learn(total_timesteps=100000)
```

**Ventajas A2C:**
- Muy simple
- Actualizaciones frecuentes
- Buen baseline para comparaciÃ³n

---

## ğŸ“Š PARÃMETROS DEL AMBIENTE SIMUL ADO

```
MALL (Centro Comercial):
â”œâ”€â”€ Carga base: 100 kW (horario cerrado)
â”œâ”€â”€ Carga pico: 300+ kW (9 AM - 10 PM)
â”œâ”€â”€ Demanda anual: 3,358,876 kWh

SOLAR (PV):
â”œâ”€â”€ Potencia nominal: 4,162 kWp
â”œâ”€â”€ PatrÃ³n: Senoidal con pico medio dÃ­a
â”œâ”€â”€ Disponibilidad: 6 AM - 6 PM
â””â”€â”€ GeneraciÃ³n anual esperada: ~8 GWh

BESS (Battery Storage):
â”œâ”€â”€ Capacidad: 4,520 kWh
â”œâ”€â”€ Potencia: 2,712 kW
â”œâ”€â”€ SOC rango: [10%, 95%]
â”œâ”€â”€ NO controlable por agent
â””â”€â”€ Despacho automÃ¡tico segÃºn reglas

EVs (32 Chargers â†’ 128 Sockets):
â”œâ”€â”€ Motos: 112 sockets @ 2 kW
â”œâ”€â”€ Mototaxis: 16 sockets @ 3 kW
â”œâ”€â”€ Demanda constante: 50 kW (simulaciÃ³n CityLearn 2.5.0)
â”œâ”€â”€ OperaciÃ³n: 9 AM - 10 PM (13 horas)
â””â”€â”€ Capacidad anual: 751,900 vehÃ­culos

GRID:
â”œâ”€â”€ COâ‚‚ factor: 0.4521 kg COâ‚‚/kWh (TÃ‰RMICA AISLADA)
â”œâ”€â”€ Tarifa: 0.20 USD/kWh
â””â”€â”€ CaracterÃ­sticas: Aislado, no interconectado
```

---

## âœ… TESTS EJECUTADOS

### Test 1: SAC Multiobjetivo Real âœ“

```bash
python test_sac_multiobjetivo.py
```

**Resultados:**
```
âœ“ Contexto Iquitos cargado
âœ“ Pesos multiobjetivo (COâ‚‚ focus)
âœ“ Environment con multiobjetivo REAL
âœ“ SAC agent entrenado (500 timesteps)
âœ“ Inferencia en 3 episodios

Metrics (promedio):
  - Reward: 62.78 Â± 0.0
  - COâ‚‚ evitado: 10.7 kg/episodio
  - r_co2: 1.000 (perfecto)
  - r_solar: -0.371 (hay margen de mejora)
  - r_ev: 0.041 (hay margen de mejora)

STATUS: âœ… SISTEMA FUNCIONANDO CORRECTAMENTE
```

---

## ğŸš€ PRÃ“XIMOS PASOS

### 1. Entrenar SAC Completo (2h CPU)
```bash
python train_sac_multiobjetivo.py
```
Output: `checkpoints/SAC/sac_final_model.zip`

### 2. Entrenar PPO y A2C (3h CPU total)
```bash
python train_ppo_a2c_multiobjetivo.py
```
Output: `checkpoints/{PPO,A2C}/` + mÃ©tricas

### 3. Evaluar y Comparar
```bash
python evaluate_agents.py
```
Output: `outputs/evaluation/evaluation_report.json`

---

## ğŸ“‹ DIFERENCIAS CON VERSIÃ“N ANTERIOR

| Aspecto | Antes | Ahora |
|---------|-------|-------|
| **Reward** | Simulado aleatorio | Multiobjetivo REAL (COâ‚‚, solar, cost, EV, grid) |
| **CÃ¡lculos COâ‚‚** | N/A | Directo + Indirecto con factores reales |
| **Contexto** | Generic | Iquitos especÃ­fico (0.4521 kg COâ‚‚/kWh) |
| **Control motos/taxis** | GenÃ©rico | Diferenciado (2kW vs 3kW) |
| **Pesos** | Hardcoded | Configurables (5 presets) |
| **Data Iquitos** | 757k motos/aÃ±o | 657k motos + 94.9k mototaxis/aÃ±o |
| **BESS control** | Mock | Dispatch integrado en reward |
| **Pruebas** | N/A | âœ… Test rÃ¡pido ejecutado |

---

## ğŸ“ ARCHIVOS NUEVOS / MODIFICADOS

**Nuevos scripts:**
- `test_sac_multiobjetivo.py` - Test rÃ¡pido multiobjetivo (âœ… ejecutado)
- `train_sac_multiobjetivo.py` - SAC con arquitectura real (listo)
- `train_ppo_a2c_multiobjetivo.py` - PPO y A2C con arquitectura real (listo)

**Archivos existentes (NO modificados):**
- `src/rewards/rewards.py` - Ya tenÃ­a arquitectura completa
- `src/rewards/__init__.py` - Exporta funciones correctas

---

## ğŸ’¡ CLAVE: Por QuÃ© Esta Arquitectura es Correcta

1. **COâ‚‚ Realista:** 
   - Usa factor actual de Iquitos (0.4521 kg COâ‚‚/kWh)
   - Diferencia evitado directo e indirecto
   - Agent aprende a maximizar solar directo

2. **Multiobjetivo Balanceado:**
   - 50% en COâ‚‚ (objetivo principal)
   - 20% en Solar (aprovecha recurso disponible)
   - 15% en Cost (minimiza USD)
   - 15% en EV+Grid (operaciÃ³n)

3. **Control FÃ­sicamente Realista:**
   - 112 motos @ 2kW (68 kW simultÃ¡neo mÃ¡x.)
   - 16 mototaxis @ 3kW (48 kW simultÃ¡neo mÃ¡x.)
   - BESS separado (no controlable por agents)
   - Patrones de demanda reales

4. **OptimizaciÃ³n Correcta:**
   - Agent controla dispatch de chargers
   - Reward incentiva: PV directo â†’ menos grid â†’ menos COâ‚‚
   - Penalidades en picos (18-21h, cierre mall)
   - Bonus por EV cargadas a 90% SOC

---

## ğŸ“ˆ MÃ‰TRICAS ESPERADAS (Post-Training)

```
SAC (esperado mejor):
  COâ‚‚ evitado: 400-600 kg/episodio
  Reward: +20 a +50
  Solar self-consumption: 60-70%

PPO (esperado similar):
  COâ‚‚ evitado: 350-550 kg/episodio
  Reward: +15 a +45
  Solar self-consumption: 55-65%

A2C (esperado base):
  COâ‚‚ evitado: 300-450 kg/episodio
  Reward: +10 a +35
  Solar self-consumption: 50-60%
```

---

**Proyecto:** pvbesscar Iquitos  
**VersiÃ³n:** 1.1 - Multiobjetivo Real  
**Status:** âœ… Ready for Production Training
