# GU√çA DE EJECUCI√ìN R√ÅPIDA - AGENTES RL

## ‚ö° INICIO INMEDIATO

### Opci√≥n A: Test R√°pido (1 minuto para verificar sistema)
```bash
python train_sac_test.py
```
‚úì Verifica: Dataset, Environment, SAC agent
‚úì Entrena: 5,000 timesteps
‚úì Esperado: "STATUS: ‚úì SAC FUNCIONANDO CORRECTAMENTE"

---

### Opci√≥n B: SAC Completo (RECOMENDADO - 2h CPU)
```bash
python train_sac_production.py
```
‚úì Entrena: 100,000 timesteps (11 episodios)
‚úì Checkpoints: Guardados cada 50k steps
‚úì Output: `checkpoints/SAC/sac_final_model.zip`
‚úì M√©tricas: `outputs/sac_training/sac_training_metrics.json`

---

### Opci√≥n C: Todos los Agents (6h CPU total)
```bash
python train_all_agents.py
```
‚úì Secuencial: SAC ‚Üí PPO ‚Üí A2C
‚úì Outputs: 3 modelos finales
‚úì Ranking: Autom√°tico al final

---

### Opci√≥n D: Paralelo (Fastest - requiere 3 terminales)

**Terminal 1:**
```bash
python train_sac_production.py
```

**Terminal 2 (mientras avanza Terminal 1):**
```bash
python train_ppo_production.py
```

**Terminal 3 (mientras progresan):**
```bash
python train_a2c_production.py
```

Luego eval√∫ar:
```bash
python evaluate_agents.py
```

---

## üìä DESPU√âS DEL ENTRENAMIENTO

### Ver M√©tricas
```bash
# JSON bonito
python -c "import json; print(json.dumps(json.load(open('outputs/sac_training/sac_training_metrics.json')), indent=2))"

# Variables clave
python -c "import json; m=json.load(open('outputs/sac_training/sac_training_metrics.json')); print(f\"Reward: {m['validation_mean_reward']:.2f} ¬± {m['validation_std_reward']:.2f}\")"
```

### Comparaci√≥nAgents
```bash
# Tabla CSV
cat outputs/evaluation/evaluation_comparison.csv

# JSON completo
python -c "import json; print(json.dumps(json.load(open('outputs/evaluation/evaluation_report.json')), indent=2))"
```

### Monitoring en Tiempo Real
```bash
# Terminal aparte - ejecutar MIENTRAS entrena
tensorboard --logdir outputs/*/tensorboard
# ‚Üí http://localhost:6006
```

---

## üîß CONFIGURACI√ìN R√ÅPIDA

### CPU vs GPU

**Detectar GPU (si disponible):**
```bash
python -c "import torch; print('GPU!' if torch.cuda.is_available() else 'CPU')"
```

**Forzar CPU (si GPU da problemas):**
Editar script antes de ejecutar:
```python
# En train_sac_production.py, cambiar:
'device': 'cpu'  # ‚Üê Agregar esta l√≠nea en sac_config
```

### Reducir Memoria

Si dice "OOM - Out of Memory":
```python
# En train_sac_production.py:
sac_config = {
    'batch_size': 32,      # ‚Üê Reducir de 64
    'buffer_size': 100000, # ‚Üê Reducir de 1,000,000
    'policy_kwargs': {
        'net_arch': [128, 128],  # ‚Üê Reducir de [256, 256]
    }
}
```

### Entrenar Menos Episodios

Editar TOTAL_TIMESTEPS:
```python
TOTAL_TIMESTEPS = 50000  # ‚Üê Cambiar de 100,000 (5 episodios en lugar de 11)
```

---

## üìã CHECKLIST PRE-EJECUCI√ìN

Antes de `python train_sac_production.py`:

- [ ] ‚úÖ `python train_sac_test.py` ejecutado exitosamente
- [ ] ‚úÖ `data/interim/oe2/` contiene 4 archivos cr√≠ticos
- [ ] ‚úÖ `data/processed/citylearn/iquitos_ev_mall/` existe (161 archivos)
- [ ] ‚úÖ `configs/default.yaml` presente
- [ ] ‚úÖ `checkpoints/` directory creado (auto-crea)
- [ ] [ ] Espacio en disco: m√≠nimo 5GB disponible

**Si falta algo:**
```bash
# Construir dataset
python build_citylearnv2_with_oe2.py
```

---

## üéØ ESCENARIOS T√çPICOS

### Escenario 1: "Quiero ver si funciona r√°pido"
```bash
python train_sac_test.py
# ‚úì 75 segundos ‚Üí Resultado: OK/ERROR
```

### Escenario 2: "Quiero entrenar un agent completo"
```bash
python train_sac_production.py
# ‚úì 1-2 horas ‚Üí Modelo guardado
python evaluate_agents.py
# ‚úì 5 minutos ‚Üí M√©tricas finales
```

### Escenario 3: "Quiero comparar SAC vs PPO vs A2C"
```bash
python train_all_agents.py
# ‚úì 6 horas ‚Üí Ranking autom√°tico
```

### Escenario 4: "Quiero entrenar y monitorear"
```bash
# Terminal 1: Entrenar
python train_sac_production.py

# Terminal 2: Monitor (abrir MIENTRAS avanza)
tensorboard --logdir outputs/sac_training/tensorboard

# Abrir navegador ‚Üí http://localhost:6006
```

### Escenario 5: "Quiero solo checkpoint r√°pido cada poco"
Editar TOTAL_TIMESTEPS = 10000 (solo 1 episodio, 5 min)

---

## ‚ö†Ô∏è ERRORES COMUNES Y SOLUCIONES

### "‚ùå ModuleNotFoundError: No module named 'stable_baselines3'"
```bash
pip install stable-baselines3
pip install gymnasium
```

### "‚ùå FileNotFoundError: data/interim/oe2/..."
```bash
# Verificar
ls -la data/interim/oe2/
# Si faltan: necesita OE2 data para ejecutar

# O ejecutar dataset builder primero
python build_citylearnv2_with_oe2.py
```

### "‚ùå CUDA out of memory"
```bash
# Reducir batch size en script:
'batch_size': 32

# O reducir timesteps:
TOTAL_TIMESTEPS = 50000
```

### "‚ùå Training seems stuck (loss not decreasing)"
Completamente normal para primeros 1000 steps.
Esperar hasta step 10,000+ para ver cambios.

### "‚ùå Modelo no carga despu√©s de entrenar"
```bash
# Verificar que existe
ls -la checkpoints/SAC/

# Si existe pero no carga, puede ser incompatibilidad
# Soluci√≥n: Entrenar de nuevo o usar backup anterior
```

---

## üìä INTERPRETAR RESULTADOS

### Reward durante entrenamiento

```
Steps: 1,000  | Loss: -25.3   ‚Üê Explorando
Steps: 10,000 | Loss: -30.2   ‚Üê Mejorando
Steps: 50,000 | Loss: -32.5   ‚Üê Convergiendo
Steps: 100,000| Loss: -32.8   ‚Üê Plateau (esperado)
```

‚úì Normal: Reward oscila ¬±10% en √∫ltimos 20k steps
‚ùå Problema: Reward aumentando monot√≥nicamente (divergencia)
‚ùå Problema: Reward siempre constante (no aprende)

### Validaci√≥n Final

```
Ep 1: reward=-38.52  ‚Üê Individual episode
Ep 2: reward=-39.15
Ep 3: reward=-38.97
Mean: -38.88 ¬± 0.30  ‚Üê Resumen

‚úì BUENOS: Std < 5.0 (agent estable)
‚ùå MALO: Std > 10.0 (agent inestable)
```

---

## üöÄ NEXT STEPS DESPU√âS DE ENTRENAR

### 1Ô∏è‚É£ Evaluar Modelo
```bash
python evaluate_agents.py
```

### 2Ô∏è‚É£ Inspeccionar En Detalle
```bash
# Cargar modelo en Python
from stable_baselines3 import SAC
model = SAC.load('checkpoints/SAC/sac_final_model')
model.policy  # Ver arquitectura
print(model.num_timesteps)  # Ver steps entrenados
```

### 3Ô∏è‚É£ Usar Modelo para Inferencia
```python
# Ejemplo de uso
from stable_baselines3 import SAC
model = SAC.load('checkpoints/SAC/sac_final_model')

# Reset environment
obs, _ = env.reset()

# Inference
for step in range(100):
    action, _ = model.predict(obs, deterministic=True)
    obs, reward, terminated, truncated, _ = env.step(action)
    if terminated or truncated:
        break
```

### 4Ô∏è‚É£ Entrenar M√°s Episodios
```python
# Resume training
model = SAC.load('checkpoints/SAC/sac_final_model')
model.learn(total_timesteps=50000, reset_num_timesteps=False)
```

---

## üíæ BACKUP Y VERSION CONTROL

Despu√©s de cada entrenamiento:
```bash
# Backup modelo
cp checkpoints/SAC/sac_final_model.zip checkpoints/SAC/sac_final_model_v1.zip

# Backup m√©tricas
cp outputs/sac_training/sac_training_metrics.json outputs/sac_training/sac_metrics_v1.json
```

---

## üîÑ WORKFLOW COMPLETO (Ejemplo)

```bash
# [1] Test r√°pido - verificar sistema (1 min)
python train_sac_test.py
# Output: "STATUS: ‚úì SAC FUNCIONANDO CORRECTAMENTE"

# [2] SAC entrenar (2h)
python train_sac_production.py
# Output: checkpoints/SAC/sac_final_model.zip

# [3] PPO entrenar (1h) - paralelo o secuencial
python train_ppo_production.py

# [4] A2C entrenar (30min)
python train_a2c_production.py

# [5] Evaluar (5 min)
python evaluate_agents.py
# Output: outputs/evaluation/evaluation_report.json

# [6] Ver resultados
cat outputs/evaluation/evaluation_comparison.csv

# [7] Monitor con TensorBoard (en navegador)
tensorboard --logdir outputs/*/tensorboard
```

---

## üìû DEBUGGING R√ÅPIDO

```bash
# Verificar PyTorch/Stable-Baselines3
python -c "import stable_baselines3; print('‚úì SB3 OK')"

# Verificar Gymnasium
python -c "import gymnasium; print('‚úì Gymnasium OK')"

# Verificar dataset
python -c "import json; json.load(open('data/processed/citylearn/iquitos_ev_mall/schema.json')); print('‚úì Dataset OK')"

# Verificar checkpoints directory
python -c "from pathlib import Path; Path('checkpoints').mkdir(exist_ok=True); print('‚úì Checkpoints OK')"
```

---

**¬°Listo para entrenar! üöÄ**

Pr√≥ximo paso:
```bash
python train_sac_test.py
```

Esperado output:
```
[6] ENTRENAR 5 EPISODIOS (TEST R√ÅPIDO)
[7] TEST INFERENCIA
[... √©xito ...]
STATUS: ‚úì SAC FUNCIONANDO CORRECTAMENTE
```

Si ves esto ‚Üí Ejecutar:
```bash
python train_sac_production.py
```
