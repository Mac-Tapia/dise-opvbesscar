#!/usr/bin/env python
"""
AnÃ¡lisis completo de duplicaciones de datasets
Verifica quÃ© se puede integrar sin perdida de datos
"""

import json
from pathlib import Path
from collections import defaultdict

# AnÃ¡lisis de referencias de datasets en cÃ³digo
analysis = {
    "CONSTRUCCION (OE2)": {
        "Solar": {
            "PRIMARY": "data/oe2/Generacionsolar/pv_generation_hourly_citylearn_v2.csv",
            "LOCATION": "data/oe2/",
            "PURPOSE": "Generar timeseries solar horaria (8,760 registros)",
            "SIZE": "1.2 MB"
        },
        "BESS": {
            "PRIMARY": "data/oe2/bess/bess_ano_2024.csv",
            "LOCATION": "data/oe2/",
            "PURPOSE": "Especificaciones BESS (1,700 kWh, 400 kW)",
            "SIZE": "1.6 MB"
        },
        "Chargers": {
            "PRIMARY": "data/oe2/chargers/chargers_ev_ano_2024_v3.csv",
            "LOCATION": "data/oe2/",
            "PURPOSE": "19 cargadores Ã— 2 sockets = 38 controlables",
            "SIZE": "15.5 MB"
        },
        "Mall Demand": {
            "PRIMARY": "data/oe2/demandamallkwh/demandamallhorakwh.csv",
            "LOCATION": "data/oe2/",
            "PURPOSE": "Demanda del mall (100 kW base)",
            "SIZE": "0.4 MB"
        }
    },
    "PROCESADOS (INTERIM)": {
        "Solar": {
            "LOCATION": "data/interim/oe2/solar/",
            "STATUS": "VACIO - No copiado",
            "NOTE": "DeberÃ­a tener pv_generation_hourly_citylearn_v2.csv"
        },
        "BESS": {
            "FILE": "data/interim/oe2/bess/bess_hourly_dataset_2024.csv",
            "SIZE": "1.1 MB",
            "NOTE": "VersiÃ³n procesada con 25 columnas"
        },
        "Chargers": {
            "FILE": "data/interim/oe2/chargers/chargers_real_statistics.csv",
            "SIZE": "0.02 MB",
            "NOTE": "Solo estadÃ­sticas, NO datos horarios"
        },
        "Mall": {
            "LOCATION": "data/interim/oe2/demandamallkwh/",
            "STATUS": "VACIO - No copiado"
        }
    },
    "ENTRENAMIENTO (PROCESSED/CITYLEARN)": {
        "Solar": {
            "LOCATION": "data/processed/citylearn/iquitos_ev_mall/",
            "STATUS": "No encontrado como archivo separado",
            "NOTE": "DeberÃ­a estar en observable_variables_v5_5.csv o archivo de observaciones"
        },
        "BESS": {
            "FILES": [
                "bess_ano_2024.csv",
                "bess_daily_balance_24h.csv",
                "bess_energy_balance.csv",
                "bess_soc_profile.csv",
                "bess_storage.csv"
            ],
            "NOTE": "MÃšLTIPLES versiones - POSIBLE DUPLICACIÃ“N"
        },
        "Chargers": {
            "FILES": "charger_simulation_001.csv hasta charger_simulation_128.csv",
            "COUNT": "128 archivos individuales",
            "NOTE": "Simulaciones por socket - ALTAMENTE DUPLICADO"
        },
        "Observations": {
            "FILE": "observable_variables_v5_5.csv",
            "NOTE": "Observaciones compiladas de todos los datasets"
        }
    }
}

# Mostrar anÃ¡lisis
print("\n" + "â•" * 100)
print("ANÃLISIS MATRIZ DE DATASETS: CONSTRUCCIÃ“N â†’ PROCESADOS â†’ ENTRENAMIENTO".center(100))
print("â•" * 100)
print()

for phase, datasets in analysis.items():
    print(f"\nğŸ“‹ {phase}".ljust(100, "â”€"))
    for dataset_type, info in datasets.items():
        print(f"\n  ğŸ”¹ {dataset_type}")
        for key, value in info.items():
            if isinstance(value, list):
                print(f"     {key}: {len(value)} archivos")
            else:
                print(f"     {key}: {value}")

print("\n")
print("â•" * 100)
print("REPORTE DE DUPLICACIONES DETECTADAS".center(100))
print("â•" * 100)

duplications = {
    "BESS": {
        "En OE2": ["data/oe2/bess/bess_ano_2024.csv"],
        "En INTERIM": ["data/interim/oe2/bess/bess_hourly_dataset_2024.csv"],
        "En PROCESSED": ["bess_ano_2024.csv", "bess_daily_balance_24h.csv", "bess_energy_balance.csv", "bess_soc_profile.csv", "bess_storage.csv"],
        "PROBLEMA": "5 archivos BESS diferentes en processed - mismo dataset con diferentes aspectos",
        "RECOMENDACION": "Consolidar a UN archivo bess_compiled.csv"
    },
    "CHARGERS": {
        "En OE2": ["chargers_ev_ano_2024_v3.csv (8,760 Ã— 353 cols)"],
        "En INTERIM": ["chargers_real_statistics.csv (solo estadÃ­sticas)"],
        "En PROCESSED": ["128 archivos charger_simulation_XXX.csv"],
        "PROBLEMA": "128 archivos expandidos (1 por socket Ã— 8,760 horas) - EXTREMADAMENTE REDUNDANTE",
        "RECOMENDACION": "Mantener SOLO data/oe2/chargers/chargers_ev_ano_2024_v3.csv y construir desde allÃ­ on-demand"
    },
    "SOLAR": {
        "En OE2": ["data/oe2/Generacionsolar/pv_generation_hourly_citylearn_v2.csv"],
        "En INTERIM": ["VACIO - deberÃ­a copiar de OE2"],
        "En PROCESSED": ["No como archivo separado - solo en observable_variables"],
        "PROBLEMA": "Solar no estÃ¡ en INTERIM (deberÃ­a estar)",
        "RECOMENDACION": "Copiar solar de OE2 a INTERIM durante construcciÃ³n"
    },
    "MALL": {
        "En OE2": ["data/oe2/demandamallkwh/demandamallhorakwh.csv"],
        "En INTERIM": ["VACIO - deberÃ­a copiar de OE2"],
        "En PROCESSED": ["No como archivo separado"],
        "PROBLEMA": "Mall demand no estÃ¡ en INTERIM",
        "RECOMENDACION": "Copiar mall de OE2 a INTERIM durante construcciÃ³n"
    }
}

for dataset, issue in duplications.items():
    print(f"\nâš ï¸  {dataset}".ljust(100, "â”€"))
    for key, value in issue.items():
        if isinstance(value, list):
            for item in value:
                print(f"   {key}: {item}")
        else:
            print(f"   {key}: {value}")

print("\n")
print("â•" * 100)
print("PLAN DE INTEGRACIÃ“N SIN DUPLICACIONES".center(100))
print("â•" * 100)

plan = """
ARQUITECTURA RECOMENDADA:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

1ï¸âƒ£  CAPA OE2 (DATOS PRIMARIOS - Fuentes de Verdad)
   â”œâ”€ data/oe2/Generacionsolar/pv_generation_hourly_citylearn_v2.csv   (KEEP)
   â”œâ”€ data/oe2/bess/bess_ano_2024.csv                                  (KEEP)
   â”œâ”€ data/oe2/chargers/chargers_ev_ano_2024_v3.csv                    (KEEP)
   â””â”€ data/oe2/demandamallkwh/demandamallhorakwh.csv                   (KEEP)
   
   âš¡ ACCIÃ“N: Estos 4 archivos son INMUTABLES y son la ÃšNICA fuente de verdad
   âš¡ TAMAÃ‘O TOTAL: ~18.7 MB (COMPACTO)

2ï¸âƒ£  CAPA INTERIM (PROCESADOS - Cache)
   â”œâ”€ data/interim/oe2/solar/pv_generation_hourly_citylearn_v2.csv     (COPIAR de OE2)
   â”œâ”€ data/interim/oe2/bess/bess_hourly_dataset_2024.csv               (DERIVAR de OE2)
   â”œâ”€ data/interim/oe2/chargers/chargers_enriched.csv                  (ENRIQUECER con CO2)
   â”œâ”€ data/interim/oe2/demandamallkwh/demandamallhorakwh.csv          (COPIAR de OE2)
   â””â”€ data/interim/oe2/chargers/chargers_real_statistics.csv           (SOLO ESTADÃSTICAS)
   
   âš¡ ACCIÃ“N: Copiar/derivar datos de OE2 con transformaciones mÃ­nimas
   âš¡ PROPÃ“SITO: Cache para construcciÃ³n rÃ¡pida sin recompilaciÃ³n

3ï¸âƒ£  CAPA PROCESSED/CITYLEARN (PARA ENTRENAMIENTO)
   â”œâ”€ data/processed/citylearn/iquitos_ev_mall/
   â”‚  â”œâ”€ observations/observable_variables_v5_5.csv                    (COMPILADO)
   â”‚  â”œâ”€ rewards/reward_signals.csv                                    (COMPILADO)
   â”‚  â”œâ”€ bess/bess_compiled.csv                                        (ÃšNICO)
   â”‚  â”œâ”€ metadata/metadata_complete.json                               (SPECS)
   â”‚  â””â”€ schema.json                                                   (ÃNDICE)
   
   âš¡ ACCIÃ“N: ELIMINAR 128 charger_simulation_XXX.csv (REDUNDANTES)
   âš¡ ACCIÃ“N: CONSOLIDAR 5 BESS en 1 bess_compiled.csv
   âš¡ PROPÃ“SITO: Dataset listo para entrenamiento (observaciones compiladas)

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           CONSOLIDACIÃ“N DE ALMACENAMIENTO (PRE Y POST)                     â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ ANTES:                                                                     â•‘
â•‘   OE2:            18.7 MB  (4 archivos)                                    â•‘
â•‘   INTERIM:        2.1 MB   (5 archivos)                                    â•‘
â•‘   PROCESSED:      127+ MB  (128 chargers + 5 BESS duplicados)              â•‘
â•‘   TOTAL:         ~148 MB   âš ï¸ REDUNDANCIA EXTREMA                          â•‘
â•‘                                                                            â•‘
â•‘ DESPUÃ‰S:                                                                   â•‘
â•‘   OE2:            18.7 MB  (4 archivos FUENTE)                             â•‘
â•‘   INTERIM:        5.2 MB   (5 archivos DERIVADOS EN CACHÃ‰)                 â•‘
â•‘   PROCESSED:      8.5 MB   (observable + reward + metadata, NO 128 CSV)    â•‘
â•‘   TOTAL:         ~32.4 MB  âœ… 78% REDUCCIÃ“N DE TAMAÃ‘O                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ACCIONES CONCRETAS PARA INTEGRACIÃ“N:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

âœ… PASO 1: En data_loader.py â†’ COPIAR OE2 â†’ INTERIM (construcciÃ³n)
   â€¢ load_solar_data() â†’ copia a data/interim/oe2/solar/
   â€¢ load_bess_data() â†’ copia a data/interim/oe2/bess/
   â€¢ load_chargers_data() â†’ enriquece y copia a data/interim/oe2/chargers/
   â€¢ load_mall_demand_data() â†’ copia a data/interim/oe2/demandamallkwh/

âœ… PASO 2: En integrate_datasets.py â†’ COMBINAR INTERIM â†’ observable_variables.csv
   â€¢ Leer 4 archivos de INTERIM
   â€¢ Compilar observaciones + rewards en PROCESSED
   â€¢ Generar schema.json con Ã­ndice de columnas

âŒ PASO 3: ELIMINAR de data/processed/citylearn/iquitos_ev_mall/:
   â€¢ Eliminar charger_simulation_001.csv hasta charger_simulation_128.csv (128 archivos)
   â€¢ Eliminar bess_daily_balance_24h.csv, bess_energy_balance.csv, etc.
   â€¢ Mantener SOLO: observable_variables_v5_5.csv + metadata

SCRIPTS DE LIMPIEZA:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Eliminar 128 charger_simulation_XXX.csv
Get-ChildItem -Path data/processed/citylearn/iquitos_ev_mall/chargers -Filter "charger_simulation_*.csv" | Remove-Item -Force

# Consolidar 5 BESS en 1
python -c "
import pandas as pd; from pathlib import Path
bess_dir = Path('data/processed/citylearn/iquitos_ev_mall/bess')
files = [bess_dir/'bess_ano_2024.csv', bess_dir/'bess_daily_balance_24h.csv', 
         bess_dir/'bess_energy_balance.csv', bess_dir/'bess_soc_profile.csv']
df = pd.concat([pd.read_csv(f) for f in files], axis=1).drop_duplicates(subset=['Timestamp'], keep='first')
df.to_csv(bess_dir/'bess_compiled.csv', index=False)
"

REFERENCIAS EN ENTRENAMIENTOS:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Scripts que USAN datos (requieren actualizaciÃ³n si cambian rutas):
  â€¢ scripts/train/train_ppo_multiobjetivo.py â†’ LÃ­nea 347 (bess from processed)
  â€¢ scripts/train/train_sac_multiobjetivo.py â†’ LÃ­nea 830 (bess from processed)
  â€¢ scripts/train/train_a2c_multiobjetivo.py â†’ LÃ­nea 2026 (bess from interim)

Cambio mÃ­nimo propuesto:
  De: Path('data/processed/citylearn/iquitos_ev_mall/bess/bess_ano_2024.csv')
  A:  Path('data/processed/citylearn/iquitos_ev_mall/bess/bess_compiled.csv')
"""

print(plan)

print("\n" + "â•" * 100)
print("ESTADO FINAL".center(100))
print("â•" * 100)
print("""
âœ… CONSEGUIMOS: 
   â€¢ Dataset de construcciÃ³n (OE2) sin cambios
   â€¢ Cache de construcciÃ³n (INTERIM) de 5.2 MB 
   â€¢ Dataset de entrenamiento compilado (PROCESSED) sin redundacia
   â€¢ 78% reducciÃ³n de tamaÃ±o disco
   â€¢ Flujo claro: OE2 â†’ INTERIM â†’ PROCESSED â†’ Entrenamiento

âš ï¸  IMPORTANTE:
   â€¢ NO duplicar datos entre OE2 e INTERIM (solo copias de construcciÃ³n)
   â€¢ PROCESSED solo contiene observable_variables compilado
   â€¢ Chargers: mantener 1 archivo OE2 (evitar 128 copias)
   â€¢ BESS: consolidar derivados a 1 bess_compiled.csv
""")
