#!/usr/bin/env python3
"""
SCRIPT DE MIGRACIÃ“N: Dataset Builder Consolidado
Actualiza automÃ¡ticamente imports en otros archivos
Date: 2026-02-04
"""

from __future__ import annotations
from pathlib import Path
import re
import logging

logging.basicConfig(level=logging.INFO, format="%(levelname)s | %(message)s")
logger = logging.getLogger(__name__)

# ============================================================================
# CONFIGURACIÃ“N DE MIGRACIÃ“N
# ============================================================================

REPO_ROOT = Path(__file__).parent

# Archivos que usan dataset_builder imports (excepto los que estamos consolidando)
FILES_TO_UPDATE = [
    "src/iquitos_citylearn/oe3/simulate.py",
    "src/iquitos_citylearn/oe3/agent_interface.py",
    "src/metrics/metric/__init__.py",
    "scripts/run_oe3_build_dataset.py",
]

# Mapeo de imports viejos â†’ nuevos
IMPORT_REPLACEMENTS = {
    # dataset_builder.py
    "from src.citylearnv2.dataset_builder.dataset_builder import build_citylearn_dataset":
        "from src.citylearnv2.dataset_builder.dataset_builder_consolidated import build_citylearn_dataset",

    "from src.citylearnv2.dataset_builder import build_citylearn_dataset":
        "from src.citylearnv2.dataset_builder.dataset_builder_consolidated import build_citylearn_dataset",

    # build_citylearn_dataset.py
    "from src.citylearnv2.dataset_builder.build_citylearn_dataset import CityLearnV2DatasetBuilder":
        "from src.citylearnv2.dataset_builder.dataset_builder_consolidated import CityLearnV2DatasetBuilder",

    # data_loader.py
    "from src.citylearnv2.dataset_builder.data_loader import OE2DataLoader":
        "from src.citylearnv2.dataset_builder.dataset_builder_consolidated import OE2DataLoader",

    "from src.citylearnv2.dataset_builder.data_loader import OE2DataLoaderException":
        "from src.citylearnv2.dataset_builder.dataset_builder_consolidated import OE2DataLoaderException",

    # validate_citylearn_build.py
    "from src.citylearnv2.dataset_builder.validate_citylearn_build import CityLearnDataValidator":
        "from src.citylearnv2.dataset_builder.dataset_builder_consolidated import CityLearnDataValidator",
}

# ============================================================================
# FUNCIONES DE MIGRACIÃ“N
# ============================================================================

def check_file_exists(file_path: Path) -> bool:
    """Verifica si un archivo existe."""
    if file_path.exists():
        logger.info(f"âœ… Encontrado: {file_path}")
        return True
    else:
        logger.warning(f"âš ï¸  No encontrado: {file_path}")
        return False


def read_file(file_path: Path) -> str | None:
    """Lee el contenido de un archivo."""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    except Exception as e:
        logger.error(f"âŒ Error leyendo {file_path}: {e}")
        return None


def write_file(file_path: Path, content: str) -> bool:
    """Escribe contenido en un archivo."""
    try:
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
        return True
    except Exception as e:
        logger.error(f"âŒ Error escribiendo {file_path}: {e}")
        return False


def migrate_imports_in_file(file_path: Path) -> int:
    """
    Migra imports en un archivo individual.
    Retorna: nÃºmero de replacements realizados
    """
    logger.info(f"\nðŸ“ Procesando: {file_path}")

    content = read_file(file_path)
    if content is None:
        return 0

    original_content = content
    replacement_count = 0

    # Realizar replacements
    for old_import, new_import in IMPORT_REPLACEMENTS.items():
        if old_import in content:
            content = content.replace(old_import, new_import)
            replacement_count += 1
            logger.info(f"  âœ… Replaced: {old_import[:60]}...")

    # Si hubo cambios, guardar
    if replacement_count > 0:
        if write_file(file_path, content):
            logger.info(f"  âœ… {file_path} actualizado ({replacement_count} changes)")
            return replacement_count
        else:
            logger.error(f"  âŒ Error guardando {file_path}")
            return 0
    else:
        logger.info(f"  â„¹ï¸  No changes needed in {file_path}")
        return 0


def show_migration_plan() -> None:
    """Muestra el plan de migraciÃ³n."""
    print("\n" + "="*80)
    print("ðŸ“‹ PLAN DE MIGRACIÃ“N: Dataset Builder Consolidado")
    print("="*80)
    print("\n1. ARCHIVOS A ACTUALIZAR:")
    for i, file_path in enumerate(FILES_TO_UPDATE, 1):
        full_path = REPO_ROOT / file_path
        exists = "âœ…" if full_path.exists() else "âš ï¸"
        print(f"   {i}. {exists} {file_path}")

    print("\n2. IMPORTS QUE SERÃN MIGRADOS:")
    for i, (old, new) in enumerate(IMPORT_REPLACEMENTS.items(), 1):
        print(f"   {i}. {old[:70]}")
        print(f"      â†’ {new[:70]}")

    print("\n3. ARCHIVOS A ELIMINAR (OPCIONAL):")
    old_files = [
        "src/citylearnv2/dataset_builder/build_oe3_dataset.py",
        "src/citylearnv2/dataset_builder/generate_pv_dataset_citylearn.py",
    ]
    for file_path in old_files:
        print(f"   â€¢ {file_path} (OBSOLETO)")

    print("\n4. ARCHIVOS A DEPRECAR (OPCIONAL):")
    deprecate_files = [
        "src/citylearnv2/dataset_builder/dataset_builder.py",
        "src/citylearnv2/dataset_builder/build_citylearn_dataset.py",
        "src/citylearnv2/dataset_builder/data_loader.py",
        "src/citylearnv2/dataset_builder/validate_citylearn_build.py",
    ]
    for file_path in deprecate_files:
        print(f"   â€¢ {file_path} (Usar dataset_builder_consolidated.py)")

    print("\n" + "="*80)


def migrate_all() -> None:
    """Ejecuta la migraciÃ³n completa."""
    print("\nðŸš€ INICIANDO MIGRACIÃ“N...")

    total_changes = 0
    successful_files = 0

    for file_path_str in FILES_TO_UPDATE:
        file_path = REPO_ROOT / file_path_str

        if not file_path.exists():
            logger.warning(f"â­ï¸  Saltando (no existe): {file_path}")
            continue

        changes = migrate_imports_in_file(file_path)
        if changes > 0:
            total_changes += changes
            successful_files += 1

    print("\n" + "="*80)
    print("ðŸ“Š RESULTADOS DE MIGRACIÃ“N")
    print("="*80)
    print(f"Archivos procesados: {successful_files}")
    print(f"Total de cambios: {total_changes}")

    if total_changes > 0:
        print("\nâœ… MIGRACIÃ“N COMPLETADA EXITOSAMENTE")
        print("\nProximos pasos:")
        print("  1. Ejecutar tests: python -m pytest tests/ -v")
        print("  2. Verificar imports: python -c 'from src.citylearnv2.dataset_builder.dataset_builder_consolidated import build_citylearn_dataset; print(\"OK\")'")
        print("  3. (Opcional) Eliminar archivos antiguos")
    else:
        print("\nâš ï¸  No se realizaron cambios. Verifica que los archivos existen.")

    print("\n" + "="*80)


def cleanup_old_files(dry_run: bool = True) -> None:
    """
    Elimina archivos antiguos (CUIDADO: es destructivo)

    Args:
        dry_run: Si True, solo muestra quÃ© se eliminarÃ­a
    """
    old_files = [
        "src/citylearnv2/dataset_builder/build_oe3_dataset.py",
        "src/citylearnv2/dataset_builder/generate_pv_dataset_citylearn.py",
        "src/citylearnv2/dataset_builder/dataset_builder.py",
        "src/citylearnv2/dataset_builder/build_citylearn_dataset.py",
        "src/citylearnv2/dataset_builder/data_loader.py",
        "src/citylearnv2/dataset_builder/validate_citylearn_build.py",
    ]

    print("\n" + "="*80)
    if dry_run:
        print("ðŸ” DRY-RUN: Archivos que PODRÃAN eliminarse")
    else:
        print("âš ï¸  CUIDADO: Eliminando archivos antiguos")
    print("="*80)

    for file_path_str in old_files:
        file_path = REPO_ROOT / file_path_str

        if file_path.exists():
            if dry_run:
                logger.info(f"[DRY-RUN] EliminarÃ­a: {file_path}")
            else:
                try:
                    file_path.unlink()
                    logger.info(f"âœ… Eliminado: {file_path}")
                except Exception as e:
                    logger.error(f"âŒ Error eliminando {file_path}: {e}")
        else:
            logger.info(f"â„¹ï¸  No existe (saltando): {file_path}")

    print("\n" + "="*80)


# ============================================================================
# MAIN
# ============================================================================

if __name__ == "__main__":
    import sys

    # Mostrar plan
    show_migration_plan()

    # Ejecutar migraciÃ³n
    if len(sys.argv) > 1 and sys.argv[1] == "--force":
        logger.info("Ejecutando migraciÃ³n...")
        migrate_all()
    else:
        print("\nâš ï¸  MODO PREVIEW (sin cambios reales)")
        print("   Para ejecutar la migraciÃ³n, usa: python migrate_dataset_builder.py --force")

        # Preview de cambios
        print("\nðŸ” PREVIEW DE CAMBIOS:")
        for file_path_str in FILES_TO_UPDATE:
            file_path = REPO_ROOT / file_path_str
            if file_path.exists():
                content = read_file(file_path)
                if content:
                    changes = sum(1 for old_import in IMPORT_REPLACEMENTS if old_import in content)
                    if changes > 0:
                        print(f"  {file_path}: {changes} import(s) que cambiarÃ­an")

    # OpciÃ³n de cleanup
    print("\nðŸ§¹ LIMPIEZA DE ARCHIVOS ANTIGUOS")
    print("   Para ver quÃ© se eliminarÃ­a: python migrate_dataset_builder.py --cleanup-preview")
    print("   Para eliminar archivos: python migrate_dataset_builder.py --cleanup-force")

    if len(sys.argv) > 1 and sys.argv[1] == "--cleanup-preview":
        cleanup_old_files(dry_run=True)
    elif len(sys.argv) > 1 and sys.argv[1] == "--cleanup-force":
        cleanup_old_files(dry_run=False)
