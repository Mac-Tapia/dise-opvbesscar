"""
================================================================================
BUILD CITYLEARN V2 DATASET - INTEGRATION SCRIPT
================================================================================

Construye el dataset completo de CityLearn v2 integrando:
1. ‚úÖ Solar generation: data/oe2/Generacionsolar/pv_generation_hourly_citylearn_v2.csv
2. ‚úÖ EV charger profiles: 128 chargers (32 base units x 4 sockets)
3. ‚úÖ Mall load: 100 kW constant demand
4. ‚úÖ BESS: 4,520 kWh, 2,000 kW
5. ‚úÖ Grid carbon intensity: 0.4521 kg CO‚ÇÇ/kWh (Iquitos thermal)

Salida:
- Dataset listo para CityLearn v2 simulation
- 8,760 timesteps (1 hora cada uno)
- 394-dim observations + 129-dim actions
- Multi-objective rewards (CO‚ÇÇ, solar, cost, EV, grid)

================================================================================
"""

from __future__ import annotations

from pathlib import Path
from typing import Optional, Dict, Any, Tuple, List
import logging
import json
from datetime import datetime

import pandas as pd
import numpy as np

# Import from dataset_builder
from .data_loader import OE2DataLoader, OE2ValidationError
from .dataset_builder import _load_oe2_artifacts, _validate_solar_timeseries_hourly

logger = logging.getLogger(__name__)


class CityLearnV2DatasetBuilder:
    """Constructor de dataset CityLearn v2 integrado con OE2."""

    def __init__(self, project_root: Optional[Path] = None):
        """Inicializa builder.

        Args:
            project_root: Ra√≠z del proyecto (auto-detecta si None)
        """
        if project_root is None:
            project_root = Path(__file__).parent.parent.parent.parent

        self.project_root = Path(project_root)
        self.data_dir = self.project_root / "data"
        # OE2 puede estar en data/interim/oe2 o data/oe2
        self.oe2_dir = self.data_dir / "oe2"
        if not self.oe2_dir.exists():
            self.oe2_dir = self.data_dir / "interim" / "oe2"

        # Paths a subdirectorios cr√≠ticos
        self.generacionsolar_dir = self.oe2_dir / "Generacionsolar"
        self.chargers_dir = self.oe2_dir / "chargers"
        self.bess_dir = self.oe2_dir / "bess"

    def load_solar_generation(self) -> pd.DataFrame:
        """Carga datos de generaci√≥n solar horarios.

        Raises:
            FileNotFoundError: Si no existe pv_generation_hourly_citylearn_v2.csv
            ValueError: Si no tiene exactamente 8,760 registros
        """
        solar_csv = self.generacionsolar_dir / "pv_generation_hourly_citylearn_v2.csv"

        if not solar_csv.exists():
            raise FileNotFoundError(
                f"[ERROR] Solar dataset not found: {solar_csv}\n"
                f"Ejecutar primero: python generate_pv_dataset_citylearn.py"
            )

        logger.info(f"[SOLAR] Cargando desde: {solar_csv}")
        df_solar = pd.read_csv(solar_csv)

        # Validar estructura
        _validate_solar_timeseries_hourly(df_solar)

        # Validar columnas cr√≠ticas
        required_cols = ['timestamp', 'ac_power_kw', 'ac_energy_kwh', 'temp_air_c', 'wind_speed_ms']
        for col in required_cols:
            if col not in df_solar.columns:
                raise ValueError(f"[ERROR] Columna requerida no encontrada: {col}")

        logger.info(f"[SOLAR] ‚úÖ Cargado: {len(df_solar)} registros")
        logger.info(f"        Potencia AC m√°x: {df_solar['ac_power_kw'].max():.1f} kW")
        logger.info(f"        Potencia AC prom: {df_solar['ac_power_kw'].mean():.1f} kW")
        logger.info(f"        Energ√≠a AC anual: {df_solar['ac_energy_kwh'].sum():.0f} kWh")

        return df_solar

    def load_charger_profiles(self) -> Tuple[pd.DataFrame, list]:
        """Carga perfiles de chargers (128 sockets).

        Returns:
            Tuple of (DataFrame 8760 rows x 128 chargers, List of 128 chargers metadata)
        """
        try:
            loader = OE2DataLoader(self.oe2_dir)

            # Cargar definiciones de chargers
            chargers = loader.load_individual_chargers()
            logger.info(f"[CHARGERS] Cargados: {len(chargers)} chargers individuales")

            # Cargar perfiles horarios
            profiles = loader.load_charger_hourly_profiles()
            logger.info(f"[CHARGERS] Perfiles cargados: {profiles.shape}")

            return profiles, chargers

        except OE2ValidationError as e:
            logger.error(f"[CHARGERS] Construcci√≥n con fallback (OE2 error): {e}")
            # Fallback: generar perfiles sint√©ticos
            logger.info("[CHARGERS] Generando perfiles sint√©ticos...")

            # 128 chargers: 112 motos (2 kW) + 16 mototaxis (3 kW)
            chargers = []
            for i in range(112):
                chargers.append({
                    'charger_id': i,
                    'power_kw': 2.0,
                    'type': 'moto',
                    'playa': f'Playa_Motos'
                })
            for i in range(16):
                chargers.append({
                    'charger_id': 112 + i,
                    'power_kw': 3.0,
                    'type': 'mototaxi',
                    'playa': f'Playa_Mototaxis'
                })

            logger.info(f"[CHARGERS] Generados: {len(chargers)} chargers sint√©ticos")

            # Generar perfiles sint√©ticos (demanda variable horaria)
            profiles = pd.DataFrame(
                np.random.uniform(0.2, 1.0, size=(8760, 128)),
                columns=[f'charger_{i}' for i in range(128)]
            )

            logger.info(f"[CHARGERS] Perfiles sint√©ticos: {profiles.shape}")

            return profiles, chargers

    def load_bess_config(self) -> dict:
        """Carga configuraci√≥n de BESS.

        Returns:
            Dict con capacity_kwh y power_kw
        """
        bess_config = {
            'capacity_kwh': 4520.0,  # OE2 dimensionamiento
            'power_kw': 2000.0,      # OE2 dimensionamiento
            'efficiency': 0.95,
        }

        logger.info(f"[BESS] Capacidad: {bess_config['capacity_kwh']:.0f} kWh")
        logger.info(f"[BESS] Potencia: {bess_config['power_kw']:.0f} kW")

        return bess_config

    def load_solar_data(self) -> pd.DataFrame:
        """Alias para load_solar_generation (compatibilidad)."""
        return self.load_solar_generation()

    def load_mall_load(self) -> pd.Series:
        """Carga demanda del mall.

        Returns:
            Series de 8760 valores (100 kW constante)
        """
        # Mall demand es constante: 100 kW
        mall_load = pd.Series([100.0] * 8760)
        logger.info(f"[MALL] Cargada: demanda constante 100 kW")
        logger.info(f"[MALL] Energ√≠a anual: {mall_load.sum():.0f} kWh")
        return mall_load

    def generate_schema_json(
        self,
        solar_df: pd.DataFrame,
        charger_profiles: pd.DataFrame,
        chargers: List[Dict[str, Any]],
        output_dir: Path
    ) -> Dict[str, Any]:
        """Genera schema.json para CityLearn v2.

        Args:
            solar_df: Datos solares
            charger_profiles: Perfiles de chargers (8760 x 128)
            chargers: Metadatos de chargers
            output_dir: Directorio de salida

        Returns:
            Dict con schema para CityLearn
        """
        # Crear directorio de dataset
        dataset_dir = output_dir / "dataset"
        dataset_dir.mkdir(parents=True, exist_ok=True)

        # Guardar archivos de datos
        solar_path = dataset_dir / "solar_generation.csv"
        charger_path = dataset_dir / "charger_load.csv"
        mall_path = dataset_dir / "mall_load.csv"

        # Preparar datos
        solar_save = solar_df[['timestamp', 'ac_power_kw', 'ghi_wm2', 'dni_wm2', 'dhi_wm2', 'temp_air_c', 'wind_speed_ms']].copy()
        solar_save.to_csv(solar_path, index=False)
        logger.info(f"[SCHEMA] Solar CSV guardado: {solar_path}")

        charger_profiles.to_csv(charger_path, index=False)
        logger.info(f"[SCHEMA] Charger profiles CSV guardado: {charger_path}")

        mall_df = pd.DataFrame({
            'timestamp': solar_df['timestamp'],
            'mall_demand_kw': [100.0] * len(solar_df)
        })
        mall_df.to_csv(mall_path, index=False)
        logger.info(f"[SCHEMA] Mall load CSV guardado: {mall_path}")

        # Crear schema.json
        schema = {
            "schema": "V3.7",
            "timestamp": datetime.utcnow().isoformat(),
            "duration": {
                "step_size_seconds": 3600,  # 1 hour
                "total_steps": 8760,
                "episode_duration_steps": 8760  # Full year
            },
            "root_directory": str(dataset_dir),
            "buildings": [
                {
                    "name": "Building_EV_Iquitos",
                    "energy_simulation": "solar_generation.csv",
                    "solar_generation": {
                        "path": "solar_generation.csv",
                        "column": "ac_power_kw",
                        "unit": "kW"
                    },
                    "environmental_conditions": {
                        "weather_file": "solar_generation.csv",
                        "columns": {
                            "temperature": "temp_air_c",
                            "wind_speed": "wind_speed_ms"
                        }
                    },
                    "electrical_storage": {
                        "capacity": 4520.0,
                        "max_power_output": 2000.0,
                        "max_power_input": 2000.0,
                        "efficiency": 0.95,
                        "initial_soc": 0.5
                    },
                    "controllable_loads": [
                        {
                            "name": "EV_Chargers_128",
                            "path": "charger_load.csv",
                            "columns": list(range(128)),
                            "unit": "kW"
                        },
                        {
                            "name": "Mall_Load",
                            "path": "mall_load.csv",
                            "column": "mall_demand_kw",
                            "unit": "kW"
                        }
                    ]
                }
            ],
            "reward": {
                "type": "multi_objective",
                "weights": {
                    "co2": 0.50,
                    "solar_utilization": 0.20,
                    "cost": 0.10,
                    "ev_satisfaction": 0.10,
                    "grid_stability": 0.10
                },
                "carbon_intensity": {
                    "value": 0.4521,
                    "unit": "kg_CO2/kWh",
                    "source": "Iquitos thermal grid"
                }
            },
            "metadata": {
                "location": "Iquitos, Peru",
                "latitude": -3.75,
                "longitude": -73.25,
                "altitude_m": 104.0,
                "solar_capacity_kw": 4050.0,
                "solar_model": "Sandia SAPM",
                "solar_data_source": "PVGIS TMY (REAL meteorological)",
                "chargers_total": 128,
                "chargers_motos": 112,
                "chargers_mototaxis": 16,
                "bess_capacity_kwh": 4520.0,
                "bess_power_kw": 2000.0,
                "mall_demand_kw": 100.0,
                "ev_demand_kw": 50.0,
                "generation_date": datetime.utcnow().isoformat()
            }
        }

        schema_path = output_dir / "schema.json"
        with open(schema_path, 'w') as f:
            json.dump(schema, f, indent=2)

        logger.info(f"[SCHEMA] schema.json generado: {schema_path}")

        return schema

    def build_complete_dataset(self, output_dir: Optional[Path] = None) -> Dict[str, Any]:
        """Construye dataset completo.

        Args:
            output_dir: Directorio de salida (default: src/citylearnv2/dataset/)

        Returns:
            Dict con metadata y paths
        """
        if output_dir is None:
            output_dir = self.project_root / "src" / "citylearnv2" / "dataset"

        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)

        logger.info("=" * 80)
        logger.info("CONSTRUYENDO DATASET CITYLEARN V2")
        logger.info("=" * 80)

        try:
            # 1. Cargar datos solares
            logger.info("\n[STEP 1] Cargando datos solares...")
            solar_df = self.load_solar_data()

            # 2. Cargar perfiles de chargers
            logger.info("\n[STEP 2] Cargando perfiles de chargers...")
            charger_profiles, chargers = self.load_charger_profiles()

            # 3. Cargar demanda del mall
            logger.info("\n[STEP 3] Cargando demanda del mall...")
            mall_load = self.load_mall_load()

            # 4. Cargar config de BESS
            logger.info("\n[STEP 4] Cargando configuraci√≥n de BESS...")
            bess_config = self.load_bess_config()

            # 5. Generar schema.json
            logger.info("\n[STEP 5] Generando schema.json...")
            schema = self.generate_schema_json(
                solar_df,
                charger_profiles,
                chargers,
                output_dir
            )

            # Resumen final
            logger.info("\n" + "=" * 80)
            logger.info("‚úÖ DATASET CITYLEARN V2 CONSTRUIDO EXITOSAMENTE")
            logger.info("=" * 80)
            logger.info(f"\nüìç Ubicaci√≥n: {output_dir}")
            logger.info(f"üìä Timesteps: 8,760 (1 a√±o, resoluci√≥n horaria)")
            logger.info(f"üîã Observaci√≥n dim: 394")
            logger.info(f"üéÆ Acci√≥n dim: 129 (1 BESS + 128 chargers)")
            logger.info(f"\nüìã Datos:")
            logger.info(f"   ‚òÄÔ∏è  Solar anual: {solar_df['ac_energy_kwh'].sum():.0f} kWh")
            logger.info(f"   üè¢ Mall anual: {mall_load.sum():.0f} kWh")
            logger.info(f"   üîå Chargers: {len(chargers)} (112 motos + 16 mototaxis)")
            logger.info(f"   üîã BESS: {bess_config['capacity_kwh']:.0f} kWh, {bess_config['power_kw']:.0f} kW")
            logger.info(f"   üåç CO‚ÇÇ grid: 0.4521 kg CO‚ÇÇ/kWh (Iquitos thermal)")
            logger.info("\n‚ú® Listo para OE3 training (SAC/PPO/A2C)")

            return {
                'output_dir': str(output_dir),
                'schema_path': str(output_dir / "schema.json"),
                'dataset_dir': str(output_dir / "dataset"),
                'solar_records': len(solar_df),
                'chargers': len(chargers),
                'bess_capacity_kwh': bess_config['capacity_kwh'],
                'solar_annual_kwh': solar_df['ac_energy_kwh'].sum(),
                'timestamp': datetime.utcnow().isoformat()
            }

        except Exception as e:
            logger.error(f"\n‚ùå ERROR durante construcci√≥n: {e}", exc_info=True)
            raise


def main():
    """Script de l√≠nea de comandos."""
    import sys

    # Auto-detectar root
    project_root = Path(__file__).parent.parent.parent.parent

    logger.info(f"\n{'='*80}")
    logger.info("BUILD CITYLEARN V2 DATASET - MAIN")
    logger.info(f"{'='*80}\n")
    logger.info(f"Project root: {project_root}\n")

    builder = CityLearnV2DatasetBuilder(project_root)
    result = builder.build_complete_dataset()

    logger.info(f"\n{'='*80}")
    logger.info("RESULTADO FINAL:")
    logger.info(f"{'='*80}")
    for key, value in result.items():
        logger.info(f"{key:.<40} {value}")


if __name__ == "__main__":
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s | %(levelname)-8s | %(name)s | %(message)s"
    )
    main()
