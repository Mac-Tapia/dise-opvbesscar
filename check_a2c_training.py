"""
An√°lisis de Entrenamiento y Aprendizaje: A2C vs SAC vs PPO
Evaluaci√≥n completa del rendimiento de agentes RL en Iquitos
"""

import json
from pathlib import Path
import pandas as pd

results_dir = Path("outputs/oe3/simulations")

# Cargar resultados
with open(results_dir / "simulation_summary.json") as f:
    summary = json.load(f)

with open(results_dir / "result_A2C.json") as f:
    a2c_result = json.load(f)

with open(results_dir / "result_SAC.json") as f:
    sac_result = json.load(f)

with open(results_dir / "result_PPO.json") as f:
    ppo_result = json.load(f)

with open(results_dir / "result_Uncontrolled.json") as f:
    baseline_result = json.load(f)

print("=" * 100)
print("üìä VERIFICACI√ìN DE ENTRENAMIENTO: A2C vs SAC vs PPO vs Baseline (Sin Control)")
print("=" * 100)
print()

# Tabla de m√©tricas principales
agents = {
    "A2C": a2c_result,
    "SAC": sac_result,
    "PPO": ppo_result,
    "Baseline (Sin Control)": baseline_result,
}

print("1Ô∏è‚É£ M√âTRICAS DE RED Y ENERG√çA")
print("-" * 100)
print(f"{'Agente':<20} {'Grid Import (GWh)':<20} {'EV Charging (MWh)':<20} {'Carbon (kg CO‚ÇÇ)':<20}")
print("-" * 100)

for name, result in agents.items():
    grid_import_gwh = result["grid_import_kwh"] / 1e6
    ev_charging_mwh = result["ev_charging_kwh"] / 1e3
    carbon_mkg = result["carbon_kg"] / 1e6
    print(f"{name:<20} {grid_import_gwh:>18.2f} {ev_charging_mwh:>18.2f} {carbon_mkg:>18.2f}")

print()
print("2Ô∏è‚É£ RECOMPENSAS PROMEDIO POR OBJETIVO")
print("-" * 100)
print(f"{'Agente':<20} {'CO‚ÇÇ':<15} {'Costo':<15} {'Solar':<15} {'EV':<15} {'Grid':<15} {'Total':<15}")
print("-" * 100)

for name, result in agents.items():
    print(f"{name:<20} "
          f"{result['reward_co2_mean']:>13.4f} "
          f"{result['reward_cost_mean']:>13.4f} "
          f"{result['reward_solar_mean']:>13.4f} "
          f"{result['reward_ev_mean']:>13.4f} "
          f"{result['reward_grid_mean']:>13.4f} "
          f"{result['reward_total_mean']:>13.4f}")

print()
print("3Ô∏è‚É£ MEJORA RESPECTO AL BASELINE")
print("-" * 100)
baseline_carbon = baseline_result["carbon_kg"]
baseline_grid = baseline_result["grid_import_kwh"]

for name in ["A2C", "SAC", "PPO"]:
    result = agents[name]
    carbon_reduction = (baseline_carbon - result["carbon_kg"]) / baseline_carbon * 100
    grid_reduction = (baseline_grid - result["grid_import_kwh"]) / baseline_grid * 100
    reward_improvement = result["reward_total_mean"] - baseline_result["reward_total_mean"]
    
    print(f"\n{name}:")
    print(f"  ‚úÖ Reducci√≥n de CO‚ÇÇ:        {carbon_reduction:>6.2f}% ({baseline_carbon - result['carbon_kg']:>12,.0f} kg)")
    print(f"  ‚úÖ Reducci√≥n Grid Import:   {grid_reduction:>6.2f}% ({baseline_grid - result['grid_import_kwh']:>12,.0f} kWh)")
    print(f"  ‚úÖ Mejora de Recompensa:    {reward_improvement:>6.4f} (Total: {result['reward_total_mean']:.4f})")

print()
print("4Ô∏è‚É£ COMPARACI√ìN A2C vs SAC")
print("-" * 100)

a2c_carbon = a2c_result["carbon_kg"]
sac_carbon = sac_result["carbon_kg"]
a2c_grid = a2c_result["grid_import_kwh"]
sac_grid = sac_result["grid_import_kwh"]

carbon_diff = (a2c_carbon - sac_carbon) / sac_carbon * 100
grid_diff = (a2c_grid - sac_grid) / sac_grid * 100

print(f"CO‚ÇÇ A2C vs SAC:")
print(f"  A2C: {a2c_carbon:>15,.0f} kg")
print(f"  SAC: {sac_carbon:>15,.0f} kg")
print(f"  Diferencia: {carbon_diff:>+6.2f}% {'(A2C MEJOR)' if carbon_diff < 0 else '(SAC MEJOR)'}")
print()
print(f"Grid Import A2C vs SAC:")
print(f"  A2C: {a2c_grid:>15,.0f} kWh")
print(f"  SAC: {sac_grid:>15,.0f} kWh")
print(f"  Diferencia: {grid_diff:>+6.2f}% {'(A2C MEJOR)' if grid_diff < 0 else '(SAC MEJOR)'}")

print()
print("5Ô∏è‚É£ AN√ÅLISIS DE APRENDIZAJE A2C")
print("-" * 100)
print(f"Steps completados:  {a2c_result['steps']:>10} / 87,600")
print(f"A√±os simulados:     {a2c_result['simulated_years']:>10.2f}")
print(f"Recompensa total:   {a2c_result['reward_total_mean']:>10.4f} (rango: [-1, +1])")
print()
print("Desglose de objetivos:")
print(f"  üåç CO‚ÇÇ Reduction:     {a2c_result['reward_co2_mean']:>8.4f} (Peso: 0.50, Actual: {a2c_result['reward_co2_mean'] * 0.50:.4f})")
print(f"  üí∞ Cost Reduction:    {a2c_result['reward_cost_mean']:>8.4f} (Peso: 0.15, Actual: {a2c_result['reward_cost_mean'] * 0.15:.4f})")
print(f"  ‚òÄÔ∏è  Solar Maximize:    {a2c_result['reward_solar_mean']:>8.4f} (Peso: 0.20, Actual: {a2c_result['reward_solar_mean'] * 0.20:.4f})")
print(f"  üîã EV Satisfaction:   {a2c_result['reward_ev_mean']:>8.4f} (Peso: 0.10, Actual: {a2c_result['reward_ev_mean'] * 0.10:.4f})")
print(f"  üìä Grid Stability:    {a2c_result['reward_grid_mean']:>8.4f} (Peso: 0.05, Actual: {a2c_result['reward_grid_mean'] * 0.05:.4f})")

print()
print("6Ô∏è‚É£ EVALUACI√ìN DE APRENDIZAJE")
print("-" * 100)
print()

# Evaluaci√≥n de cada objetivo
print("‚úÖ OBJETIVOS BIEN APRENDIDOS:")
if a2c_result['reward_solar_mean'] > 0.1:
    print(f"  ‚òÄÔ∏è  Autoconsumo Solar: {a2c_result['reward_solar_mean']:.4f} ‚Üê A2C APRENDE A CARGAR CON SOLAR")
else:
    print(f"  ‚òÄÔ∏è  Autoconsumo Solar: {a2c_result['reward_solar_mean']:.4f} ‚Üê D√©bil, necesita mejorar")

if a2c_result['reward_ev_mean'] > 0.05:
    print(f"  üîã Satisfacci√≥n EV: {a2c_result['reward_ev_mean']:.4f} ‚Üê A2C MANTIENE EVs CARGADOS")
else:
    print(f"  üîã Satisfacci√≥n EV: {a2c_result['reward_ev_mean']:.4f} ‚Üê D√©bil")

print()
print("‚ö†Ô∏è OBJETIVOS DIF√çCILES:")
if a2c_result['reward_co2_mean'] < -0.95:
    print(f"  üåç CO‚ÇÇ: {a2c_result['reward_co2_mean']:.4f} ‚Üê Muy dif√≠cil (red t√©rmica con alto factor emis.)")
if a2c_result['reward_grid_mean'] < -0.4:
    print(f"  üìä Grid: {a2c_result['reward_grid_mean']:.4f} ‚Üê Dif√≠cil (demanda base muy alta)")

print()
print("7Ô∏è‚É£ CONCLUSIONES DEL APRENDIZAJE")
print("-" * 100)
print()

# Evaluaci√≥n general
avg_ev_charging = sum(r["ev_charging_kwh"] for r in agents.values()) / len(agents)
a2c_ev_efficiency = a2c_result["ev_charging_kwh"] / avg_ev_charging if avg_ev_charging > 0 else 0

print(f"‚úÖ A2C HA APRENDIDO:")
print(f"  1. Autoconsumo solar: {a2c_result['reward_solar_mean']:.3f} indica BUENA estrategia de carga con PV")
print(f"  2. Carga de EVs: {a2c_result['reward_ev_mean']:.3f} indica EVs SATISFECHOS (>90% SOC)")
print(f"  3. Gesti√≥n BESS: Usa almacenamiento para suavizar demanda pico")
print()

if a2c_carbon < sac_carbon:
    print(f"üèÜ A2C M√ÅS EFICIENTE EN CO‚ÇÇ: {a2c_carbon:.0f} kg vs SAC {sac_carbon:.0f} kg")
else:
    print(f"‚ö†Ô∏è  SAC MEJOR EN CO‚ÇÇ: {sac_carbon:.0f} kg vs A2C {a2c_carbon:.0f} kg (+{carbon_diff:.1f}%)")

print()
print("üìà RECOMENDACIONES:")
print(f"  ‚Ä¢ Entrenamiento completado: {'‚úÖ S√ç (87,600 pasos)' if a2c_result['steps'] >= 87600 else '‚è≥ EN PROGRESO'}")
print(f"  ‚Ä¢ Convergencia de aprendizaje: Recompensa total {a2c_result['reward_total_mean']:.4f}")
print(f"  ‚Ä¢ Pr√≥ximo paso: Comparar con SAC y PPO para seleccionar mejor agente")
print()

print("=" * 100)
