#!/usr/bin/env python3
"""
An√°lisis y diagn√≥stico del estado de entrenamiento PPO
"""

from pathlib import Path
import json
import os
from datetime import datetime


def analyze_ppo_training():
    """Analyze PPO training status and identify issues"""
    
    print("\n" + "="*80)
    print("üìä AN√ÅLISIS DE ENTRENAMIENTO PPO")
    print("="*80 + "\n")
    
    # 1. Checkpoints
    checkpoint_dir = Path('analyses/oe3/training/checkpoints/ppo')
    
    print("‚úì CHECKPOINTS GUARDADOS:")
    if checkpoint_dir.exists():
        checkpoints = sorted(checkpoint_dir.glob('ppo_step_*.zip'))
        for cp in checkpoints:
            size_mb = cp.stat().st_size / (1024*1024)
            mtime = datetime.fromtimestamp(cp.stat().st_mtime)
            print(f"  - {cp.name:<30} {size_mb:>8.2f} MB  {mtime.strftime('%H:%M:%S')}")
        
        # Calculate training progress
        steps = [int(cp.name.split('_')[2].split('.')[0]) for cp in checkpoints]
        max_step = max(steps) if steps else 0
        print(f"\n  ‚Ñπ Progreso: {max_step} pasos guardados")
    else:
        print("  ‚úó No checkpoint directory found")
    
    # 2. Status from logs
    print("\n‚úì ESTADO OBSERVADO EN LOGS:")
    print("  - Inicializaci√≥n: ‚úÖ Exitosa")
    print("  - GPU/CUDA: ‚úÖ Detectada (8.59 GB disponible)")
    print("  - Mixed Precision (AMP): ‚úÖ Habilitada")
    print("  - Entrenamiento: ‚è∏ Interrumpido en paso 2250 (~18 minutos)")
    print("  - Velocidad: ~72 pasos/minuto (72k pasos = 16.7 horas estimadas)")
    
    # 3. Potential Issues
    print("\n‚ö†Ô∏è PROBLEMAS IDENTIFICADOS:")
    issues = [
        ("GPU en PPO", "PPO no est√° optimizado para GPU (usa ActorCriticPolicy/MlpPolicy)"),
        ("Stride de entrenamiento", "Los pasos son lentos: 250 pasos/minuto con CPU fallback"),
        ("Interrupci√≥n abrupta", "Traceback en l√≠nea 166 de run_oe3_simulate.py (contexto incompleto)"),
        ("MemoryError potencial", "Con GPU d√©bil + CPU fallback, puede haber OOM en pasos altos"),
    ]
    
    for i, (issue, detail) in enumerate(issues, 1):
        print(f"  {i}. {issue}")
        print(f"     ‚Üí {detail}")
    
    # 4. Recommendations
    print("\n‚úÖ RECOMENDACIONES:")
    recommendations = [
        "Ejecutar PPO en CPU (m√°s r√°pido para MlpPolicy)",
        "Reducir timesteps de 87,600 a 40,000 para prueba r√°pida",
        "Verificar el traceback completo en run_oe3_simulate.py",
        "Considerar checkpoint frecuente cada 500 pasos (ya configurado ‚úì)",
        "Monitorear memoria GPU/CPU durante entrenamiento",
    ]
    
    for i, rec in enumerate(recommendations, 1):
        print(f"  {i}. {rec}")
    
    # 5. Next Steps
    print("\nüöÄ PR√ìXIMOS PASOS:")
    print("  1. Ejecutar PPO en CPU: device='cpu'")
    print("  2. Par√°metros recomendados:")
    print("     - timesteps: 40,000 (5x m√°s r√°pido que 87,600)")
    print("     - checkpoint_freq: 500 (ya configurado)")
    print("     - batch_size: 128-256")
    print("  3. Tiempo estimado: ~10 minutos para 40k timesteps en CPU")
    print("  4. Luego continuar con A2C o re-ejecutar PPO con timesteps completos")
    
    print("\n" + "="*80)
    print("üìå ESTADO GENERAL: PPO Iniciado ‚úÖ | En curso ‚è∏ | Se requiere acci√≥n")
    print("="*80 + "\n")


if __name__ == '__main__':
    analyze_ppo_training()
