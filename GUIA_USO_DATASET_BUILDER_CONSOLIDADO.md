# ğŸ“– GUÃA COMPLETA: CÃ³mo Usar Dataset Builder Consolidado

**VersiÃ³n**: 2.0 (2026-02-04)  
**Estado**: ğŸŸ¢ Listo para ProducciÃ³n

---

## ğŸ¯ OBJETIVO

Este documento explica **paso a paso** cÃ³mo usar `dataset_builder_consolidated.py` para construir datasets CityLearn v2 con integraciÃ³n completa de OE2 data y contexto de recompensas.

---

## ğŸ“‹ TABLA DE CONTENIDOS

1. [InstalaciÃ³n & Setup](#instalaciÃ³n--setup)
2. [Uso BÃ¡sico](#uso-bÃ¡sico)
3. [Opciones Avanzadas](#opciones-avanzadas)
4. [Troubleshooting](#troubleshooting)
5. [Ejemplos Completos](#ejemplos-completos)
6. [Preguntas Frecuentes](#preguntas-frecuentes)

---

## ğŸ’¾ InstalaciÃ³n & Setup

### Paso 1: Verificar que el Archivo Existe
```bash
# El archivo debe estar en:
src/citylearnv2/dataset_builder/dataset_builder_consolidated.py

# Verifica:
test -f src/citylearnv2/dataset_builder/dataset_builder_consolidated.py && echo "âœ… Existe" || echo "âŒ No existe"
```

### Paso 2: Instalar Dependencias
```bash
# Las dependencias ya deberÃ­an estar en requirements.txt
pip install -r requirements.txt

# O si usas pip especÃ­fico:
pip install pandas numpy citylearn>=2.5.0 pyyaml
```

### Paso 3: Validar la InstalaciÃ³n
```bash
# Ejecuta el script de validaciÃ³n
python validate_dataset_builder_consolidated.py

# Debe mostrar: "âœ… TODAS LAS VALIDACIONES PASARON!"
```

---

## ğŸš€ Uso BÃ¡sico

### OpciÃ³n 1: Importar como MÃ³dulo (RECOMENDADO)

#### Paso 1: Importar la funciÃ³n
```python
from src.citylearnv2.dataset_builder.dataset_builder_consolidated import (
    build_citylearn_dataset,
    BuiltDataset,
)
from pathlib import Path
```

#### Paso 2: Llamar la funciÃ³n
```python
# Uso con parÃ¡metros por defecto
result = build_citylearn_dataset()

# Uso con parÃ¡metros custom
result = build_citylearn_dataset(
    processed_dir=Path("data/processed/oe3/citylearn"),
    building_name="Iquitos_EV_Mall",
    overwrite=False
)
```

#### Paso 3: Acceder a los resultados
```python
# result es de tipo BuiltDataset
print(f"Dataset directory: {result.dataset_dir}")
print(f"Schema path: {result.schema_path}")
print(f"Building name: {result.building_name}")
print(f"Timestamp: {result.timestamp}")
print(f"Specs: {result.specs}")

# Verificar que se generaron los archivos
import os
charger_csvs = result.dataset_dir / "charger_simulation_0.csv"
print(f"Charger CSV exists: {charger_csvs.exists()}")
```

### OpciÃ³n 2: Usar como Script CLI

#### Paso 1: Ejecutar directamente
```bash
# Con directorio por defecto (data/processed/oe3/citylearn)
python src/citylearnv2/dataset_builder/dataset_builder_consolidated.py

# Con directorio custom
python src/citylearnv2/dataset_builder/dataset_builder_consolidated.py \
    /ruta/custom/output
```

#### Paso 2: Ver la salida
```bash
# Debe ver algo como:
# âœ… LOADING OE2 ARTIFACTS
#   âœ… Solar timeseries loaded (8760 rows)
#   âœ… Charger profiles loaded (128 chargers)
#   âœ… BESS configuration loaded
#   âœ… Mall demand loaded (optional)
# 
# âœ… INITIALIZING REWARD CONTEXT
#   âœ… IquitosContext created
#   âœ… MultiObjectiveWeights loaded
# 
# ... mÃ¡s outputs ...
# 
# âœ… DATASET CONSTRUCTION COMPLETE
#   Dataset: /ruta/output
#   Building: Iquitos_EV_Mall
#   Timestamp: 2026-02-04T12:34:56
```

---

## ğŸ”§ Opciones Avanzadas

### ParÃ¡metro 1: `processed_dir`

```python
from pathlib import Path

# OpciÃ³n A: Auto-detect (default)
result = build_citylearn_dataset()
# Busca automÃ¡ticamente:
# 1. data/processed/oe3/citylearn/
# 2. data/oe3/citylearn/
# 3. Lanza error si no encuentra

# OpciÃ³n B: Path explÃ­cito
result = build_citylearn_dataset(
    processed_dir=Path("/mi/ruta/custom/citylearn")
)

# OpciÃ³n C: Usar variable de entorno
import os
output_dir = os.getenv("CITYLEARN_OUTPUT_DIR", "data/processed/oe3/citylearn")
result = build_citylearn_dataset(
    processed_dir=Path(output_dir)
)
```

### ParÃ¡metro 2: `building_name`

```python
# OpciÃ³n A: Nombre por defecto
result = build_citylearn_dataset()
# Usa: "Iquitos_EV_Mall"

# OpciÃ³n B: Nombre custom
result = build_citylearn_dataset(
    building_name="Mi_Edificio_Custom"
)
# Usa: "Mi_Edificio_Custom"

# OpciÃ³n C: Nombre desde config
import yaml
with open("config.yaml") as f:
    config = yaml.safe_load(f)
    building = config.get("building_name", "Iquitos_EV_Mall")

result = build_citylearn_dataset(building_name=building)
```

### ParÃ¡metro 3: `overwrite`

```python
# OpciÃ³n A: No sobrescribir (default, seguro)
result = build_citylearn_dataset(overwrite=False)
# Si los archivos ya existen, usa los existentes

# OpciÃ³n B: Forzar regeneraciÃ³n
result = build_citylearn_dataset(overwrite=True)
# Elimina los archivos existentes y regenera todo
```

---

## ğŸ” Entender el Workflow

### Los 7 Pasos de ConstrucciÃ³n

```
1. INITIALIZE
   â”œâ”€ Detecta directorios
   â”œâ”€ Valida rutas
   â””â”€ Carga configuraciÃ³n

2. LOAD OE2 DATA
   â”œâ”€ Solar: 8,760 hourly (obligatorio)
   â”œâ”€ Chargers: (8760, 128) shape (obligatorio)
   â”œâ”€ BESS: Optional, SOC tracking
   â””â”€ Mall demand: Optional, hourly kW

3. LOAD REWARD CONTEXT
   â”œâ”€ IquitosContext (COâ‚‚ factors, EV specs)
   â”œâ”€ MultiObjectiveWeights (reward priorities)
   â””â”€ Fallback manual si rewards.py no disponible

4. VALIDATE COMPLETENESS
   â”œâ”€ Verifica presencia de todos los datos
   â”œâ”€ Valida shapes
   â”œâ”€ Chequea ranges
   â””â”€ Fail fast si hay problemas

5. GENERATE SCHEMA
   â”œâ”€ Crea schema.json
   â”œâ”€ Embeds co2_context (para agentes)
   â”œâ”€ Embeds reward_weights (para agentes)
   â””â”€ Escribe a disco

6. GENERATE CHARGER CSVs
   â”œâ”€ Crea 128 archivos (charger_simulation_0.csv ... 127.csv)
   â”œâ”€ Formato CityLearn v2 (8760 Ã— 1 kW)
   â”œâ”€ ValidaciÃ³n de shape pre-generaciÃ³n
   â””â”€ Escribe a disco

7. POST-VALIDATE
   â”œâ”€ Verifica que todos los 128 CSVs existen
   â”œâ”€ Valida schema.json structure
   â”œâ”€ Chequea que rewards estÃ¡n presentes
   â””â”€ Retorna BuiltDataset result
```

---

## ğŸ§ª Validaciones AutomÃ¡ticas

### ValidaciÃ³n 1: Solar Timeseries
```python
# âœ… ACEPTADO: 8,760 filas (hourly)
# âŒ RECHAZADO: 52,560 filas (15-min)
# âŒ RECHAZADO: 365 filas (daily)

# CÃ³mo verificar manualmente:
import pandas as pd
df = pd.read_csv("data/interim/oe2/solar/pv_generation_timeseries_v2_hourly.csv")
print(f"Rows: {len(df)}")  # Debe ser 8760
print(f"Shape: {df.shape}")  # Debe ser (8760, 1)
```

### ValidaciÃ³n 2: Charger Profiles
```python
# âœ… ACEPTADO: (8760, 128)
# âŒ RECHAZADO: (8760, 126)
# âŒ RECHAZADO: (8760,) - 1D array

# CÃ³mo verificar manualmente:
chargers = pd.read_csv("data/interim/oe2/chargers/chargers_real_hourly_2024.csv")
print(f"Shape: {chargers.shape}")  # Debe ser (8760, 128)
```

### ValidaciÃ³n 3: BESS Optional
```python
# âœ… ACEPTADO: (8760,) o (8760, 1)
# âš ï¸  SKIPPED: Si no existe (es opcional)

# CÃ³mo verificar manualmente:
bess = pd.read_csv("data/interim/oe2/bess/bess_hourly_dataset_2024.csv")
print(f"Shape: {bess.shape}")  # Debe ser (8760,) o (8760, 1)
```

---

## ğŸ› Troubleshooting

### Problema 1: "Module not found: src.citylearnv2"
```python
# Causa: PYTHONPATH no configurado

# SoluciÃ³n A: Ejecutar desde root
cd /ruta/a/diseÃ±opvbesscar  # Root del proyecto
python -c "from src.citylearnv2.dataset_builder.dataset_builder_consolidated import build_citylearn_dataset"

# SoluciÃ³n B: Agregar a PYTHONPATH
export PYTHONPATH="${PYTHONPATH}:/ruta/a/diseÃ±opvbesscar"
python ...

# SoluciÃ³n C: Usar script de wrapper
python scripts/run_oe3_build_dataset.py --config configs/default.yaml
```

### Problema 2: "Solar timeseries must be 8,760 rows"
```
Causa: Tu archivo solar tiene 52,560 filas (15-min data)

SoluciÃ³n: Downsample a hourly
import pandas as pd
df = pd.read_csv("path/to/15min_solar.csv")
df_hourly = df.set_index('time').resample('h').mean()
df_hourly.to_csv("solar_hourly.csv")
```

### Problema 3: "Charger profiles must be (8760, 128)"
```
Causa: Tu archivo de chargers tiene forma incorrecta

Soluciones:
1. Si tiene (8760, 126):
   - Verifica que hay 128 chargers (112 motos + 16 mototaxis)
   - Puede faltar una columna

2. Si tiene (8760,):
   - Reshape usando numpy
   import numpy as np
   arr = np.expand_dims(arr, axis=1)

3. Si tiene (365, 128):
   - Necesitas datos horarios, no diarios
   - Interpolar u obtener datos correctos
```

### Problema 4: "rewards.py not found (fallback mode)"
```
Causa: El mÃ³dulo rewards.py no estÃ¡ disponible

SoluciÃ³n: Instalar o copiar rewards.py
# El dataset_builder_consolidated.py cae a "fallback mode"
# sin rewards integration, pero sigue funcionando

# Para arreglarlo:
# 1. Verifica que src/rewards/rewards.py existe
# 2. Verifica que __init__.py estÃ¡ en src/rewards/
# 3. Reinstala el paquete
```

### Problema 5: "Output directory already exists"
```
Causa: Los archivos de salida ya existen

Soluciones:
# OpciÃ³n 1: Usar parametro overwrite
result = build_citylearn_dataset(overwrite=True)

# OpciÃ³n 2: Eliminar directorio manualmente
import shutil
shutil.rmtree("data/processed/oe3/citylearn")
result = build_citylearn_dataset()

# OpciÃ³n 3: Usar directorio diferente
result = build_citylearn_dataset(
    processed_dir=Path("data/processed/oe3/citylearn_v2")
)
```

---

## ğŸ“š Ejemplos Completos

### Ejemplo 1: Uso BÃ¡sico MÃ­nimo
```python
from src.citylearnv2.dataset_builder.dataset_builder_consolidated import build_citylearn_dataset

# Construir con defaults
result = build_citylearn_dataset()

# Imprimir resultado
print(f"âœ… Dataset construido en: {result.dataset_dir}")
```

### Ejemplo 2: Uso con ParÃ¡metros
```python
from src.citylearnv2.dataset_builder.dataset_builder_consolidated import build_citylearn_dataset
from pathlib import Path

# Construir con custom params
result = build_citylearn_dataset(
    processed_dir=Path("data/processed/oe3/citylearn"),
    building_name="Iquitos_EV_Mall",
    overwrite=False
)

# Acceder a resultados
print(f"Dataset dir: {result.dataset_dir}")
print(f"Schema: {result.schema_path}")
print(f"Building: {result.building_name}")

# Verificar archivos generados
import os
charger_0 = result.dataset_dir / "charger_simulation_0.csv"
schema_file = result.schema_path

assert charger_0.exists(), "Charger 0 CSV no encontrado"
assert schema_file.exists(), "Schema JSON no encontrado"
print("âœ… Todos los archivos existen")
```

### Ejemplo 3: IntegraciÃ³n con Agent Training
```python
from pathlib import Path
from src.citylearnv2.dataset_builder.dataset_builder_consolidated import build_citylearn_dataset
from src.agents.sac import make_sac

# Paso 1: Construir dataset
print("ğŸ”¨ Construyendo dataset...")
dataset = build_citylearn_dataset(overwrite=False)
print(f"âœ… Dataset en: {dataset.dataset_dir}")

# Paso 2: Crear ambiente CityLearn
print("ğŸŒ Creando ambiente...")
from citylearn import CityLearnEnv
env = CityLearnEnv(dataset.schema_path)

# Paso 3: Crear y entrenar agente SAC
print("ğŸ¤– Entrenando agente...")
agent = make_sac(env)
agent.learn(total_timesteps=26280)  # 3 episodes

# Paso 4: Guardar agente
agent.save("checkpoints/sac_model")
print("âœ… Agente entrenado y guardado")
```

### Ejemplo 4: ValidaciÃ³n Manual
```python
from src.citylearnv2.dataset_builder.dataset_builder_consolidated import (
    build_citylearn_dataset,
    validate_solar_timeseries,
    validate_charger_profiles,
    validate_dataset_completeness,
)
import pandas as pd
from pathlib import Path

# Validar solar antes de construir
solar_path = Path("data/interim/oe2/solar/pv_generation_timeseries_v2_hourly.csv")
solar_data = pd.read_csv(solar_path)
print(f"Solar shape: {solar_data.shape}")

try:
    validate_solar_timeseries(solar_data.values.ravel())
    print("âœ… Solar validation passed")
except Exception as e:
    print(f"âŒ Solar validation failed: {e}")

# Validar chargers antes de construir
chargers_path = Path("data/interim/oe2/chargers/chargers_real_hourly_2024.csv")
chargers_data = pd.read_csv(chargers_path)
print(f"Chargers shape: {chargers_data.shape}")

try:
    validate_charger_profiles(chargers_data.values)
    print("âœ… Charger validation passed")
except Exception as e:
    print(f"âŒ Charger validation failed: {e}")

# Ahora construir dataset
print("\nğŸ”¨ Construyendo dataset...")
result = build_citylearn_dataset()
print(f"âœ… Dataset construido: {result.dataset_dir}")
```

---

## â“ Preguntas Frecuentes

### P1: Â¿QuÃ© pasa si tengo 15-min solar data?
**R**: El consolidado RECHAZA automÃ¡ticamente y muestra:
```
âŒ DatasetValidationError: Solar timeseries must be 8,760 rows (hourly).
   Got: 52,560 rows (15-minute data)
```

**SoluciÃ³n**: Downsample a hourly:
```python
import pandas as pd
df = pd.read_csv("solar_15min.csv", index_col='time', parse_dates=True)
df_hourly = df.resample('h').mean()
df_hourly.to_csv("solar_hourly.csv")
```

### P2: Â¿Puedo usar sin rewards.py?
**R**: SÃ. El consolidado detecta automÃ¡ticamente:
```
âš ï¸  warnings.py not available (fallback mode)
   Rewards will be created manually
```

El dataset se genera pero sin contexto de recompensas optimizado.

### P3: Â¿CuÃ¡nto tiempo toma construir el dataset?
**R**: TÃ­picamente:
- Load data: ~1 segundo
- Validation: ~0.5 segundos
- Schema generation: ~0.1 segundos
- CSV generation (128 files): ~2-3 segundos
- **TOTAL**: ~4-5 segundos

### P4: Â¿Puedo paralelizar la generaciÃ³n de CSVs?
**R**: El consolidado actual es secuencial, pero podrÃ­as paralelizar:
```python
from concurrent.futures import ThreadPoolExecutor
# CÃ³digo custom aquÃ­ (NO incluido en consolidado)
```

### P5: Â¿DÃ³nde estÃ¡n los 128 CSVs generados?
**R**: En: `{processed_dir}/charger_simulation_0.csv` ... `charger_simulation_127.csv`

Ejemplo:
```bash
ls data/processed/oe3/citylearn/charger_simulation_*.csv | wc -l
# Debe mostrar: 128
```

### P6: Â¿CÃ³mo cambio los pesos de recompensa?
**R**: Los pesos estÃ¡n en `schema["reward_weights"]`. Puedes:

**OpciÃ³n 1**: Editar despuÃ©s de generar
```python
import json
with open("data/processed/oe3/citylearn/schema.json") as f:
    schema = json.load(f)

schema["reward_weights"]["co2"] = 0.70  # Cambiar COâ‚‚ weight
schema["reward_weights"]["solar"] = 0.10  # Cambiar solar weight

with open("data/processed/oe3/citylearn/schema.json", "w") as f:
    json.dump(schema, f, indent=2)
```

**OpciÃ³n 2**: Pasar config custom (si implementas en rewards.py)
```python
from src.rewards.rewards import create_iquitos_reward_weights
weights = create_iquitos_reward_weights(priority="co2_focus")
```

---

## ğŸ“ Aprender MÃ¡s

### DocumentaciÃ³n Relacionada
- [DATASET_BUILDER_CONSOLIDADO_v2.md](DATASET_BUILDER_CONSOLIDADO_v2.md) - Overview general
- [MAPEO_CONSOLIDACION_DETALLADO.md](MAPEO_CONSOLIDACION_DETALLADO.md) - QuÃ© se consolidÃ³
- [CONSOLIDACION_FINAL_RESUMEN.md](CONSOLIDACION_FINAL_RESUMEN.md) - Resumen ejecutivo

### Fuentes de CÃ³digo
- Main file: `src/citylearnv2/dataset_builder/dataset_builder_consolidated.py`
- Migration tool: `migrate_dataset_builder.py`
- Validation tool: `validate_dataset_builder_consolidated.py`

### Ejecutar Ejemplos
```bash
# Validar instalaciÃ³n
python validate_dataset_builder_consolidated.py

# Ver plan de migraciÃ³n
python migrate_dataset_builder.py

# Ejecutar dataset builder
python src/citylearnv2/dataset_builder/dataset_builder_consolidated.py
```

---

## ğŸ“ Soporte

Si encuentras problemas:

1. **Revisar Troubleshooting arriba** (cubre 90% de casos)
2. **Ejecutar validaciones**: `python validate_dataset_builder_consolidated.py`
3. **Revisar logs**: Buscar `[ERROR]` o `[WARNING]` en la salida
4. **Contactar soporte**: Proporcionar full stack trace + logs

---

*GuÃ­a de uso: 2026-02-04*  
*VersiÃ³n del consolidado: 2.0*
