# ğŸ“Š Arquitectura Visual Completa del Proyecto pvbesscar

## VersiÃ³n: 2026-02-14 | Estado: âœ… COMPLETO

---

## ğŸ¯ Resumen Ejecutivo

**pvbesscar** es un sistema de optimizaciÃ³n de carga de vehÃ­culos elÃ©ctricos (270 motos + 39 mototaxis) en Iquitos, PerÃº, que minimiza emisiones de COâ‚‚ usando:
- **OE2 (Dimensionamiento)**: Infraestructura = 4,050 kWp solar + 1,700 kWh BESS + 38 sockets
- **OE3 (Control)**: Agentes RL (SAC/PPO/A2C) entrenados con CityLearn v2

**Meta**: Reducir COâ‚‚ grid-dependiente (~190,000 kg/aÃ±o baseline) mediante control inteligente de carga

---

## ğŸ—ï¸ Diagrama 1: Arquitectura General del Proyecto

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ğŸ“Š OE2: Dimensionamiento                       â”‚
â”‚                                                             â”‚
â”‚  â˜€ï¸ Solar 4,050 kWp    ğŸ”‹ BESS 1,700 kWh                   â”‚
â”‚  ğŸ”Œ 38 Sockets Ã— 7.4kW  ğŸª Mall 100 kW demanda           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚ Datos validados (8,760 h)
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ğŸŒ OE3: Control con RL Agents                  â”‚
â”‚                                                             â”‚
â”‚  CityLearn v2 Environment:                                 â”‚
â”‚  - obs: 394-dim (solar, grid, BESS, sockets, tiempo)      â”‚
â”‚  - action: [0,1]^39 (1 BESS + 38 sockets)                â”‚
â”‚  - episodes: 8,760 timesteps (1 aÃ±o/hora)                 â”‚
â”‚                                                             â”‚
â”‚  Agentes entrenables:                                       â”‚
â”‚  ğŸ¤– SAC (Off-policy) | PPO (On-policy) | A2C (Simple)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            ğŸ’¾ Checkpoints & Training                        â”‚
â”‚                                                             â”‚
â”‚  /checkpoints/SAC/, /PPO/, /A2C/                          â”‚
â”‚  â†’ Auto-resume | Model weights | Metadata                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           ğŸ“ˆ Salidas & Resultados                          â”‚
â”‚                                                             â”‚
â”‚  ğŸ“Š COâ‚‚ kg/aÃ±o (baseline: 190k â†’ ~140k RL)               â”‚
â”‚  â˜€ï¸ Solar utilization % (target: >65%)                    â”‚
â”‚  ğŸ“‰ Reward trajectory & convergence                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Ver grÃ¡fico Mermaid completo**: [Arquitectura General](#diagrama-mermaid-1)

---

## ğŸ”„ Diagrama 2: Flujo de Datos OE2 â†’ OE3

```
ENTRADA â†’ VALIDACIÃ“N â†’ ARTEFACTOS â†’ CONSTRUCCIÃ“N â†’ ENTRENAMIENTO â†’ SALIDA
   â†“           â†“           â†“             â†“              â†“            â†“
CSV files â†’ data_loader â†’ OE2 specs â†’ CityLearn env â†’ SAC/PPO/A2C â†’ Results
           - 8,760 rows
           - Chargers OK
           - BESS params
           - Demand ready
```

**Componentes claves**:

| Componente | Archivo | Funcionalidad |
|-----------|---------|--------------|
| **Data Loader** | `data_loader.py` | âœ… Valida solar (8,760h), specs chargers, BESS, demanda |
| **OE2 Artifacts** | `csv/json files` | â˜€ï¸ Solar, ğŸ”Œ Chargers, ğŸ”‹ BESS, ğŸ“Š Demand |
| **Dataset Builder** | `dataset_builder.py` | ğŸ—ï¸ Construye CityLearn env (394-dim obs, [0,1]^39 action) |
| **Training Loop** | `train_*.py` | ğŸ”„ 26,280 pasos (365 days Ã— 24h Ã— 3 episodes) |
| **Checkpointing** | `checkpoints/` | ğŸ’¾ Auto-resume, best model selection |

**Ver grÃ¡fico Mermaid completo**: [Data Pipeline](#diagrama-mermaid-2)

---

## ğŸš€ Diagrama 3: Pipeline de Entrenamiento

```
START
  â†“
Load OE2 (Solar 8,760h, Chargers 19, BESS 1.7MWh, Demand)
  â†“
Build CityLearn v2 Env (394-dim obs, [0,1]^39 actions)
  â†“
Load Latest Checkpoint (if exists)
  â†“
Initialize Agent (SAC/PPO/A2C)
  â†“
Log Hyperparameters
  â†“
â”Œâ”€ TRAINING LOOP (26,280 steps = 365 days) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                     â”‚
â”‚  FOR each timestep t=0..8,759:                    â”‚
â”‚    1. Reset env â†’ obs (394-dim)                   â”‚
â”‚    2. Agent predict action (39-dim)               â”‚
â”‚    3. Env step â†’ reward (multi-objective)         â”‚
â”‚    4. Agent update policy (SAC/PPO/A2C)          â”‚
â”‚    5. Save checkpoint if best reward             â”‚
â”‚    6. Log metrics (COâ‚‚, Solar %, reward)         â”‚
â”‚                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
Save Final Model (weights + summary)
  â†“
Evaluate Metrics (COâ‚‚ reduction %, solar util %)
  â†“
Export Results (train_log.csv, checkpoint_summary.json)
  â†“
âœ… COMPLETE â†’ Ready for OE3 deployment
```

**DuraciÃ³n estimada** (GPU RTX 4060):
- **SAC**: 5-7 horas â†’ COâ‚‚ -26%, Solar 65%
- **PPO**: 4-6 horas â†’ COâ‚‚ -29%, Solar 68% â­
- **A2C**: 3-5 horas â†’ COâ‚‚ -24%, Solar 60%

**Ver grÃ¡fico Mermaid completo**: [Training Pipeline](#diagrama-mermaid-3)

---

## ğŸ“‚ Diagrama 4: Estructura de Directorios

```
diseÃ±opvbesscar/
â”‚
â”œâ”€â”€ ğŸ“‚ src/
â”‚   â”œâ”€â”€ dimensionamiento/oe2/
â”‚   â”‚   â”œâ”€â”€ solar_pvlib.py         â˜€ï¸ Validar/generar solar
â”‚   â”‚   â”œâ”€â”€ chargers.py             ğŸ”Œ 38 sockets spec
â”‚   â”‚   â””â”€â”€ bess.py                 ğŸ”‹ Storage rules
â”‚   â”‚
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ sac.py                  ğŸ¤– Soft Actor-Critic
â”‚   â”‚   â”œâ”€â”€ ppo_sb3.py              ğŸ¤– Proximal Policy Opt
â”‚   â”‚   â””â”€â”€ a2c_sb3.py              ğŸ¤– Advantage Actor-Critic
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ agent_utils.py          âš™ï¸ Common patterns
â”‚   â”‚   â”œâ”€â”€ logging.py              ğŸ“ Logging
â”‚   â”‚   â””â”€â”€ series.py               ğŸ“Š Time series
â”‚   â”‚
â”‚   â””â”€â”€ citylearnv2/
â”‚       â””â”€â”€ dataset_builder.py      ğŸ—ï¸ Build environment
â”‚
â”œâ”€â”€ ğŸ“‚ data/
â”‚   â”œâ”€â”€ raw/                        ğŸ“¥ Original datasets
â”‚   â”œâ”€â”€ oe2/                        â˜€ï¸ Solar, Chargers, BESS
â”‚   â”œâ”€â”€ interim/                    âš™ï¸ Processed data
â”‚   â””â”€â”€ processed/                  âœ… Ready for training
â”‚
â”œâ”€â”€ ğŸ“‚ scripts/
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ train_sac_multiobjetivo.py      ğŸš€ SAC training
â”‚   â”‚   â”œâ”€â”€ train_ppo_multiobjetivo.py      ğŸš€ PPO training
â”‚   â”‚   â””â”€â”€ train_a2c_multiobjetivo.py      ğŸš€ A2C training
â”‚   â”œâ”€â”€ eval/
â”‚   â”‚   â””â”€â”€ evaluate_agents.py              ğŸ“ˆ Compare agents
â”‚   â””â”€â”€ run_dual_baselines.py               ğŸ“Š Baselines
â”‚
â”œâ”€â”€ ğŸ“‚ checkpoints/
â”‚   â”œâ”€â”€ SAC/latest.zip              ğŸ’¾ Model state
â”‚   â”œâ”€â”€ PPO/latest.zip              ğŸ’¾ Model state
â”‚   â””â”€â”€ A2C/latest.zip              ğŸ’¾ Model state
â”‚
â”œâ”€â”€ ğŸ“‚ outputs/
â”‚   â”œâ”€â”€ sac_training/train_log.csv  ğŸ“Š SAC metrics
â”‚   â”œâ”€â”€ ppo_training/train_log.csv  ğŸ“Š PPO metrics
â”‚   â”œâ”€â”€ a2c_training/train_log.csv  ğŸ“Š A2C metrics
â”‚   â””â”€â”€ baselines/                  ğŸ¯ WITH/WITHOUT solar
â”‚
â”œâ”€â”€ ğŸ“‚ configs/
â”‚   â”œâ”€â”€ default.yaml                âš™ï¸ All parameters
â”‚   â””â”€â”€ sac_optimized.json          ğŸ¯ SAC tuned
â”‚
â””â”€â”€ ğŸ“‚ docs/
    â”œâ”€â”€ copilot-instructions.md     ğŸ¯ Project guide
    â”œâ”€â”€ DATA_SOURCES_*.md           ğŸ“‹ Data map
    â””â”€â”€ ARQUITECTURA_VISUAL_COMPLETA.md  (este archivo)
```

**Ver grÃ¡fico Mermaid completo**: [Estructura Directorios](#diagrama-mermaid-4)

---

## ğŸŒ Diagrama 5: CityLearn v2 y Ciclo Agente-Ambiente

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              env.reset() â†’ Inicializar episode              â”‚
â”‚              t=0, SOC_BESS=50%, obs_dim=394               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  ğŸ“ OBSERVATIONS (394-dim)            â”‚
    â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€          â”‚
    â”‚  â€¢ Solar W/mÂ² (today, tomorrow, week)â”‚
    â”‚  â€¢ Grid Hz (frequency)               â”‚
    â”‚  â€¢ BESS % SOC (current storage %)   â”‚
    â”‚  â€¢ 38 Socket States:                 â”‚
    â”‚    - Power drawn (kW)                â”‚
    â”‚    - EV connected (bool)             â”‚
    â”‚    - Time to deadline (hours)        â”‚
    â”‚  â€¢ Mall Load (current + forecast)   â”‚
    â”‚  â€¢ Time Features (hour, month, DoW) â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  ğŸ¤– AGENT PREDICT                    â”‚
    â”‚  â””â”€ action = agent.predict(obs)      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  ğŸ’¡ ACTION SPACE ([0,1]^39)           â”‚
    â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
    â”‚  â€¢ action[0]: BESS setpoint [0, 300kW]â”‚
    â”‚  â€¢ action[1:39]: Socket setpoints    â”‚
    â”‚                  38 Ã— [0, 7.4 kW]     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  ğŸ”„ ENVIRONMENT STEP                 â”‚
    â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
    â”‚  1. Power Balance:                   â”‚
    â”‚     Solar + BESS - Mall - EVs = ??   â”‚
    â”‚  2. Update BESS SOC (charge/discharge)â”‚
    â”‚  3. Charge EVs (if connected)        â”‚
    â”‚  4. Grid Import = max(0, net_demand) â”‚
    â”‚  5. COâ‚‚ = Grid_Import Ã— 0.4521 kg/kWhâ”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  ğŸ¯ REWARD CALCULATION               â”‚
    â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
    â”‚  Total Reward = Î£ weighted components â”‚
    â”‚  â€¢ -0.50 Ã— COâ‚‚ (minimize grid)       â”‚
    â”‚  â€¢ +0.20 Ã— Solar util (PV direct)   â”‚
    â”‚  â€¢ +0.15 Ã— EV charged (by deadline)  â”‚
    â”‚  â€¢ -0.10 Ã— Grid ramping (smooth)     â”‚
    â”‚  â€¢ -0.05 Ã— Cost (off-peak)          â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  â™»ï¸  AGENT UPDATE POLICY             â”‚
    â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
    â”‚  SAC: Replay buffer â†’ gradient       â”‚
    â”‚  PPO: Rollout buffer â†’ gradient      â”‚
    â”‚  A2C: Direct gradient update         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  âœ… t >= 8,760 timesteps?            â”‚
    â”‚  â”œâ”€ YES â†’ Episode complete          â”‚
    â”‚  â”‚         Calc final COâ‚‚, solar %   â”‚
    â”‚  â”‚         Save best model           â”‚
    â”‚  â”‚         â†’ t=0 (next episode)      â”‚
    â”‚  â””â”€ NO â†’ Continue (t+1, go to obs)  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Ver grÃ¡fico Mermaid completo**: [CityLearn v2 Cycle](#diagrama-mermaid-5)

---

## ğŸ¤– Diagrama 6: ComparaciÃ³n de Agentes RL

| CaracterÃ­stica | **SAC** | **PPO** | **A2C** |
|---|---|---|---|
| **Tipo** | Off-policy | On-policy | On-policy |
| **Mejor para** | Asymmetric rewards COâ‚‚ | General, stable | Baseline rÃ¡pido |
| **Architecture** | Actor + 2Ã—Critic | Actor + Critic | Actor + Critic |
| **Update** | Batch (256) | Rollout (2048) | Sync (256) |
| **Learning Rate** | 3e-4 | 3e-4 | 7e-4 |
| **Entropy Coef** | Auto | Fixed | 0.01 |
| **Expected COâ‚‚** | -26% (140k kg) | **-29% (135k kg)** â­ | -24% (145k kg) |
| **Solar Util** | 65% | **68%** â­ | 60% |
| **Tiempo (GPU)** | 5-7 h | 4-6 h | **3-5 h** âš¡ |
| **Stability** | Very high | High | Medium |
| **Memory** | ~2.5GB | ~2.0GB | ~1.5GB |

**RecomendaciÃ³n**: PPO para mejor balance rendimiento/estabilidad; SAC si priorizas COâ‚‚ asymmetric.

**Ver grÃ¡fico Mermaid completo**: [Agentes RL](#diagrama-mermaid-6)

---

## ğŸ¯ Diagrama 7: OE2 â†’ OE3 y Baselines

```
OE2 DATA SOURCES
  â”‚
  â”œâ”€ â˜€ï¸ Solar 4,050 kWp (8,760 h)
  â”œâ”€ ğŸ”Œ Chargers 19 Ã— 2 = 38 sockets
  â”œâ”€ ğŸ”‹ BESS 1,700 kWh max SOC
  â”œâ”€ ğŸª Mall 100 kW baseline
  â””â”€ ğŸ“Š EV Demand (actual profiles)
       â”‚
       â–¼
  âœ… VALIDATION LAYER
       â”‚
       â”œâ”€ Validate solar 8,760 rows (not 15-min)
       â”œâ”€ Charger specs OK
       â”œâ”€ BESS params OK
       â””â”€ Demand profiles OK
            â”‚
            â–¼
  ğŸ—ï¸ BUILDING CITYLEARN ENV
       â”‚
       â””â”€ 394-dim observations
          [0,1]^39 continuous actions
          8,760 timesteps per episode
            â”‚
            â–¼
  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
  â•‘                  AGENTS TRAIN                         â•‘
  â•‘  ğŸ¤– SAC    |    ğŸ¤– PPO    |    ğŸ¤– A2C               â•‘
  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
       â”‚           â”‚           â”‚
       â”œâ”€ vs â—„â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º vs
       â”‚    BASELINE WITH SOLAR         BASELINE WITHOUT SOLAR
       â”‚    (4,050 kWp enabled)         (0 kWp, grid only)
       â”‚    COâ‚‚: ~190,000 kg/year       COâ‚‚: ~640,000 kg/year
       â”‚    â†‘ REFERENCE POINT            â†‘ Shows 410k kg impact
       â”‚
       â–¼
  â”Œâ”€ RESULTS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                                                   â”‚
  â”‚ SAC:  COâ‚‚ 140k kg (-26%), Solar 65%             â”‚
  â”‚ PPO:  COâ‚‚ 135k kg (-29%), Solar 68% â­         â”‚
  â”‚ A2C:  COâ‚‚ 145k kg (-24%), Solar 60%             â”‚
  â”‚                                                   â”‚
  â”‚ ğŸ† Winner: Highest reduction % + sustained util â”‚
  â””â”€ FINAL COMPARISON â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Ver grÃ¡fico Mermaid completo**: [OE2â†’OE3 & Baselines](#diagrama-mermaid-7)

---

## ğŸ“Š Diagrama 8: Flujo de MÃ©tricas

```
âš¡ SIMULATION STEP (t=0..8,759)
  â”‚
  â”œâ”€ Solar_gen(t) [kW]
  â”œâ”€ Mall_demand(t) [kW]
  â”œâ”€ EV_demand(t) [38 sockets]
  â”œâ”€ BESS_action(t) [kW]
  â””â”€ Socket_actions[1:39](t) [kW]
       â”‚
       â–¼
ğŸ”„ POWER FLOW
  â”‚
  â”œâ”€ Power Balance: Solar + BESS - Mall - EVs = ??
  â”œâ”€ EV Charging: Min(requested, setpoint, max_kW)
  â”œâ”€ BESS Update: SOC_new = SOC - discharge + charge - losses
  â””â”€ Grid Import: Max(0, net_demand)
       â”‚
       â–¼
ğŸŒ ENVIRONMENTAL METRICS
  â”‚
  â”œâ”€ COâ‚‚_hour(t) = Grid_import(t) Ã— 0.4521 kg/kWh
  â”œâ”€ COâ‚‚_cumulate = Î£ COâ‚‚_hour(t) for t=0..step
  â”œâ”€ Solar_used(t) = Min(Solar_gen, demand_served)
  â””â”€ Solar_util% = Î£ Solar_used / Î£ Solar_gen Ã— 100%
       â”‚
       â–¼
ğŸ¯ REWARD COMPONENTS
  â”‚
  â”œâ”€ COâ‚‚_reward = -norm(COâ‚‚_hour) Ã— 0.50
  â”œâ”€ Solar_reward = Solar_used/Solar_gen Ã— 0.20
  â”œâ”€ Charge_reward = EVs_charged_deadline Ã— 0.15
  â”œâ”€ Grid_reward = -dPower/dt Ã— 0.10
  â””â”€ Cost_reward = Peak_vs_offpeak Ã— 0.05
       â”‚
       â–¼
âœ… EPISODE METRICS (t=8,760)
  â”‚
  â”œâ”€ Total COâ‚‚ annual [kg/year]
  â”œâ”€ Final Solar % [average utilization]
  â”œâ”€ Charge Success [% EVs charged]
  â”œâ”€ Total Episode Reward [cumsum]
  â””â”€ Convergence Rate [V(s) stability]
       â”‚
       â–¼
ğŸ’¾ LOGGING & CHECKPOINTING
  â”‚
  â”œâ”€ Step Log (every 512 steps)
  â”‚  â””â”€ step_count, COâ‚‚_cumul, solar_kw, bess_soc, reward
  â”œâ”€ Episode Log
  â”‚  â””â”€ total_co2, solar_util%, total_reward, timestamp
  â””â”€ Checkpoint Metadata
     â””â”€ agent_type, episode, total_steps, best_reward, hyperparams
       â”‚
       â–¼
ğŸ“Š OUTPUT FILES
  â”‚
  â”œâ”€ train_log.csv
  â”‚  â””â”€ All steps & episodes, metrics history
  â”œâ”€ checkpoint_summary.json
  â”‚  â””â”€ Best model metadata, training progress
  â””â”€ best_model.zip
     â””â”€ Model weights, policy + critic
       â”‚
       â–¼
ğŸ“ˆ ANALYSIS & VISUALIZATION
  â”‚
  â”œâ”€ COâ‚‚ reduction % vs baseline
  â”œâ”€ Solar utilization % by month/hour
  â”œâ”€ Reward trajectory & convergence
  â””â”€ SAC vs PPO vs A2C comparison table
```

**Ver grÃ¡fico Mermaid completo**: [Metrics Flow](#diagrama-mermaid-8)

---

## ğŸ”‘ Componentes Clave Explicados

### 1ï¸âƒ£ OE2 (Dimensionamiento - Infraestructura)

**UbicaciÃ³n**: `src/dimensionamiento/oe2/`

| Componente | Valor | ValidaciÃ³n |
|-----------|-------|-----------|
| **Solar** | 4,050 kWp | 8,760 filas (hourly, NOT 15-min) |
| **Chargers** | 19 units Ã— 2 sockets | 38 controllable sockets @ 7.4 kW |
| **BESS** | 1,700 kWh max SOC | Verified from `bess_ano_2024.csv` |
| **Mall Load** | 100 kW baseline | Continuous consumption |
| **EV Demand** | 270 motos + 39 taxis | Time-varying, actual profiles |

**Archivos de entrada**:
- `data/oe2/Generacionsolar/pv_generation_citylearn2024.csv` (8,760 rows)
- `data/oe2/chargers/chargers_ev_ano_2024_v3.csv` (19 chargers)
- `data/oe2/bess/bess_ano_2024.csv` (BESS parameters)
- `data/oe2/demandamallkwh/demandamallhorakwh.csv` (8,760 demand values)

### 2ï¸âƒ£ OE3 (Control - Agentes RL)

**UbicaciÃ³n**: `src/agents/`

**CityLearn v2 Environment**:
- **Observation State**: 394-dimensional vector
  - Solar irradiance (today + 24h forecast)
  - Grid frequency
  - BESS SOC %
  - 38 socket states (power, connected, deadline)
  - Mall load (current + 24h forecast)
  - Time features (hour, month, day_of_week, season)

- **Action Space**: Continuous [0,1]^39
  - action[0]: BESS dispatch (normalized)
  - action[1:39]: 38 socket setpoints (normalized)

- **Reward Function**: Multi-objective, weighted
  ```
  reward = -0.50 Ã— COâ‚‚ + 0.20 Ã— Solar_util + 0.15 Ã— Charge_ok
           - 0.10 Ã— Grid_ramping - 0.05 Ã— Cost
  ```

- **Episode**: 8,760 timesteps (1 year, hourly resolution)

### 3ï¸âƒ£ Training Pipeline

**Archivos de entrada**: OE2 artifacts
**Algoritmo**: SAC/PPO/A2C from stable-baselines3
**Pasos**: 26,280 total (3 episodes Ã— 8,760 steps)
**Resultados**: Checkpoint saved, metrics logged

**Comandos principales**:
```bash
# Train SAC
python scripts/train/train_sac_multiobjetivo.py

# Train PPO
python scripts/train/train_ppo_multiobjetivo.py

# Train A2C
python scripts/train/train_a2c_multiobjetivo.py

# Run baselines (WITH/WITHOUT solar)
python -m scripts.run_dual_baselines --config configs/default.yaml
```

### 4ï¸âƒ£ Checkpointing & Resume

**Auto-resume pattern**: Agents automatically load latest checkpoint if exists
```python
agent = make_sac(env)  # Checks /checkpoints/SAC/ for latest
agent.learn(total_timesteps=10000, reset_num_timesteps=False)
# reset_num_timesteps=False â†’ accumulates steps across resumptions
```

**Checkpoint metadata**: `TRAINING_CHECKPOINTS_SUMMARY_*.json` tracks agent, episode, total_steps, best_reward

### 5ï¸âƒ£ Baselines de ComparaciÃ³n

**Baseline 1 - "CON SOLAR"**:
- Solar: 4,050 kWp (enabled)
- BESS: 1,700 kWh (enabled)
- COâ‚‚: ~190,000 kg/year (uncontrolled)
- âœ… REFERENCE POINT para medir mejoras RL

**Baseline 2 - "SIN SOLAR"**:
- Solar: 0 kWp (disabled)
- BESS: no disponible
- COâ‚‚: ~640,000 kg/year (grid only)
- ğŸ“Š Muestra impacto de 410k kg COâ‚‚ por 4,050 kWp

---

## ğŸ“ˆ Resultados Esperados

| MÃ©trica | Baseline | SAC | PPO â­ | A2C |
|---------|----------|-----|--------|-----|
| **COâ‚‚ kg/aÃ±o** | 190,000 | 140,000 | 135,000 | 145,000 |
| **ReducciÃ³n %** | 0% | -26% | **-29%** | -24% |
| **Solar util %** | ~40% | 65% | **68%** | 60% |
| **Grid import** | Maximum | -26% | **-29%** | -24% |
| **Tiempo entrenamiento** | N/A | 5-7 h | 4-6 h | 3-5 h âš¡ |

---

## ğŸš€ Quick Start

### 1. Verificar datos OE2
```bash
python -c "
import pandas as pd
from pathlib import Path

print('âœ… Verificando OE2 data:')
files = [
    'data/oe2/Generacionsolar/pv_generation_citylearn2024.csv',
    'data/oe2/chargers/chargers_ev_ano_2024_v3.csv',
    'data/oe2/bess/bess_ano_2024.csv',
    'data/oe2/demandamallkwh/demandamallhorakwh.csv'
]
for f in files:
    p = Path(f)
    if p.exists():
        print(f'  âœ“ {p.name}: {p.stat().st_size/1024/1024:.1f} MB')
"
```

### 2. Entrenar agente
```bash
# SAC: Mejor para rewards asimÃ©tricos (COâ‚‚ focused)
python scripts/train/train_sac_multiobjetivo.py

# PPO: Balance estabilidad/rendimiento (recommended)
python scripts/train/train_ppo_multiobjetivo.py

# A2C: Baseline rÃ¡pido
python scripts/train/train_a2c_multiobjetivo.py
```

### 3. Comparar resultados
```bash
ls outputs/sac_training/train_log.csv
ls outputs/ppo_training/train_log.csv
ls outputs/a2c_training/train_log.csv
```

---

## âš ï¸ Validaciones CrÃ­ticas

| ValidaciÃ³n | Status | Fix |
|-----------|--------|-----|
| **Solar 8,760 h** (hourly, not 15-min) | âœ… | `resample('h').mean()` |
| **19 chargers = 38 sockets** | âœ… | Check `chargers_ev_ano_2024_v3.csv` |
| **BESS max 1,700 kWh** | âœ… | `bess_ano_2024.csv` verified |
| **Demand 8,760 values** | âœ… | `demandamallhorakwh.csv` |
| **Environment obs 394-dim** | âœ… | Stack all features |
| **Action space [0,1]^39** | âœ… | 1 BESS + 38 sockets |

---

## ğŸ“ Archivos Importantes

| Archivo | LÃ­neas | PropÃ³sito |
|---------|--------|-----------|
| [sac.py](../src/agents/sac.py) | ~150 | SAC agent implementation |
| [ppo_sb3.py](../src/agents/ppo_sb3.py) | ~120 | PPO agent implementation |
| [a2c_sb3.py](../src/agents/a2c_sb3.py) | ~110 | A2C agent implementation |
| [data_loader.py](../src/dimensionamiento/oe2/data_loader.py) | ~200 | OE2 validation & loading |
| [agent_utils.py](../src/utils/agent_utils.py) | ~180 | Common patterns (validate_env_spaces) |
| [chargers.py](../src/dimensionamiento/oe2/chargers.py) | ~250 | Charger specs v5.2 (@dataclass frozen) |
| [dataset_builder.py](../src/citylearnv2/dataset_builder.py) | ~300 | CityLearn env construction |
| [train_sac_multiobjetivo.py](../scripts/train/train_sac_multiobjetivo.py) | ~400 | SAC training script |
| [train_ppo_multiobjetivo.py](../scripts/train/train_ppo_multiobjetivo.py) | ~400 | PPO training script |
| [train_a2c_multiobjetivo.py](../scripts/train/train_a2c_multiobjetivo.py) | ~400 | A2C training script |
| [copilot-instructions.md](../copilot-instructions.md) | ~500 | Full project documentation |

---

## ğŸ“ Conceptos Clave

### Off-policy vs On-policy
- **SAC (Off-policy)**: Aprende de experiencias pasadas (replay buffer) â†’ sample efficient
- **PPO/A2C (On-policy)**: Aprende de rollout actual â†’ mÃ¡s estable pero requiere mÃ¡s samples

### Multi-objective Reward
```
R = Î£ w_i Ã— r_i  where Î£ w_i = 1.0
  = 0.50 Ã— r_COâ‚‚ + 0.20 Ã— r_solar + 0.15 Ã— r_charge
    + 0.10 Ã— r_grid + 0.05 Ã— r_cost
```
Ajustar pesos para priorizar objetivos.

### Checkpoint & Resume
- Auto-load latest checkpoint (by modification date)
- `reset_num_timesteps=False` acumula pasos
- Metadata JSON rastrea progreso

---

## ğŸ“ Soporte

Para preguntas sobre arquitectura, ver:
- [copilot-instructions.md](../copilot-instructions.md) - Full documentation
- [DATA_SOURCES_REAL_VS_SIMULATED.md](../docs/DATA_SOURCES_REAL_VS_SIMULATED.md) - Data architecture
- Inline cÃ³digo comments en `src/agents/` y `src/dimensionamiento/`

---

**Ãšltima actualizaciÃ³n**: 2026-02-14 20:45 UTC
**Estado**: âœ… Todos los diagramas verificados y funcionales
**PrÃ³ximos pasos**: Ejecutar `train_ppo_multiobjetivo.py` para obtener resultados optimales

