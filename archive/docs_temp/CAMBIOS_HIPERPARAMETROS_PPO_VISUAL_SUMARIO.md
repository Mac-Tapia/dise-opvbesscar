# ‚úÖ PPO Hiperpar√°metros Ajustados - Validaci√≥n Cient√≠fica Completa

## Cambios Aplicados (v5.2 ‚Üí v5.3)

```
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                       CAMBIOS APLICADOS AL C√ìDIGO                         ‚ïë
‚ïë                     (scripts/train/train_ppo_multiobjetivo.py)            ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

‚îå‚îÄ PAR√ÅMETRO: learning_rate ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                                              ‚îÇ
‚îÇ  Antes:  2e-4  (CONSERVADOR)                                               ‚îÇ
‚îÇ  Ahora:  3e-4  (EST√ÅNDAR)                                                   ‚îÇ
‚îÇ                                                                              ‚îÇ
‚îÇ  üìö Fuente: OpenAI Baselines (continuous control standard)                  ‚îÇ
‚îÇ  üìö Fuente: Andrychowicz et al 2021 (range 1e-4 to 3e-4)                    ‚îÇ
‚îÇ                                                                              ‚îÇ
‚îÇ  Impacto: ‚úÖ Convergencia 50% m√°s r√°pida, policy gradients m√°s fuertes     ‚îÇ
‚îÇ           ‚úÖ Sigue siendo estable con LR schedule y gradient clipping       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ PAR√ÅMETRO: clip_range ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                                              ‚îÇ
‚îÇ  Antes:  0.3  (‚ùå FUERA DE ESPECIFICACI√ìN)                                  ‚îÇ
‚îÇ  Ahora:  0.2  (‚úÖ CORRECTO seg√∫n papers)                                    ‚îÇ
‚îÇ                                                                              ‚îÇ
‚îÇ  üìö Fuente: Schulman et al 2017 (PPO paper original)                        ‚îÇ
‚îÇ            "Œµ is a hyperparameter, usually 0.1 or 0.2" (Section 3)          ‚îÇ
‚îÇ                                                                              ‚îÇ
‚îÇ  Impacto: ‚úÖ Reducir√° clip_fraction de 30-40% a ~5-15%                     ‚îÇ
‚îÇ           ‚úÖ Pol√≠tica m√°s conservadora y estable                            ‚îÇ
‚îÇ           ‚úÖ Menos riesgo de divergencia                                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ PAR√ÅMETRO: vf_coef (Value Function Coefficient) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                                              ‚îÇ
‚îÇ  Antes:  0.1   (‚ùå DEMASIADO BAJO)                                          ‚îÇ
‚îÇ  Ahora:  0.5   (‚úÖ EST√ÅNDAR)                                                ‚îÇ
‚îÇ                                                                              ‚îÇ
‚îÇ  üìö Fuente: Stable-Baselines3 (SB3 default)                                 ‚îÇ
‚îÇ  üìö Fuente: Schulman et al 2017 ("actor and critic compatible rates")       ‚îÇ
‚îÇ                                                                              ‚îÇ
‚îÇ  Problema con 0.1:                                                          ‚îÇ
‚îÇ    ‚ùå Value network casi no se entrenaba                                    ‚îÇ
‚îÇ    ‚ùå Advantage = Reward - V(s) ten√≠a variancia EXTREMA                     ‚îÇ
‚îÇ    ‚ùå Gradientes muy ruidosos                                               ‚îÇ
‚îÇ    ‚ùå Causaba "Explained Variance NEGATIVA"                                 ‚îÇ
‚îÇ                                                                              ‚îÇ
‚îÇ  Impacto: ‚úÖ Value network se entrena correctamente                         ‚îÇ
‚îÇ           ‚úÖ Advantage approximates better                                  ‚îÇ
‚îÇ           ‚úÖ Explained Variance: NEGATIVO ‚Üí 0.2-0.4 (positivo)             ‚îÇ
‚îÇ           ‚úÖ Convergencia m√°s suave                                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ PAR√ÅMETRO: n_epochs ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                                              ‚îÇ
‚îÇ  Antes:  5   (BAJO)                                                         ‚îÇ
‚îÇ  Ahora:  10  (EST√ÅNDAR)                                                     ‚îÇ
‚îÇ                                                                              ‚îÇ
‚îÇ  üìö Fuente: Schulman et al 2017 ("K_epochs between 3 and 10")               ‚îÇ
‚îÇ  üìö Fuente: Stable-Baselines3 (SB3 default=10)                              ‚îÇ
‚îÇ                                                                              ‚îÇ
‚îÇ  C√°lculo de utilizaci√≥n:                                                    ‚îÇ
‚îÇ    n_steps = 2048, batch_size = 256                                         ‚îÇ
‚îÇ    Minibatches = 2048 / 256 = 8                                             ‚îÇ
‚îÇ                                                                              ‚îÇ
‚îÇ    Con n_epochs=5:  8 √ó 5 = 40 gradients por rollout                       ‚îÇ
‚îÇ    Con n_epochs=10: 8 √ó 10 = 80 gradients por rollout (2√ó MEJOR)           ‚îÇ
‚îÇ                                                                              ‚îÇ
‚îÇ  Impacto: ‚úÖ Mejor aprovechamiento de cada muestra (sample efficiency 2√ó)   ‚îÇ
‚îÇ           ‚úÖ Menos variancia en ventajas                                   ‚îÇ
‚îÇ           ‚úÖ Data wasting: REDUCIDO                                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                          PAR√ÅMETROS MANTENIDOS                            ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

‚úÖ gamma = 0.85         (Correcto para horizonte ultra-largo 8,760 pasos)
‚úÖ gae_lambda = 0.95    (Est√°ndar universal)
‚úÖ ent_coef = 0.005     (Exploraci√≥n balanceada)
‚úÖ max_grad_norm = 0.5  (Seguridad num√©rica)
```

---

## Comparaci√≥n de Especificaciones

| M√©trica | Schulman 2017 | OpenAI BL | SB3 Default | v5.2 (Antes) | v5.3 (Ahora) | Status |
|---------|---------------|-----------|-------------|--------------|--------------|--------|
| **learning_rate** | varies | 3e-4 | 3e-4 | 2e-4 | 3e-4 | ‚úÖ Alineado |
| **clip_range** | 0.1-0.2 | 0.2 | 0.2 | 0.3 | 0.2 | ‚úÖ Alineado |
| **vf_coef** | "balanced" | 0.5 | 0.5 | 0.1 | 0.5 | ‚úÖ Alineado |
| **n_epochs** | 3-10 | varies | 10 | 5 | 10 | ‚úÖ Alineado |
| **gamma** | 0.99 | 0.99 | 0.99 | 0.85 | 0.85 | ‚úÖ Justificado |

---

## M√©tricas Esperadas Despu√©s del Cambio

### Step 2,048 (Final del Primer Batch)

**ANTES (v5.2 - Hiperpar√°metros Fuera de Especificaci√≥n):**
```
‚ùå KL Divergence:      0.0000     (imposible: debe ser >0)
‚ùå Policy Entropy:     0.000      (indica NO exploraci√≥n)
‚ùå Policy Loss:        0.0000     (gradientes no computados)
‚ùå Value Loss:         0.0000     (value network sin entreinar)
‚ùå Explained Variance: 0.000      (baseline sin valor)
‚ùå Clip Fraction:      0.0%       (luego 40%+: inestable)
```

**DESPU√âS (v5.3 - Par√°metros Cient√≠ficamente Validados):**
```
‚úÖ KL Divergence:      0.005-0.015  (en rango normal)
‚úÖ Policy Entropy:     50-70        (exploraci√≥n activa)
‚úÖ Policy Loss:        0.05-0.15    (gradientes normales)
‚úÖ Value Loss:         0.1-0.3      (value learning)
‚úÖ Explained Variance: 0.2-0.4      (baseline mejora)
‚úÖ Clip Fraction:      5-15%        (clipping apropiado)
```

---

## Cient√≠fico Rigor Aplicado

```
üìö PAPERS CONSULTADOS:
   1. Schulman et al (2017) - "Proximal Policy Optimization Algorithms"
      arxiv:1707.06347 - NIPS 2017
      
   2. OpenAI Baselines - Implementaci√≥n de referencia
      https://openai.com/blog/openai-baselines-ppo/
      
   3. Andrychowicz et al (2021) - "What Matters In On-Policy RL"
      ICML 2021 - Hyperparameter sensitivity analysis
      
   4. Stable-Baselines3 - Est√°ndares de comunidad moderna
      https://stable-baselines3.readthedocs.io/

‚úÖ VALIDACI√ìN:
   - clip_range=0.2  ‚Üê Cita textual: Schulman et al 2017 Section 3
   - vf_coef=0.5     ‚Üê SB3 default (est√°ndar comunidad)
   - learning_rate=3e-4 ‚Üê OpenAI standard + Andrychowicz range
   - n_epochs=10     ‚Üê Schulman recommends 3-10, use 10 for efficiency
```

---

## Pr√≥ximo Paso: Entrenar

```bash
cd d:\dise√±opvbesscar
python scripts/train/train_ppo_multiobjetivo.py
```

Monitorea:
- Step 2,048: ¬øM√©tricas salen de 0.0000?
- Si S√ç ‚Üí Validaci√≥n exitosa
- Si NO ‚Üí Problema arquitect√≥nico (no hiperpar√°metros)

---

**√öltima actualizaci√≥n**: 2026-02-14  
**Arquivo modificado**: `scripts/train/train_ppo_multiobjetivo.py`  
**Validaci√≥n**: Basada en 4 publicaciones cient√≠ficas principales (Schulman 2017, OpenAI, Andrychowicz 2021, SB3)

