# ‚úì LANZAMIENTO DE ENTRENAMIENTO SERIAL - GPU M√ÅXIMO

## Estado de Verificaci√≥n

‚úÖ **Todos los requisitos est√°n listos:**

### OE2 (Preparaci√≥n de datos)

- ‚úÖ Solar: 8760h profile + PV sizing
- ‚úÖ BESS: 2000 kWh + hourly simulation
- ‚úÖ Chargers: 128 profiles (112 motos 2kW + 16 mototaxis 3kW)

### OE3 (Dataset)

- ‚úÖ Dataset CityLearn construido: `data/processed/citylearn/iquitos_ev_mall/`
  - 2 buildings (Grid + PV/BESS)
  - 128 charger profiles
  - 17 Weather files
  - Schemas JSON v√°lidos

### GPU

- ‚úÖ CUDA disponible
- ‚úÖ Memoria GPU suficiente
- ‚úÖ Variables de entorno optimizadas

---

## üöÄ LANZAR ENTRENAMIENTO

### Opci√≥n 1: PowerShell (RECOMENDADO)

```powershell
# Activar venv primero
.venv\Scripts\Activate.ps1

# Ejecutar entrenamiento
.\train_agents_serial.ps1
```

### Opci√≥n 2: Python directo

```bash
# Activar venv
.venv\Scripts\activate

# Ejecutar
python train_agents_serial_gpu.py
```

### Opci√≥n 3: Script cl√°sico de OE3

```bash
python -m scripts.run_oe3_simulate --config configs/default.yaml --skip-dataset
```

---

## üìä Orden de Entrenamiento (SERIAL)

El script `train_agents_serial_gpu.py` ejecuta:

1. **SAC** (Soft Actor-Critic)
   - Device: CUDA
   - Episodes: 5
   - Batch: 65,536 (m√°ximo)
   - AMP: Enabled
   - Tiempo estimado: 1.5-2h

2. **PPO** (Proximal Policy Optimization)
   - Device: CPU (m√°s estable)
   - Episodes: 5
   - n_steps: 16,384
   - Tiempo estimado: 2-2.5h

3. **A2C** (Advantage Actor-Critic)
   - Device: CUDA
   - Episodes: 5
   - n_steps: 32,768
   - AMP: Enabled
   - Tiempo estimado: 1.5-2h

**Total estimado: 5-6.5 horas**

---

## üìà Monitoreo en Tiempo Real

### Ver checkpoints mientras entrena

```bash
python monitor_checkpoints.py
```

### Ver archivos de training

```bash
ls -lah outputs/oe3/checkpoints/SAC/
ls -lah outputs/oe3/checkpoints/PPO/
ls -lah outputs/oe3/checkpoints/A2C/
```

---

## ‚úì Resultados Esperados

### Despu√©s de completar

**Archivo: `outputs/oe3/simulations/simulation_summary.json`**

```json
{
  "best_agent": "SAC",
  "pv_bess_uncontrolled": {
    "carbon_kg": 7847032,
    "simulated_years": 1,
    ...
  },
  "pv_bess_results": {
    "SAC": { "carbon_kg": 7547021 },
    "PPO": { "carbon_kg": 7578734 },
    "A2C": { "carbon_kg": 7615072 }
  },
  "reductions": {
    "SAC": { "reduction_pct": 0.0381 },
    ...
  }
}
```

**Archivo: `outputs/oe3/simulations/co2_comparison.md`**
Tabla comparativa con reducciones %

---

## üõ†Ô∏è Configuraci√≥n de Hiperpar√°metros

Editar `configs/default.yaml` ‚Üí secci√≥n `oe3.evaluation`:

```yaml
evaluation:
  agents:
    - SAC
    - PPO
    - A2C
  
  sac:
    episodes: 5           # ‚Üê Aumentar para mejor convergencia
    batch_size: 65536     # ‚Üê M√°ximo recomendado
    device: cuda          # GPU
    use_amp: true         # Mixed Precision
  
  ppo:
    episodes: 5
    device: cpu           # CPU para estabilidad
    batch_size: 16384
  
  a2c:
    episodes: 5
    device: cuda          # GPU
    use_amp: true
```

---

## ‚ö†Ô∏è Troubleshooting

### GPU no detectada

```bash
python -c "import torch; print(torch.cuda.is_available())"
```

- Si False ‚Üí Instalar CUDA Toolkit compatible

### Memory error (OOM)

- Reducir `batch_size` en config
- Reducir `n_steps` para PPO/A2C
- Usar `device: cpu`

### Entrenamiento lento

- Verificar `use_amp: true` en config
- Aumentar `batch_size`
- Reducir `log_interval`

### Reanudar entrenamiento interrumpido

```bash
python -m scripts.run_oe3_simulate --config configs/default.yaml --skip-dataset --skip-uncontrolled
```

Los checkpoints se detectan autom√°ticamente.

---

## üìã Checklist Pre-Lanzamiento

- ‚úÖ `.venv\Scripts\activate` ejecutado
- ‚úÖ `configs/default.yaml` verificado
- ‚úÖ `data/interim/oe2/` completo (solar, bess, chargers)
- ‚úÖ `data/processed/citylearn/iquitos_ev_mall/` existe
- ‚úÖ GPU disponible: `python -c "import torch; print(torch.cuda.is_available())"`
- ‚úÖ Espacio disco: ~20 GB (checkpoints + outputs)

---

## üìû Comandos √ötiles

```bash
# Ver status de entrenamiento actual
python show_training_status.py

# Monitorear memoria GPU
nvidia-smi -l 1

# Limpiar checkpoints viejos
rm -rf outputs/oe3/checkpoints/

# Resetear simulaci√≥n (cuidado!)
rm outputs/oe3/simulations/*

# Ver logs detallados
tail -f analyses/oe3/training/*.log
```

---

## ‚ú® Siguiente: Post-Entrenamiento

Una vez completado, ejecutar:

```bash
python -m scripts.run_oe3_co2_table --config configs/default.yaml
```

Para generar tabla final de CO‚ÇÇ y reducciones.

---

**Estado: LISTO PARA LANZAMIENTO** ‚úÖ
Fecha: 2025-01-15
